{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WebGrip Infrastructure \u00b6 Welcome to the comprehensive documentation for WebGrip's infrastructure repository. This site provides an end-to-end map of our CI/CD infrastructure, Docker images, and automation workflows. What's Inside \u00b6 This repository contains the foundational infrastructure components that power WebGrip's development and deployment processes: 6 Specialized Docker Images for different stages of our CI/CD pipeline Automated Build & Deploy Workflows using GitHub Actions Testing Infrastructure with Playwright for end-to-end testing Development Tools for local testing and development Quick Navigation \u00b6 \ud83d\ude80 Getting Started \u00b6 Purpose & Scope - Understand what this repository provides Architecture Overview - High-level system design Quick Start Guide - Get up and running quickly \ud83d\udc33 Docker Images \u00b6 Our specialized container images for different purposes: Image Purpose Documentation Rust CI Runner Rust development and CI environment Complete Rust toolchain + utilities GitHub Actions Runner Self-hosted GitHub Actions runner Custom runner with additional tools Helm Deploy Kubernetes deployment via Helm Alpine-based deployment image Playwright Runner End-to-end testing environment Browser testing infrastructure ACT Runner Local GitHub Actions testing Run workflows locally with ACT Rust Releaser Release automation for Rust projects Node.js + Rust release tooling \u2699\ufe0f Operations \u00b6 CI/CD Pipeline - How our automation works Testing - End-to-end test infrastructure Contributing - Add new images or improve existing ones Repository Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 infrastructure/ \u251c\u2500\u2500 ops/docker/ # Docker image definitions \u2502 \u251c\u2500\u2500 rust-ci-runner/ # Rust development environment \u2502 \u251c\u2500\u2500 github-runner/ # GitHub Actions runner \u2502 \u251c\u2500\u2500 helm-deploy/ # Kubernetes Helm deployment \u2502 \u251c\u2500\u2500 playwright-runner/ # Browser testing environment \u2502 \u251c\u2500\u2500 act-runner/ # Local GitHub Actions testing \u2502 \u2514\u2500\u2500 rust-releaser/ # Release automation \u251c\u2500\u2500 .github/workflows/ # CI/CD automation \u251c\u2500\u2500 tests/playwright-runner/ # Testing infrastructure \u251c\u2500\u2500 docs/techdocs/ # This documentation \u2514\u2500\u2500 catalog-info.yml # Backstage service catalog Key Features \u00b6 \u2705 Automated Docker Image Building - Changes to Dockerfiles trigger automatic builds and pushes \u2705 Multi-Platform Support - Images built for different architectures where needed \u2705 Integrated Testing - Playwright setup for comprehensive E2E testing \u2705 Local Development - ACT runner for testing GitHub Actions locally \u2705 Backstage Integration - Full service catalog integration Getting Help \u00b6 Issues : Report problems or request features via GitHub Issues Discussions : Ask questions in GitHub Discussions Team : Owned by group:webgrip/ops (see catalog-info.yml ) Note : This documentation is automatically maintained. See our Maintenance Guide for details on keeping it current. Recent Updates \u00b6 Check the ADRs section for recent architectural decisions and changes to our infrastructure approach.","title":"Home"},{"location":"#webgrip-infrastructure","text":"Welcome to the comprehensive documentation for WebGrip's infrastructure repository. This site provides an end-to-end map of our CI/CD infrastructure, Docker images, and automation workflows.","title":"WebGrip Infrastructure"},{"location":"#whats-inside","text":"This repository contains the foundational infrastructure components that power WebGrip's development and deployment processes: 6 Specialized Docker Images for different stages of our CI/CD pipeline Automated Build & Deploy Workflows using GitHub Actions Testing Infrastructure with Playwright for end-to-end testing Development Tools for local testing and development","title":"What's Inside"},{"location":"#quick-navigation","text":"","title":"Quick Navigation"},{"location":"#getting-started","text":"Purpose & Scope - Understand what this repository provides Architecture Overview - High-level system design Quick Start Guide - Get up and running quickly","title":"\ud83d\ude80 Getting Started"},{"location":"#docker-images","text":"Our specialized container images for different purposes: Image Purpose Documentation Rust CI Runner Rust development and CI environment Complete Rust toolchain + utilities GitHub Actions Runner Self-hosted GitHub Actions runner Custom runner with additional tools Helm Deploy Kubernetes deployment via Helm Alpine-based deployment image Playwright Runner End-to-end testing environment Browser testing infrastructure ACT Runner Local GitHub Actions testing Run workflows locally with ACT Rust Releaser Release automation for Rust projects Node.js + Rust release tooling","title":"\ud83d\udc33 Docker Images"},{"location":"#operations","text":"CI/CD Pipeline - How our automation works Testing - End-to-end test infrastructure Contributing - Add new images or improve existing ones","title":"\u2699\ufe0f Operations"},{"location":"#repository-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 infrastructure/ \u251c\u2500\u2500 ops/docker/ # Docker image definitions \u2502 \u251c\u2500\u2500 rust-ci-runner/ # Rust development environment \u2502 \u251c\u2500\u2500 github-runner/ # GitHub Actions runner \u2502 \u251c\u2500\u2500 helm-deploy/ # Kubernetes Helm deployment \u2502 \u251c\u2500\u2500 playwright-runner/ # Browser testing environment \u2502 \u251c\u2500\u2500 act-runner/ # Local GitHub Actions testing \u2502 \u2514\u2500\u2500 rust-releaser/ # Release automation \u251c\u2500\u2500 .github/workflows/ # CI/CD automation \u251c\u2500\u2500 tests/playwright-runner/ # Testing infrastructure \u251c\u2500\u2500 docs/techdocs/ # This documentation \u2514\u2500\u2500 catalog-info.yml # Backstage service catalog","title":"Repository Structure"},{"location":"#key-features","text":"\u2705 Automated Docker Image Building - Changes to Dockerfiles trigger automatic builds and pushes \u2705 Multi-Platform Support - Images built for different architectures where needed \u2705 Integrated Testing - Playwright setup for comprehensive E2E testing \u2705 Local Development - ACT runner for testing GitHub Actions locally \u2705 Backstage Integration - Full service catalog integration","title":"Key Features"},{"location":"#getting-help","text":"Issues : Report problems or request features via GitHub Issues Discussions : Ask questions in GitHub Discussions Team : Owned by group:webgrip/ops (see catalog-info.yml ) Note : This documentation is automatically maintained. See our Maintenance Guide for details on keeping it current.","title":"Getting Help"},{"location":"#recent-updates","text":"Check the ADRs section for recent architectural decisions and changes to our infrastructure approach.","title":"Recent Updates"},{"location":"information-architecture-analysis/","text":"Information Architecture Analysis for webgrip/infrastructure \u00b6 Repository Analysis Summary \u00b6 The webgrip/infrastructure repository serves as a centralized CI/CD infrastructure provider, containing Docker images and automation tooling that supports WebGrip's development and deployment workflows. Key Components Identified : - 6 specialized Docker images in ops/docker/ - GitHub Actions automation in .github/workflows/ - Playwright testing infrastructure in tests/playwright-runner/ - Backstage catalog integration via catalog-info.yml Proposed Information Architecture Alternatives \u00b6 Alternative 1: Service-First Organization (RECOMMENDED) \u00b6 Rationale : Each Docker image serves as a distinct \"service\" with specific responsibilities in the CI/CD ecosystem. This mirrors how the repository is already organized and aligns with how users will interact with individual images. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1. Overview - Purpose and scope - Quick start guide - Architecture overview 2. Docker Images (Services) - Rust CI Runner - GitHub Actions Runner - Helm Deploy - Playwright Runner - ACT Runner - Rust Releaser 3. CI/CD Pipeline - Automated building - Docker registry integration - Workflow details 4. Testing - Playwright setup - Test execution 5. Operations - Building locally - Contributing new images - Maintenance procedures 6. ADRs Mapping to Code : - Overview \u2192 Root README, catalog-info.yml - Docker Images \u2192 Individual directories in ops/docker/ - CI/CD \u2192 .github/workflows/on_dockerfile_change.yml - Testing \u2192 tests/playwright-runner/ - Operations \u2192 Dockerfile patterns, docker-compose.yml Alternative 2: Layer-First Organization \u00b6 Rationale : Organizes by infrastructure layers (runtime, build, deploy, test). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. Overview 2. Runtime Environment - Base images and platforms - Container orchestration 3. Build Layer - Rust toolchains (rust-ci-runner, rust-releaser) - Build automation 4. Deployment Layer - Helm deployment (helm-deploy) - Runner infrastructure (github-runner, act-runner) 5. Testing Layer - Playwright testing (playwright-runner) 6. Automation - CI/CD workflows 7. Operations & Maintenance 8. ADRs Alternative 3: Workflow-First Organization \u00b6 Rationale : Organizes around development workflows and use cases. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1. Overview 2. Development Workflows - Rust development (rust-ci-runner) - Local testing with ACT (act-runner) - E2E testing (playwright-runner) 3. Deployment Workflows - Kubernetes deployment (helm-deploy) - Release processes (rust-releaser) 4. Infrastructure Workflows - Self-hosted runners (github-runner) - Automated image building 5. Testing & Quality 6. Operations 7. ADRs Recommendation: Alternative 1 (Service-First) \u00b6 Why this works best for this repository : Matches existing structure : The repository is already organized by service (Docker image) User-centric : Developers typically need specific images for specific purposes Clear ownership : Each image has distinct responsibilities and can be documented independently Scalable : Easy to add new images as new services Maintenance-friendly : Changes to one image don't affect documentation of others Trade-offs : - Some cross-cutting concerns (security, monitoring) need to be addressed in multiple places - Workflow documentation is distributed across services rather than centralized Implementation depth : \u2264 3 levels - Level 1: Main sections (Overview, Docker Images, etc.) - Level 2: Individual services or subsections - Level 3: Specific topics within services (Usage, Configuration, Troubleshooting) Next Steps \u00b6 Implement the Service-First IA in mkdocs.yml navigation Create placeholder pages for each section Populate content section by section, starting with Overview Add cross-links and Mermaid diagrams where helpful Integrate ADRs and establish maintenance procedures","title":"Information Architecture Analysis for webgrip/infrastructure"},{"location":"information-architecture-analysis/#information-architecture-analysis-for-webgripinfrastructure","text":"","title":"Information Architecture Analysis for webgrip/infrastructure"},{"location":"information-architecture-analysis/#repository-analysis-summary","text":"The webgrip/infrastructure repository serves as a centralized CI/CD infrastructure provider, containing Docker images and automation tooling that supports WebGrip's development and deployment workflows. Key Components Identified : - 6 specialized Docker images in ops/docker/ - GitHub Actions automation in .github/workflows/ - Playwright testing infrastructure in tests/playwright-runner/ - Backstage catalog integration via catalog-info.yml","title":"Repository Analysis Summary"},{"location":"information-architecture-analysis/#proposed-information-architecture-alternatives","text":"","title":"Proposed Information Architecture Alternatives"},{"location":"information-architecture-analysis/#alternative-1-service-first-organization-recommended","text":"Rationale : Each Docker image serves as a distinct \"service\" with specific responsibilities in the CI/CD ecosystem. This mirrors how the repository is already organized and aligns with how users will interact with individual images. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1. Overview - Purpose and scope - Quick start guide - Architecture overview 2. Docker Images (Services) - Rust CI Runner - GitHub Actions Runner - Helm Deploy - Playwright Runner - ACT Runner - Rust Releaser 3. CI/CD Pipeline - Automated building - Docker registry integration - Workflow details 4. Testing - Playwright setup - Test execution 5. Operations - Building locally - Contributing new images - Maintenance procedures 6. ADRs Mapping to Code : - Overview \u2192 Root README, catalog-info.yml - Docker Images \u2192 Individual directories in ops/docker/ - CI/CD \u2192 .github/workflows/on_dockerfile_change.yml - Testing \u2192 tests/playwright-runner/ - Operations \u2192 Dockerfile patterns, docker-compose.yml","title":"Alternative 1: Service-First Organization (RECOMMENDED)"},{"location":"information-architecture-analysis/#alternative-2-layer-first-organization","text":"Rationale : Organizes by infrastructure layers (runtime, build, deploy, test). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. Overview 2. Runtime Environment - Base images and platforms - Container orchestration 3. Build Layer - Rust toolchains (rust-ci-runner, rust-releaser) - Build automation 4. Deployment Layer - Helm deployment (helm-deploy) - Runner infrastructure (github-runner, act-runner) 5. Testing Layer - Playwright testing (playwright-runner) 6. Automation - CI/CD workflows 7. Operations & Maintenance 8. ADRs","title":"Alternative 2: Layer-First Organization"},{"location":"information-architecture-analysis/#alternative-3-workflow-first-organization","text":"Rationale : Organizes around development workflows and use cases. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1. Overview 2. Development Workflows - Rust development (rust-ci-runner) - Local testing with ACT (act-runner) - E2E testing (playwright-runner) 3. Deployment Workflows - Kubernetes deployment (helm-deploy) - Release processes (rust-releaser) 4. Infrastructure Workflows - Self-hosted runners (github-runner) - Automated image building 5. Testing & Quality 6. Operations 7. ADRs","title":"Alternative 3: Workflow-First Organization"},{"location":"information-architecture-analysis/#recommendation-alternative-1-service-first","text":"Why this works best for this repository : Matches existing structure : The repository is already organized by service (Docker image) User-centric : Developers typically need specific images for specific purposes Clear ownership : Each image has distinct responsibilities and can be documented independently Scalable : Easy to add new images as new services Maintenance-friendly : Changes to one image don't affect documentation of others Trade-offs : - Some cross-cutting concerns (security, monitoring) need to be addressed in multiple places - Workflow documentation is distributed across services rather than centralized Implementation depth : \u2264 3 levels - Level 1: Main sections (Overview, Docker Images, etc.) - Level 2: Individual services or subsections - Level 3: Specific topics within services (Usage, Configuration, Troubleshooting)","title":"Recommendation: Alternative 1 (Service-First)"},{"location":"information-architecture-analysis/#next-steps","text":"Implement the Service-First IA in mkdocs.yml navigation Create placeholder pages for each section Populate content section by section, starting with Overview Add cross-links and Mermaid diagrams where helpful Integrate ADRs and establish maintenance procedures","title":"Next Steps"},{"location":"adrs/","text":"Architectural Decision Records (ADRs) \u00b6 Index of architectural decisions made for the WebGrip infrastructure repository. What are ADRs? \u00b6 Architectural Decision Records (ADRs) document important architectural decisions along with their context and consequences. They help teams: Track decision history and understand why choices were made Share context with new team members and contributors Revisit decisions when circumstances change Learn from past decisions to improve future choices ADR Format \u00b6 We use the MADR (Markdown Architectural Decision Records) format for consistency and clarity. Template Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # [short title of solved problem and solution] * Status: [ proposed | rejected | accepted | deprecated | superseded by [ADR-0005 ]( 0005-example.md )] * Deciders: [list everyone involved in the decision] * Date: [YYYY-MM-DD when the decision was last updated] ## Context and Problem Statement [Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.] ## Decision Drivers * [driver 1, e.g., a force, facing concern, \u2026] * [driver 2, e.g., a force, facing concern, \u2026] * \u2026 <!-- numbers of drivers can vary --> ## Considered Options * [option 1] * [option 2] * [option 3] * \u2026 <!-- numbers of options can vary --> ## Decision Outcome Chosen option: \"[option 1]\", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)]. ### Positive Consequences * [e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] * \u2026 ### Negative Consequences * [e.g., compromising quality attribute, follow-up decisions required, \u2026] * \u2026 ## Links * [Link type] [Link to ADR] <!-- example: Refines [ ADR-0005 ]( 0005-example.md ) --> * \u2026 <!-- numbers of links can vary --> Current ADRs \u00b6 Infrastructure Architecture \u00b6 ADR Title Status Date ADR-0001 Docker Image Architecture and Organization Accepted 2024-01-15 ADR-0002 CI/CD Workflow Strategy with Reusable Components Accepted 2024-01-20 ADR-0003 Documentation Platform Selection (TechDocs) Accepted 2024-01-25 Image Design Decisions \u00b6 ADR Title Status Date ADR-0004 Base Image Selection Strategy Accepted 2024-02-01 ADR-0005 Multi-stage Build Pattern Adoption Accepted 2024-02-05 ADR-0006 Container Security Hardening Standards Accepted 2024-02-10 Operational Decisions \u00b6 ADR Title Status Date ADR-0007 Docker Registry Strategy and Management Accepted 2024-02-15 ADR-0008 Testing Strategy for Infrastructure Images Accepted 2024-02-20 ADR-0009 Maintenance and Update Automation Proposed 2024-02-25 Creating New ADRs \u00b6 When to Create an ADR \u00b6 Create an ADR when making decisions that: Affect system architecture or overall design Have long-term impact on the project Involve trade-offs between different approaches Change existing patterns or standards Require team consensus to move forward Process \u00b6 Identify the Decision : Recognize that an architectural decision needs to be made Research Options : Investigate different approaches and their trade-offs Draft ADR : Create a new ADR using the template Gather Input : Share with team members and stakeholders for feedback Make Decision : Finalize the decision and update the ADR status Communicate : Share the decision with relevant teams Naming Convention \u00b6 ADRs are numbered sequentially and use descriptive titles: 1 NNNN-short-descriptive-title.md Examples: - 0001-docker-image-architecture.md - 0010-monitoring-and-alerting-strategy.md - 0015-dependency-management-approach.md File Location \u00b6 ADRs are stored in the docs/adrs/ directory: 1 2 3 4 5 docs/adrs/ \u251c\u2500\u2500 0001-docker-image-architecture.md \u251c\u2500\u2500 0002-ci-cd-workflow-strategy.md \u251c\u2500\u2500 0003-documentation-platform.md \u2514\u2500\u2500 template.md ADR Lifecycle \u00b6 Status Transitions \u00b6 flowchart TD DRAFT[Draft] --> PROPOSED[Proposed] PROPOSED --> ACCEPTED[Accepted] PROPOSED --> REJECTED[Rejected] ACCEPTED --> DEPRECATED[Deprecated] ACCEPTED --> SUPERSEDED[Superseded] PROPOSED --> DRAFT REJECTED --> DRAFT Draft : Initial version being developed Proposed : Ready for review and decision Accepted : Decision has been made and is being implemented Rejected : Decision was considered but not adopted Deprecated : Decision is no longer recommended but not replaced Superseded : Decision has been replaced by a newer ADR Reviewing ADRs \u00b6 ADRs should be reviewed: Quarterly : Review all current ADRs for relevance and accuracy When circumstances change : Major technology shifts or requirement changes Before major decisions : Ensure new decisions align with existing ADRs During onboarding : Help new team members understand architectural context Using ADRs in Development \u00b6 Referencing ADRs \u00b6 When making implementation decisions, reference relevant ADRs: 1 2 3 4 5 6 <!-- In pull request descriptions --> This change implements the multi-stage build pattern as decided in [ ADR-0005 ]( docs/adrs/0005-multi-stage-builds.md ). <!-- In code comments --> // Following the security hardening standards from ADR-0006 USER appuser Updating Implementation \u00b6 When ADR decisions affect implementation: Review existing code for compliance with ADR decisions Update implementation to align with architectural decisions Document deviations if full compliance isn't immediately possible Plan migration for systems that don't yet follow ADR guidelines Tools and Automation \u00b6 ADR Management \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 #!/bin/bash # scripts/adr-tools.sh # Create new ADR create_adr () { local title = \" $1 \" local number = $( printf \"%04d\" $(($( ls docs/adrs/ | grep -E '^[0-9]{4}-' | wc -l ) + 1 ))) local filename = \"docs/adrs/ ${ number } - ${ title } .md\" # Copy template and update cp docs/adrs/template.md \" $filename \" sed -i \"s/\\[short title of solved problem and solution\\]/ $title /\" \" $filename \" sed -i \"s/Date: \\[YYYY-MM-DD when the decision was last updated\\]/Date: $( date +%Y-%m-%d ) /\" \" $filename \" echo \"Created ADR: $filename \" } # List ADRs by status list_adrs () { local status = \" $1 \" echo \"ADRs with status: $status \" grep -l \"Status:.* $status \" docs/adrs/*.md | sort } # Validate ADRs validate_adrs () { echo \"Validating ADR format...\" for adr in docs/adrs/ [ 0 -9 ] *.md ; do if ! grep -q \"^# \" \" $adr \" ; then echo \"\u274c $adr : Missing title\" fi if ! grep -q \"Status:\" \" $adr \" ; then echo \"\u274c $adr : Missing status\" fi if ! grep -q \"Date:\" \" $adr \" ; then echo \"\u274c $adr : Missing date\" fi done echo \"ADR validation complete\" } # Usage case \" $1 \" in \"create\" ) create_adr \" $2 \" ;; \"list\" ) list_adrs \" $2 \" ;; \"validate\" ) validate_adrs ;; * ) echo \"Usage: $0 {create|list|validate} [args]\" ;; esac Integration with Documentation \u00b6 ADRs are automatically included in the TechDocs site navigation and can be referenced from other documentation pages. GitHub Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # .github/workflows/adr-validation.yml name : ADR Validation on : pull_request : paths : - 'docs/adrs/**' jobs : validate : runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Validate ADR format run : ./scripts/adr-tools.sh validate - name : Check for duplicate numbers run : | duplicates=$(ls docs/adrs/[0-9]*.md | sed 's/.*\\/\\([0-9]*\\)-.*/\\1/' | sort | uniq -d) if [[ -n \"$duplicates\" ]]; then echo \"\u274c Duplicate ADR numbers found: $duplicates\" exit 1 fi - name : Validate links run : | # Check that all ADR links are valid find docs/adrs -name \"*.md\" -exec markdown-link-check {} \\; Best Practices \u00b6 Writing Effective ADRs \u00b6 Be Specific : Focus on one architectural decision per ADR Include Context : Explain the problem and constraints clearly Compare Options : Show what alternatives were considered Document Trade-offs : Explain both positive and negative consequences Keep Updated : Update status and content as decisions evolve Decision Process \u00b6 Involve Stakeholders : Include relevant team members in decision-making Time-box Decisions : Set deadlines to avoid endless discussion Document Assumptions : Make implicit assumptions explicit Plan Reviews : Schedule regular reviews of important decisions Learn from Outcomes : Track how decisions work out in practice Maintenance \u00b6 Regular Reviews : Review ADRs quarterly for relevance Update Status : Keep status information current Link Maintenance : Ensure all links remain valid Archive Old ADRs : Mark superseded ADRs clearly Extract Patterns : Identify common decision patterns over time Contributing to ADRs \u00b6 Proposing New ADRs \u00b6 Create Issue : Start with a GitHub issue to discuss the need for an ADR Draft ADR : Create initial draft using the template Seek Feedback : Share with team members for input Iterate : Refine the ADR based on feedback Finalize : Update status to \"Accepted\" after team agreement Improving Existing ADRs \u00b6 Identify Gaps : Notice missing information or outdated content Propose Changes : Create pull request with improvements Update Status : Change status if decision has evolved Add Links : Connect related ADRs for better navigation Enhance Context : Add more background information if helpful Related Documentation \u00b6 Architecture Overview - High-level architectural context Contributing Images - How architectural decisions affect contributions Maintenance - How ADRs guide maintenance decisions Templates and Examples \u00b6 ADR Template - Standard template for new ADRs Example ADRs - Real examples from this project MADR Documentation - Detailed format specification Note : ADRs are living documents that should evolve with the project. Regular review and updates ensure they remain valuable for decision-making and knowledge sharing. Maintainer : WebGrip Ops Team Location : docs/adrs/ Format : MADR (Markdown ADR)","title":"ADRs"},{"location":"adrs/#architectural-decision-records-adrs","text":"Index of architectural decisions made for the WebGrip infrastructure repository.","title":"Architectural Decision Records (ADRs)"},{"location":"adrs/#what-are-adrs","text":"Architectural Decision Records (ADRs) document important architectural decisions along with their context and consequences. They help teams: Track decision history and understand why choices were made Share context with new team members and contributors Revisit decisions when circumstances change Learn from past decisions to improve future choices","title":"What are ADRs?"},{"location":"adrs/#adr-format","text":"We use the MADR (Markdown Architectural Decision Records) format for consistency and clarity.","title":"ADR Format"},{"location":"adrs/#template-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # [short title of solved problem and solution] * Status: [ proposed | rejected | accepted | deprecated | superseded by [ADR-0005 ]( 0005-example.md )] * Deciders: [list everyone involved in the decision] * Date: [YYYY-MM-DD when the decision was last updated] ## Context and Problem Statement [Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.] ## Decision Drivers * [driver 1, e.g., a force, facing concern, \u2026] * [driver 2, e.g., a force, facing concern, \u2026] * \u2026 <!-- numbers of drivers can vary --> ## Considered Options * [option 1] * [option 2] * [option 3] * \u2026 <!-- numbers of options can vary --> ## Decision Outcome Chosen option: \"[option 1]\", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)]. ### Positive Consequences * [e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] * \u2026 ### Negative Consequences * [e.g., compromising quality attribute, follow-up decisions required, \u2026] * \u2026 ## Links * [Link type] [Link to ADR] <!-- example: Refines [ ADR-0005 ]( 0005-example.md ) --> * \u2026 <!-- numbers of links can vary -->","title":"Template Structure"},{"location":"adrs/#current-adrs","text":"","title":"Current ADRs"},{"location":"adrs/#infrastructure-architecture","text":"ADR Title Status Date ADR-0001 Docker Image Architecture and Organization Accepted 2024-01-15 ADR-0002 CI/CD Workflow Strategy with Reusable Components Accepted 2024-01-20 ADR-0003 Documentation Platform Selection (TechDocs) Accepted 2024-01-25","title":"Infrastructure Architecture"},{"location":"adrs/#image-design-decisions","text":"ADR Title Status Date ADR-0004 Base Image Selection Strategy Accepted 2024-02-01 ADR-0005 Multi-stage Build Pattern Adoption Accepted 2024-02-05 ADR-0006 Container Security Hardening Standards Accepted 2024-02-10","title":"Image Design Decisions"},{"location":"adrs/#operational-decisions","text":"ADR Title Status Date ADR-0007 Docker Registry Strategy and Management Accepted 2024-02-15 ADR-0008 Testing Strategy for Infrastructure Images Accepted 2024-02-20 ADR-0009 Maintenance and Update Automation Proposed 2024-02-25","title":"Operational Decisions"},{"location":"adrs/#creating-new-adrs","text":"","title":"Creating New ADRs"},{"location":"adrs/#when-to-create-an-adr","text":"Create an ADR when making decisions that: Affect system architecture or overall design Have long-term impact on the project Involve trade-offs between different approaches Change existing patterns or standards Require team consensus to move forward","title":"When to Create an ADR"},{"location":"adrs/#process","text":"Identify the Decision : Recognize that an architectural decision needs to be made Research Options : Investigate different approaches and their trade-offs Draft ADR : Create a new ADR using the template Gather Input : Share with team members and stakeholders for feedback Make Decision : Finalize the decision and update the ADR status Communicate : Share the decision with relevant teams","title":"Process"},{"location":"adrs/#naming-convention","text":"ADRs are numbered sequentially and use descriptive titles: 1 NNNN-short-descriptive-title.md Examples: - 0001-docker-image-architecture.md - 0010-monitoring-and-alerting-strategy.md - 0015-dependency-management-approach.md","title":"Naming Convention"},{"location":"adrs/#file-location","text":"ADRs are stored in the docs/adrs/ directory: 1 2 3 4 5 docs/adrs/ \u251c\u2500\u2500 0001-docker-image-architecture.md \u251c\u2500\u2500 0002-ci-cd-workflow-strategy.md \u251c\u2500\u2500 0003-documentation-platform.md \u2514\u2500\u2500 template.md","title":"File Location"},{"location":"adrs/#adr-lifecycle","text":"","title":"ADR Lifecycle"},{"location":"adrs/#status-transitions","text":"flowchart TD DRAFT[Draft] --> PROPOSED[Proposed] PROPOSED --> ACCEPTED[Accepted] PROPOSED --> REJECTED[Rejected] ACCEPTED --> DEPRECATED[Deprecated] ACCEPTED --> SUPERSEDED[Superseded] PROPOSED --> DRAFT REJECTED --> DRAFT Draft : Initial version being developed Proposed : Ready for review and decision Accepted : Decision has been made and is being implemented Rejected : Decision was considered but not adopted Deprecated : Decision is no longer recommended but not replaced Superseded : Decision has been replaced by a newer ADR","title":"Status Transitions"},{"location":"adrs/#reviewing-adrs","text":"ADRs should be reviewed: Quarterly : Review all current ADRs for relevance and accuracy When circumstances change : Major technology shifts or requirement changes Before major decisions : Ensure new decisions align with existing ADRs During onboarding : Help new team members understand architectural context","title":"Reviewing ADRs"},{"location":"adrs/#using-adrs-in-development","text":"","title":"Using ADRs in Development"},{"location":"adrs/#referencing-adrs","text":"When making implementation decisions, reference relevant ADRs: 1 2 3 4 5 6 <!-- In pull request descriptions --> This change implements the multi-stage build pattern as decided in [ ADR-0005 ]( docs/adrs/0005-multi-stage-builds.md ). <!-- In code comments --> // Following the security hardening standards from ADR-0006 USER appuser","title":"Referencing ADRs"},{"location":"adrs/#updating-implementation","text":"When ADR decisions affect implementation: Review existing code for compliance with ADR decisions Update implementation to align with architectural decisions Document deviations if full compliance isn't immediately possible Plan migration for systems that don't yet follow ADR guidelines","title":"Updating Implementation"},{"location":"adrs/#tools-and-automation","text":"","title":"Tools and Automation"},{"location":"adrs/#adr-management","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 #!/bin/bash # scripts/adr-tools.sh # Create new ADR create_adr () { local title = \" $1 \" local number = $( printf \"%04d\" $(($( ls docs/adrs/ | grep -E '^[0-9]{4}-' | wc -l ) + 1 ))) local filename = \"docs/adrs/ ${ number } - ${ title } .md\" # Copy template and update cp docs/adrs/template.md \" $filename \" sed -i \"s/\\[short title of solved problem and solution\\]/ $title /\" \" $filename \" sed -i \"s/Date: \\[YYYY-MM-DD when the decision was last updated\\]/Date: $( date +%Y-%m-%d ) /\" \" $filename \" echo \"Created ADR: $filename \" } # List ADRs by status list_adrs () { local status = \" $1 \" echo \"ADRs with status: $status \" grep -l \"Status:.* $status \" docs/adrs/*.md | sort } # Validate ADRs validate_adrs () { echo \"Validating ADR format...\" for adr in docs/adrs/ [ 0 -9 ] *.md ; do if ! grep -q \"^# \" \" $adr \" ; then echo \"\u274c $adr : Missing title\" fi if ! grep -q \"Status:\" \" $adr \" ; then echo \"\u274c $adr : Missing status\" fi if ! grep -q \"Date:\" \" $adr \" ; then echo \"\u274c $adr : Missing date\" fi done echo \"ADR validation complete\" } # Usage case \" $1 \" in \"create\" ) create_adr \" $2 \" ;; \"list\" ) list_adrs \" $2 \" ;; \"validate\" ) validate_adrs ;; * ) echo \"Usage: $0 {create|list|validate} [args]\" ;; esac","title":"ADR Management"},{"location":"adrs/#integration-with-documentation","text":"ADRs are automatically included in the TechDocs site navigation and can be referenced from other documentation pages.","title":"Integration with Documentation"},{"location":"adrs/#github-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # .github/workflows/adr-validation.yml name : ADR Validation on : pull_request : paths : - 'docs/adrs/**' jobs : validate : runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Validate ADR format run : ./scripts/adr-tools.sh validate - name : Check for duplicate numbers run : | duplicates=$(ls docs/adrs/[0-9]*.md | sed 's/.*\\/\\([0-9]*\\)-.*/\\1/' | sort | uniq -d) if [[ -n \"$duplicates\" ]]; then echo \"\u274c Duplicate ADR numbers found: $duplicates\" exit 1 fi - name : Validate links run : | # Check that all ADR links are valid find docs/adrs -name \"*.md\" -exec markdown-link-check {} \\;","title":"GitHub Integration"},{"location":"adrs/#best-practices","text":"","title":"Best Practices"},{"location":"adrs/#writing-effective-adrs","text":"Be Specific : Focus on one architectural decision per ADR Include Context : Explain the problem and constraints clearly Compare Options : Show what alternatives were considered Document Trade-offs : Explain both positive and negative consequences Keep Updated : Update status and content as decisions evolve","title":"Writing Effective ADRs"},{"location":"adrs/#decision-process","text":"Involve Stakeholders : Include relevant team members in decision-making Time-box Decisions : Set deadlines to avoid endless discussion Document Assumptions : Make implicit assumptions explicit Plan Reviews : Schedule regular reviews of important decisions Learn from Outcomes : Track how decisions work out in practice","title":"Decision Process"},{"location":"adrs/#maintenance","text":"Regular Reviews : Review ADRs quarterly for relevance Update Status : Keep status information current Link Maintenance : Ensure all links remain valid Archive Old ADRs : Mark superseded ADRs clearly Extract Patterns : Identify common decision patterns over time","title":"Maintenance"},{"location":"adrs/#contributing-to-adrs","text":"","title":"Contributing to ADRs"},{"location":"adrs/#proposing-new-adrs","text":"Create Issue : Start with a GitHub issue to discuss the need for an ADR Draft ADR : Create initial draft using the template Seek Feedback : Share with team members for input Iterate : Refine the ADR based on feedback Finalize : Update status to \"Accepted\" after team agreement","title":"Proposing New ADRs"},{"location":"adrs/#improving-existing-adrs","text":"Identify Gaps : Notice missing information or outdated content Propose Changes : Create pull request with improvements Update Status : Change status if decision has evolved Add Links : Connect related ADRs for better navigation Enhance Context : Add more background information if helpful","title":"Improving Existing ADRs"},{"location":"adrs/#related-documentation","text":"Architecture Overview - High-level architectural context Contributing Images - How architectural decisions affect contributions Maintenance - How ADRs guide maintenance decisions","title":"Related Documentation"},{"location":"adrs/#templates-and-examples","text":"ADR Template - Standard template for new ADRs Example ADRs - Real examples from this project MADR Documentation - Detailed format specification Note : ADRs are living documents that should evolve with the project. Regular review and updates ensure they remain valuable for decision-making and knowledge sharing. Maintainer : WebGrip Ops Team Location : docs/adrs/ Format : MADR (Markdown ADR)","title":"Templates and Examples"},{"location":"cicd/automated-building/","text":"Automated Building \u00b6 Our automated building system ensures that Docker images are built, tested, and published whenever changes are made to the infrastructure repository. Overview \u00b6 The automated building pipeline provides: \u2705 Change-triggered builds - Only build images when their source code changes \u2705 Multi-platform support - Build for different architectures where needed \u2705 Automated publishing - Push images to Docker Hub with proper tagging \u2705 Efficient resource usage - Build only what's necessary using change detection \u2705 Parallel execution - Build multiple images simultaneously when possible Architecture \u00b6 Build Trigger Flow \u00b6 flowchart TD PUSH[Developer Push] --> GH[GitHub Repository] GH --> DETECT[Change Detection Workflow] DETECT --> MATRIX[Build Matrix Generation] MATRIX --> PARALLEL[Parallel Build Jobs] PARALLEL --> BUILD1[Build Image 1] PARALLEL --> BUILD2[Build Image 2] PARALLEL --> BUILD3[Build Image N] BUILD1 --> PUSH1[Push to Registry] BUILD2 --> PUSH2[Push to Registry] BUILD3 --> PUSH3[Push to Registry] subgraph \"GitHub Actions\" WORKFLOW[on_dockerfile_change.yml] REUSABLE[webgrip/workflows] end DETECT --> WORKFLOW WORKFLOW --> REUSABLE Change Detection System \u00b6 flowchart LR subgraph \"Source Changes\" DOCKERFILE[Dockerfile Modified] CONTEXT[Build Context Changed] DEPS[Dependencies Updated] end subgraph \"Detection Logic\" PATH_FILTER[Path Filter: ops/docker/**] DIR_SCAN[Directory Scanner] MATRIX_GEN[Matrix Generator] end subgraph \"Build Execution\" STRATEGY[Build Strategy] PARALLEL_JOBS[Parallel Jobs] DOCKER_BUILD[Docker Build & Push] end DOCKERFILE --> PATH_FILTER CONTEXT --> PATH_FILTER DEPS --> PATH_FILTER PATH_FILTER --> DIR_SCAN DIR_SCAN --> MATRIX_GEN MATRIX_GEN --> STRATEGY STRATEGY --> PARALLEL_JOBS PARALLEL_JOBS --> DOCKER_BUILD Workflow Configuration \u00b6 Main Workflow: on_dockerfile_change.yml \u00b6 Located at .github/workflows/on_dockerfile_change.yml , this workflow: Triggers on pushes to main branch affecting ops/docker/** paths Detects changed directories using a reusable workflow Builds only the Docker images that have changes Publishes images with both :latest and :${{ github.sha }} tags 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name : '[Workflow] On Dockerfile Change' concurrency : group : push-${{ github.branch }} cancel-in-progress : true on : push : branches : [ main ] paths : [ 'ops/docker/**' ] jobs : determine-changed-directories : uses : webgrip/workflows/.github/workflows/determine-changed-directories.yml@ubuntu-latest with : inside-dir : 'ops/docker' build-and-push-changed-dirs : needs : [ determine-changed-directories ] if : needs.determine-changed-directories.outputs.matrix != '[]' strategy : fail-fast : false matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} uses : webgrip/workflows/.github/workflows/docker-build-and-push.yml@ubuntu-latest with : docker-context : ${{ matrix.path }} docker-file : Dockerfile docker-tags : | ${{ github.repository_owner }}/${{ matrix.basename }}:latest ${{ github.repository_owner }}/${{ matrix.basename }}:${{ github.sha }} secrets : DOCKER_USERNAME : ${{ secrets.DOCKER_USERNAME }} DOCKER_TOKEN : ${{ secrets.DOCKER_TOKEN }} Reusable Workflows \u00b6 The pipeline leverages shared workflows from the webgrip/workflows repository: Change Detection Workflow \u00b6 Purpose : Identify which Docker image directories have changes Output : JSON matrix of changed directories for parallel building Logic : Compares current commit against previous commit Docker Build & Push Workflow \u00b6 Purpose : Build and publish individual Docker images Features : Multi-platform builds, layer caching, security scanning Outputs : Published images with proper tags Build Process Details \u00b6 Change Detection Algorithm \u00b6 Path Filtering : Only triggers on changes to ops/docker/** Directory Scanning : Identifies which subdirectories contain changes Matrix Generation : Creates build matrix for parallel execution 1 2 3 4 5 # Example change detection logic changed_dirs = $( git diff --name-only HEAD~1 HEAD | grep '^ops/docker/' | cut -d '/' -f1-3 | sort -u ) Build Matrix Example \u00b6 When multiple images are changed simultaneously: 1 2 3 4 5 6 7 8 9 10 11 12 { \"include\" : [ { \"path\" : \"ops/docker/rust-ci-runner\" , \"basename\" : \"rust-ci-runner\" }, { \"path\" : \"ops/docker/playwright-runner\" , \"basename\" : \"playwright-runner\" } ] } Docker Image Tagging Strategy \u00b6 Each successful build produces two tags: Tag Pattern Purpose Example :latest Latest stable version webgrip/rust-ci-runner:latest :${{ github.sha }} Specific commit version webgrip/rust-ci-runner:a1b2c3d4 Build Context and Optimization \u00b6 Each Docker image build: Uses the correct context : Each image's subdirectory ( ops/docker/image-name/ ) Leverages layer caching : Docker layer caching for faster builds Optimizes build args : Build-time arguments for customization Implements security : Vulnerability scanning during build Supported Images \u00b6 The pipeline automatically builds and publishes these images: Directory Image Name Purpose ops/docker/rust-ci-runner webgrip/rust-ci-runner Rust development environment ops/docker/github-runner webgrip/github-runner Self-hosted GitHub Actions runner ops/docker/helm-deploy webgrip/helm-deploy Kubernetes deployment tools ops/docker/playwright-runner webgrip/playwright-runner E2E testing environment ops/docker/act-runner webgrip/act-runner Local GitHub Actions testing ops/docker/rust-releaser webgrip/rust-releaser Release automation Performance Optimizations \u00b6 Parallel Execution \u00b6 1 2 3 4 strategy : fail-fast : false # Continue building other images if one fails matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} Benefits : - Multiple images build simultaneously - Faster overall pipeline execution - Independent failure handling Build Caching \u00b6 The pipeline implements several caching strategies: Docker Layer Caching : Reuse unchanged layers between builds Registry Caching : Pull existing layers from registry GitHub Actions Cache : Cache build contexts and dependencies Resource Optimization \u00b6 Change Detection : Only build images with actual changes Concurrency Control : Prevent duplicate builds with cancel-in-progress Selective Triggers : Path-based triggering reduces unnecessary executions Security Features \u00b6 Build Security \u00b6 Vulnerability Scanning : Images scanned during build process Secret Management : Build credentials stored as GitHub secrets Signed Images : Images signed for integrity verification Base Image Updates : Regular updates to base images for security patches Access Control \u00b6 1 2 3 secrets : DOCKER_USERNAME : ${{ secrets.DOCKER_USERNAME }} DOCKER_TOKEN : ${{ secrets.DOCKER_TOKEN }} Registry Access : Controlled via organization-level secrets Workflow Permissions : Minimal required permissions Branch Protection : Only builds from protected main branch Monitoring and Observability \u00b6 Build Status Tracking \u00b6 GitHub Actions UI : Real-time build status and logs Commit Status Checks : Build status visible on pull requests Notification Integration : Slack/email notifications for failures Build Metrics \u00b6 Track key metrics for pipeline health: Build Duration : Time to complete full pipeline Success Rate : Percentage of successful builds Image Size : Monitor image size growth over time Vulnerability Count : Security scan results Logging and Debugging \u00b6 1 2 3 4 5 6 # Access build logs gh run list --workflow = \"on_dockerfile_change.yml\" gh run view <run-id> --log # Debug specific job gh run view <run-id> --job = \"build-and-push-changed-dirs\" Troubleshooting \u00b6 Common Build Issues \u00b6 \"No changed directories detected\" 1 2 3 4 5 # Verify path filters git diff --name-only HEAD~1 HEAD | grep \"ops/docker/\" # Check workflow trigger paths cat .github/workflows/on_dockerfile_change.yml | grep -A5 \"paths:\" Docker build failures 1 2 3 4 5 # Check Dockerfile syntax docker build --no-cache ops/docker/rust-ci-runner/ # Verify build context ls -la ops/docker/rust-ci-runner/ Registry push failures 1 2 3 4 5 # Verify credentials docker login --username $DOCKER_USERNAME # Test manual push docker push webgrip/rust-ci-runner:test Matrix generation errors 1 2 3 # Debug matrix output - name : Debug Matrix run : echo '${{ needs.determine-changed-directories.outputs.matrix }}' Performance Issues \u00b6 Slow builds - Check for layer cache misses - Optimize Dockerfile ordering - Review base image sizes Resource limitations - Monitor GitHub Actions resource usage - Consider self-hosted runners for heavy builds - Implement build queue management Manual Build Procedures \u00b6 Emergency Manual Build \u00b6 If automated builds fail, you can manually build and push: 1 2 3 4 5 6 7 8 # Build specific image cd ops/docker/rust-ci-runner docker build -t webgrip/rust-ci-runner:manual . # Tag and push docker tag webgrip/rust-ci-runner:manual webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:manual Bulk Rebuild \u00b6 To rebuild all images: 1 2 3 4 5 6 7 8 9 10 11 12 # Build all images locally for dir in ops/docker/*/ ; do image_name = $( basename \" $dir \" ) echo \"Building $image_name ...\" docker build -t \"webgrip/ $image_name :rebuild\" \" $dir \" done # Push all images for dir in ops/docker/*/ ; do image_name = $( basename \" $dir \" ) docker push \"webgrip/ $image_name :rebuild\" done Configuration Management \u00b6 Workflow Updates \u00b6 To modify the build pipeline: Test changes locally using ACT Runner Create feature branch for workflow changes Test in staging before merging to main Monitor first builds after changes Adding New Images \u00b6 To add a new Docker image to the automated pipeline: Create image directory : ops/docker/new-image/ Add Dockerfile : Follow existing patterns Test locally : Verify build works Commit changes : Pipeline will automatically detect and build No workflow changes needed - the change detection system automatically includes new directories. Secrets Management \u00b6 Required secrets for the pipeline: Secret Purpose Where to Set DOCKER_USERNAME Docker Hub authentication GitHub org secrets DOCKER_TOKEN Docker Hub push token GitHub org secrets Related Documentation \u00b6 Architecture Overview - How CI/CD fits into our infrastructure Docker Registry - Registry configuration and management Workflow Details - Detailed workflow breakdown ACT Runner - Local testing of workflows Maintenance \u00b6 Regular Maintenance Tasks \u00b6 Weekly : - Review build success rates - Check for security vulnerabilities - Monitor image sizes Monthly : - Update base images - Review workflow performance - Clean up old image tags Quarterly : - Audit secrets and permissions - Review and optimize build times - Update reusable workflows Update Procedures \u00b6 Workflow Updates : 1. Test with ACT locally 2. Deploy to feature branch 3. Monitor initial builds 4. Merge to main Image Updates : 1. Update Dockerfile 2. Test local build 3. Commit to trigger pipeline 4. Verify published image Assumption : Builds primarily target x86_64 architecture. Multi-architecture builds (ARM64, etc.) may require additional configuration in the reusable workflows. Validation needed: Confirm architecture requirements with development teams. Maintainer : WebGrip Ops Team Source : .github/workflows/on_dockerfile_change.yml Dependencies : webgrip/workflows","title":"Automated Building"},{"location":"cicd/automated-building/#automated-building","text":"Our automated building system ensures that Docker images are built, tested, and published whenever changes are made to the infrastructure repository.","title":"Automated Building"},{"location":"cicd/automated-building/#overview","text":"The automated building pipeline provides: \u2705 Change-triggered builds - Only build images when their source code changes \u2705 Multi-platform support - Build for different architectures where needed \u2705 Automated publishing - Push images to Docker Hub with proper tagging \u2705 Efficient resource usage - Build only what's necessary using change detection \u2705 Parallel execution - Build multiple images simultaneously when possible","title":"Overview"},{"location":"cicd/automated-building/#architecture","text":"","title":"Architecture"},{"location":"cicd/automated-building/#build-trigger-flow","text":"flowchart TD PUSH[Developer Push] --> GH[GitHub Repository] GH --> DETECT[Change Detection Workflow] DETECT --> MATRIX[Build Matrix Generation] MATRIX --> PARALLEL[Parallel Build Jobs] PARALLEL --> BUILD1[Build Image 1] PARALLEL --> BUILD2[Build Image 2] PARALLEL --> BUILD3[Build Image N] BUILD1 --> PUSH1[Push to Registry] BUILD2 --> PUSH2[Push to Registry] BUILD3 --> PUSH3[Push to Registry] subgraph \"GitHub Actions\" WORKFLOW[on_dockerfile_change.yml] REUSABLE[webgrip/workflows] end DETECT --> WORKFLOW WORKFLOW --> REUSABLE","title":"Build Trigger Flow"},{"location":"cicd/automated-building/#change-detection-system","text":"flowchart LR subgraph \"Source Changes\" DOCKERFILE[Dockerfile Modified] CONTEXT[Build Context Changed] DEPS[Dependencies Updated] end subgraph \"Detection Logic\" PATH_FILTER[Path Filter: ops/docker/**] DIR_SCAN[Directory Scanner] MATRIX_GEN[Matrix Generator] end subgraph \"Build Execution\" STRATEGY[Build Strategy] PARALLEL_JOBS[Parallel Jobs] DOCKER_BUILD[Docker Build & Push] end DOCKERFILE --> PATH_FILTER CONTEXT --> PATH_FILTER DEPS --> PATH_FILTER PATH_FILTER --> DIR_SCAN DIR_SCAN --> MATRIX_GEN MATRIX_GEN --> STRATEGY STRATEGY --> PARALLEL_JOBS PARALLEL_JOBS --> DOCKER_BUILD","title":"Change Detection System"},{"location":"cicd/automated-building/#workflow-configuration","text":"","title":"Workflow Configuration"},{"location":"cicd/automated-building/#main-workflow-on_dockerfile_changeyml","text":"Located at .github/workflows/on_dockerfile_change.yml , this workflow: Triggers on pushes to main branch affecting ops/docker/** paths Detects changed directories using a reusable workflow Builds only the Docker images that have changes Publishes images with both :latest and :${{ github.sha }} tags 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name : '[Workflow] On Dockerfile Change' concurrency : group : push-${{ github.branch }} cancel-in-progress : true on : push : branches : [ main ] paths : [ 'ops/docker/**' ] jobs : determine-changed-directories : uses : webgrip/workflows/.github/workflows/determine-changed-directories.yml@ubuntu-latest with : inside-dir : 'ops/docker' build-and-push-changed-dirs : needs : [ determine-changed-directories ] if : needs.determine-changed-directories.outputs.matrix != '[]' strategy : fail-fast : false matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} uses : webgrip/workflows/.github/workflows/docker-build-and-push.yml@ubuntu-latest with : docker-context : ${{ matrix.path }} docker-file : Dockerfile docker-tags : | ${{ github.repository_owner }}/${{ matrix.basename }}:latest ${{ github.repository_owner }}/${{ matrix.basename }}:${{ github.sha }} secrets : DOCKER_USERNAME : ${{ secrets.DOCKER_USERNAME }} DOCKER_TOKEN : ${{ secrets.DOCKER_TOKEN }}","title":"Main Workflow: on_dockerfile_change.yml"},{"location":"cicd/automated-building/#reusable-workflows","text":"The pipeline leverages shared workflows from the webgrip/workflows repository:","title":"Reusable Workflows"},{"location":"cicd/automated-building/#change-detection-workflow","text":"Purpose : Identify which Docker image directories have changes Output : JSON matrix of changed directories for parallel building Logic : Compares current commit against previous commit","title":"Change Detection Workflow"},{"location":"cicd/automated-building/#docker-build-push-workflow","text":"Purpose : Build and publish individual Docker images Features : Multi-platform builds, layer caching, security scanning Outputs : Published images with proper tags","title":"Docker Build &amp; Push Workflow"},{"location":"cicd/automated-building/#build-process-details","text":"","title":"Build Process Details"},{"location":"cicd/automated-building/#change-detection-algorithm","text":"Path Filtering : Only triggers on changes to ops/docker/** Directory Scanning : Identifies which subdirectories contain changes Matrix Generation : Creates build matrix for parallel execution 1 2 3 4 5 # Example change detection logic changed_dirs = $( git diff --name-only HEAD~1 HEAD | grep '^ops/docker/' | cut -d '/' -f1-3 | sort -u )","title":"Change Detection Algorithm"},{"location":"cicd/automated-building/#build-matrix-example","text":"When multiple images are changed simultaneously: 1 2 3 4 5 6 7 8 9 10 11 12 { \"include\" : [ { \"path\" : \"ops/docker/rust-ci-runner\" , \"basename\" : \"rust-ci-runner\" }, { \"path\" : \"ops/docker/playwright-runner\" , \"basename\" : \"playwright-runner\" } ] }","title":"Build Matrix Example"},{"location":"cicd/automated-building/#docker-image-tagging-strategy","text":"Each successful build produces two tags: Tag Pattern Purpose Example :latest Latest stable version webgrip/rust-ci-runner:latest :${{ github.sha }} Specific commit version webgrip/rust-ci-runner:a1b2c3d4","title":"Docker Image Tagging Strategy"},{"location":"cicd/automated-building/#build-context-and-optimization","text":"Each Docker image build: Uses the correct context : Each image's subdirectory ( ops/docker/image-name/ ) Leverages layer caching : Docker layer caching for faster builds Optimizes build args : Build-time arguments for customization Implements security : Vulnerability scanning during build","title":"Build Context and Optimization"},{"location":"cicd/automated-building/#supported-images","text":"The pipeline automatically builds and publishes these images: Directory Image Name Purpose ops/docker/rust-ci-runner webgrip/rust-ci-runner Rust development environment ops/docker/github-runner webgrip/github-runner Self-hosted GitHub Actions runner ops/docker/helm-deploy webgrip/helm-deploy Kubernetes deployment tools ops/docker/playwright-runner webgrip/playwright-runner E2E testing environment ops/docker/act-runner webgrip/act-runner Local GitHub Actions testing ops/docker/rust-releaser webgrip/rust-releaser Release automation","title":"Supported Images"},{"location":"cicd/automated-building/#performance-optimizations","text":"","title":"Performance Optimizations"},{"location":"cicd/automated-building/#parallel-execution","text":"1 2 3 4 strategy : fail-fast : false # Continue building other images if one fails matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} Benefits : - Multiple images build simultaneously - Faster overall pipeline execution - Independent failure handling","title":"Parallel Execution"},{"location":"cicd/automated-building/#build-caching","text":"The pipeline implements several caching strategies: Docker Layer Caching : Reuse unchanged layers between builds Registry Caching : Pull existing layers from registry GitHub Actions Cache : Cache build contexts and dependencies","title":"Build Caching"},{"location":"cicd/automated-building/#resource-optimization","text":"Change Detection : Only build images with actual changes Concurrency Control : Prevent duplicate builds with cancel-in-progress Selective Triggers : Path-based triggering reduces unnecessary executions","title":"Resource Optimization"},{"location":"cicd/automated-building/#security-features","text":"","title":"Security Features"},{"location":"cicd/automated-building/#build-security","text":"Vulnerability Scanning : Images scanned during build process Secret Management : Build credentials stored as GitHub secrets Signed Images : Images signed for integrity verification Base Image Updates : Regular updates to base images for security patches","title":"Build Security"},{"location":"cicd/automated-building/#access-control","text":"1 2 3 secrets : DOCKER_USERNAME : ${{ secrets.DOCKER_USERNAME }} DOCKER_TOKEN : ${{ secrets.DOCKER_TOKEN }} Registry Access : Controlled via organization-level secrets Workflow Permissions : Minimal required permissions Branch Protection : Only builds from protected main branch","title":"Access Control"},{"location":"cicd/automated-building/#monitoring-and-observability","text":"","title":"Monitoring and Observability"},{"location":"cicd/automated-building/#build-status-tracking","text":"GitHub Actions UI : Real-time build status and logs Commit Status Checks : Build status visible on pull requests Notification Integration : Slack/email notifications for failures","title":"Build Status Tracking"},{"location":"cicd/automated-building/#build-metrics","text":"Track key metrics for pipeline health: Build Duration : Time to complete full pipeline Success Rate : Percentage of successful builds Image Size : Monitor image size growth over time Vulnerability Count : Security scan results","title":"Build Metrics"},{"location":"cicd/automated-building/#logging-and-debugging","text":"1 2 3 4 5 6 # Access build logs gh run list --workflow = \"on_dockerfile_change.yml\" gh run view <run-id> --log # Debug specific job gh run view <run-id> --job = \"build-and-push-changed-dirs\"","title":"Logging and Debugging"},{"location":"cicd/automated-building/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"cicd/automated-building/#common-build-issues","text":"\"No changed directories detected\" 1 2 3 4 5 # Verify path filters git diff --name-only HEAD~1 HEAD | grep \"ops/docker/\" # Check workflow trigger paths cat .github/workflows/on_dockerfile_change.yml | grep -A5 \"paths:\" Docker build failures 1 2 3 4 5 # Check Dockerfile syntax docker build --no-cache ops/docker/rust-ci-runner/ # Verify build context ls -la ops/docker/rust-ci-runner/ Registry push failures 1 2 3 4 5 # Verify credentials docker login --username $DOCKER_USERNAME # Test manual push docker push webgrip/rust-ci-runner:test Matrix generation errors 1 2 3 # Debug matrix output - name : Debug Matrix run : echo '${{ needs.determine-changed-directories.outputs.matrix }}'","title":"Common Build Issues"},{"location":"cicd/automated-building/#performance-issues","text":"Slow builds - Check for layer cache misses - Optimize Dockerfile ordering - Review base image sizes Resource limitations - Monitor GitHub Actions resource usage - Consider self-hosted runners for heavy builds - Implement build queue management","title":"Performance Issues"},{"location":"cicd/automated-building/#manual-build-procedures","text":"","title":"Manual Build Procedures"},{"location":"cicd/automated-building/#emergency-manual-build","text":"If automated builds fail, you can manually build and push: 1 2 3 4 5 6 7 8 # Build specific image cd ops/docker/rust-ci-runner docker build -t webgrip/rust-ci-runner:manual . # Tag and push docker tag webgrip/rust-ci-runner:manual webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:manual","title":"Emergency Manual Build"},{"location":"cicd/automated-building/#bulk-rebuild","text":"To rebuild all images: 1 2 3 4 5 6 7 8 9 10 11 12 # Build all images locally for dir in ops/docker/*/ ; do image_name = $( basename \" $dir \" ) echo \"Building $image_name ...\" docker build -t \"webgrip/ $image_name :rebuild\" \" $dir \" done # Push all images for dir in ops/docker/*/ ; do image_name = $( basename \" $dir \" ) docker push \"webgrip/ $image_name :rebuild\" done","title":"Bulk Rebuild"},{"location":"cicd/automated-building/#configuration-management","text":"","title":"Configuration Management"},{"location":"cicd/automated-building/#workflow-updates","text":"To modify the build pipeline: Test changes locally using ACT Runner Create feature branch for workflow changes Test in staging before merging to main Monitor first builds after changes","title":"Workflow Updates"},{"location":"cicd/automated-building/#adding-new-images","text":"To add a new Docker image to the automated pipeline: Create image directory : ops/docker/new-image/ Add Dockerfile : Follow existing patterns Test locally : Verify build works Commit changes : Pipeline will automatically detect and build No workflow changes needed - the change detection system automatically includes new directories.","title":"Adding New Images"},{"location":"cicd/automated-building/#secrets-management","text":"Required secrets for the pipeline: Secret Purpose Where to Set DOCKER_USERNAME Docker Hub authentication GitHub org secrets DOCKER_TOKEN Docker Hub push token GitHub org secrets","title":"Secrets Management"},{"location":"cicd/automated-building/#related-documentation","text":"Architecture Overview - How CI/CD fits into our infrastructure Docker Registry - Registry configuration and management Workflow Details - Detailed workflow breakdown ACT Runner - Local testing of workflows","title":"Related Documentation"},{"location":"cicd/automated-building/#maintenance","text":"","title":"Maintenance"},{"location":"cicd/automated-building/#regular-maintenance-tasks","text":"Weekly : - Review build success rates - Check for security vulnerabilities - Monitor image sizes Monthly : - Update base images - Review workflow performance - Clean up old image tags Quarterly : - Audit secrets and permissions - Review and optimize build times - Update reusable workflows","title":"Regular Maintenance Tasks"},{"location":"cicd/automated-building/#update-procedures","text":"Workflow Updates : 1. Test with ACT locally 2. Deploy to feature branch 3. Monitor initial builds 4. Merge to main Image Updates : 1. Update Dockerfile 2. Test local build 3. Commit to trigger pipeline 4. Verify published image Assumption : Builds primarily target x86_64 architecture. Multi-architecture builds (ARM64, etc.) may require additional configuration in the reusable workflows. Validation needed: Confirm architecture requirements with development teams. Maintainer : WebGrip Ops Team Source : .github/workflows/on_dockerfile_change.yml Dependencies : webgrip/workflows","title":"Update Procedures"},{"location":"cicd/docker-registry/","text":"Docker Registry \u00b6 Our Docker Registry strategy and configuration for storing and distributing infrastructure container images. Overview \u00b6 WebGrip uses Docker Hub as the primary registry for hosting our infrastructure container images, providing: \u2705 Public accessibility for all team members and CI/CD systems \u2705 Automated pushing from GitHub Actions workflows \u2705 Version management with semantic tagging strategies \u2705 Security scanning and vulnerability management \u2705 Global CDN for fast image pulls worldwide Registry Configuration \u00b6 Docker Hub Organization \u00b6 Organization : webgrip Visibility : Public repositories Access Control : Organization-managed credentials Image Repositories \u00b6 Repository Purpose Latest Size Tags webgrip/rust-ci-runner Rust development environment ~800MB latest , commit SHAs webgrip/github-runner Self-hosted GitHub Actions runner ~500MB latest , commit SHAs webgrip/helm-deploy Kubernetes deployment tools ~150MB latest , commit SHAs webgrip/playwright-runner E2E testing environment ~2GB latest , commit SHAs webgrip/act-runner Local GitHub Actions testing ~100MB latest , commit SHAs webgrip/rust-releaser Release automation ~2GB latest , commit SHAs Tagging Strategy \u00b6 Standard Tags \u00b6 Every successful build produces consistent tags: 1 2 3 4 5 # Latest stable version (moves with each build) webgrip/rust-ci-runner:latest # Specific commit version (immutable) webgrip/rust-ci-runner:a1b2c3d4567890abcdef1234567890abcdef1234 Semantic Versioning (Future) \u00b6 For stable releases, we plan to implement semantic versioning: 1 2 3 4 5 6 7 8 # Major.Minor.Patch versions webgrip/rust-ci-runner:1.0.0 webgrip/rust-ci-runner:1.0.1 webgrip/rust-ci-runner:1.1.0 # Pre-release versions webgrip/rust-ci-runner:2.0.0-beta.1 webgrip/rust-ci-runner:2.0.0-rc.1 Tag Lifecycle \u00b6 flowchart TD COMMIT[Git Commit] --> BUILD[Automated Build] BUILD --> SHA_TAG[Create SHA Tag] BUILD --> LATEST_TAG[Update Latest Tag] SHA_TAG --> IMMUTABLE[Immutable Reference] LATEST_TAG --> MOVING[Moving Reference] IMMUTABLE --> LONG_TERM[Long-term Storage] MOVING --> CURRENT[Current Version] subgraph \"Tag Retention\" LONG_TERM --> CLEANUP[Cleanup Old SHAs] CURRENT --> ALWAYS[Always Available] end Authentication and Access \u00b6 Registry Credentials \u00b6 Access to push images is controlled via GitHub organization secrets: Secret Purpose Access Level DOCKER_USERNAME Docker Hub username Organization-wide DOCKER_TOKEN Docker Hub access token Organization-wide Access Patterns \u00b6 1 2 3 4 5 6 7 8 9 # CI/CD Push Access - name : Login to Docker Hub uses : docker/login-action@v2 with : username : ${{ secrets.DOCKER_USERNAME }} password : ${{ secrets.DOCKER_TOKEN }} # Public Pull Access (no authentication required) docker pull webgrip/rust-ci-runner:latest Permission Model \u00b6 flowchart LR subgraph \"GitHub Organization\" ORG_SECRETS[Organization Secrets] WORKFLOWS[GitHub Actions Workflows] end subgraph \"Docker Hub\" WEBGRIP_ORG[webgrip Organization] REPOSITORIES[Image Repositories] end subgraph \"Users\" DEVELOPERS[Developers - Pull Only] CI_CD[CI/CD - Push Access] PUBLIC[Public - Pull Only] end ORG_SECRETS --> WORKFLOWS WORKFLOWS --> CI_CD CI_CD --> WEBGRIP_ORG WEBGRIP_ORG --> REPOSITORIES DEVELOPERS --> REPOSITORIES PUBLIC --> REPOSITORIES Image Management \u00b6 Build and Push Process \u00b6 The automated pipeline follows this sequence: Change Detection : Identify modified Docker images Parallel Building : Build changed images simultaneously Security Scanning : Scan for vulnerabilities Registry Push : Upload with both tags Cleanup : Remove temporary build artifacts sequenceDiagram participant Dev as Developer participant GH as GitHub participant Actions as GitHub Actions participant Registry as Docker Hub Dev->>GH: Push Dockerfile changes GH->>Actions: Trigger workflow Actions->>Actions: Build image Actions->>Actions: Security scan Actions->>Registry: docker login Actions->>Registry: docker push image:latest Actions->>Registry: docker push image:sha Registry->>Registry: Update repository Image Size Optimization \u00b6 We implement several strategies to keep images small: Multi-stage Builds \u00b6 1 2 3 4 5 6 # Example from rust-ci-runner FROM rust:1.87.0-slim-bookworm AS build # ... build tools and dependencies FROM debian:bookworm-slim AS final # ... copy only necessary artifacts Layer Optimization \u00b6 1 2 3 4 5 # Combine RUN commands to reduce layers RUN apt-get update -qq && \\ apt-get install -y --no-install-recommends \\ ca-certificates build-essential && \\ rm -rf /var/lib/apt/lists/* Base Image Selection \u00b6 Alpine Linux : For minimal footprint ( act-runner , helm-deploy ) Debian Slim : For compatibility ( rust-ci-runner ) Official Images : For feature completeness ( playwright-runner ) Registry Storage Management \u00b6 Automated Cleanup \u00b6 Current State : Manual cleanup of old SHA tags Planned : Automated retention policies 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Manual cleanup script (planned automation) #!/bin/bash # Keep last 50 SHA tags, remove older ones docker_tags = $( curl -s \"https://hub.docker.com/v2/repositories/webgrip/rust-ci-runner/tags/\" | \\ jq -r '.results[].name' | \\ grep -E '^[a-f0-9]{40}$' | \\ tail -n +51 ) for tag in $docker_tags ; do # Delete old SHA tags curl -X DELETE \\ -H \"Authorization: Bearer $DOCKER_TOKEN \" \\ \"https://hub.docker.com/v2/repositories/webgrip/rust-ci-runner/tags/ $tag /\" done Storage Monitoring \u00b6 Track registry usage metrics: Total storage : Sum of all image layers across repositories Bandwidth usage : Download statistics for optimization Tag proliferation : Number of tags per repository Security and Compliance \u00b6 Image Security Scanning \u00b6 Images are scanned for vulnerabilities during the build process: 1 2 3 4 5 6 # Security scanning in CI pipeline - name : Scan image for vulnerabilities uses : docker/scout-action@v1 with : command : cves image : webgrip/rust-ci-runner:latest Vulnerability Management \u00b6 flowchart TD BUILD[Image Build] --> SCAN[Security Scan] SCAN --> CRITICAL{Critical Vulns?} CRITICAL -->|Yes| BLOCK[Block Release] CRITICAL -->|No| HIGH{High Vulns?} HIGH -->|Yes| WARN[Warning + Release] HIGH -->|No| PASS[Pass + Release] BLOCK --> FIX[Fix Vulnerabilities] FIX --> BUILD WARN --> TRACK[Track for Next Release] PASS --> RELEASE[Release to Registry] Supply Chain Security \u00b6 Base Image Verification : Use official, signed base images Dependency Scanning : Scan package dependencies for vulnerabilities SBOM Generation : Generate Software Bill of Materials Image Signing : Plan to implement image signing with cosign Access Security \u00b6 Token Rotation : Regular rotation of Docker Hub access tokens Least Privilege : Minimal permissions for CI/CD access Audit Logging : Track all registry access and modifications Performance and Optimization \u00b6 Pull Performance \u00b6 Optimize image pull times through: Layer Caching Strategy \u00b6 1 2 3 4 5 6 # Order layers by change frequency (least to most) COPY requirements.txt . RUN pip install -r requirements.txt # Changes infrequently COPY . . # Changes frequently RUN python setup.py install # Changes frequently Registry Proximity \u00b6 Global CDN : Docker Hub provides global edge locations Regional Caching : Consider additional registry mirrors for high-usage regions Build Performance \u00b6 Parallel Builds \u00b6 1 2 3 4 5 6 7 8 9 10 strategy : matrix : image : [ rust-ci-runner , playwright-runner , helm-deploy ] jobs : build : runs-on : ubuntu-latest steps : - name : Build ${{ matrix.image }} run : docker build ops/docker/${{ matrix.image }} Build Cache Optimization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 - name : Setup Docker Buildx uses : docker/setup-buildx-action@v2 with : driver-opts : | image=moby/buildkit:master network=host - name : Build with cache uses : docker/build-push-action@v4 with : cache-from : type=gha cache-to : type=gha,mode=max Monitoring and Alerting \u00b6 Registry Health Monitoring \u00b6 Track key metrics for registry health: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Example monitoring checks registry_metrics : - name : \"Image pull success rate\" threshold : \"> 99%\" - name : \"Average pull time\" threshold : \"< 30s\" - name : \"Storage usage growth\" threshold : \"< 10% per month\" - name : \"Security scan pass rate\" threshold : \"> 95%\" Alerting Configuration \u00b6 Critical Alerts : - Registry authentication failures - Critical security vulnerabilities detected - Registry storage quota exceeded Warning Alerts : - Slow image pull times - High vulnerability counts - Unusual download patterns Backup and Disaster Recovery \u00b6 Backup Strategy \u00b6 flowchart TD REGISTRY[Docker Hub Registry] --> MIRROR[Mirror Registry] REGISTRY --> LOCAL[Local Backup] REGISTRY --> REBUILD[Source-based Rebuild] subgraph \"Recovery Options\" MIRROR --> RESTORE1[Quick Restore] LOCAL --> RESTORE2[Offline Restore] REBUILD --> RESTORE3[Clean Rebuild] end Recovery Procedures \u00b6 Quick Recovery (Mirror Registry) \u00b6 1 2 3 4 # Pull from backup registry docker pull backup-registry.com/webgrip/rust-ci-runner:latest docker tag backup-registry.com/webgrip/rust-ci-runner:latest webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:latest Source-based Recovery \u00b6 1 2 3 4 # Rebuild from source git clone https://github.com/webgrip/infrastructure cd infrastructure make rebuild-all-images Local Backup Recovery \u00b6 1 2 3 # Restore from local backup docker load < backups/webgrip-rust-ci-runner-latest.tar docker push webgrip/rust-ci-runner:latest Future Improvements \u00b6 Planned Enhancements \u00b6 Multi-architecture Builds : Support ARM64 and other architectures Private Registry : Consider private registry for sensitive images Image Signing : Implement cosign for image verification Automated Cleanup : Implement automated tag retention policies Registry Mirrors : Deploy regional mirrors for faster access Migration Considerations \u00b6 To Private Registry : - Update authentication mechanisms - Modify CI/CD workflows - Update documentation and access patterns To Multi-registry Strategy : - Implement registry selection logic - Add failover mechanisms - Update monitoring and alerting Troubleshooting \u00b6 Common Issues \u00b6 \"Authentication failed\" errors 1 2 3 4 5 # Verify credentials docker login --username $DOCKER_USERNAME # Test with docker command echo $DOCKER_TOKEN | docker login --username $DOCKER_USERNAME --password-stdin Image pull failures 1 2 3 4 5 6 # Check image exists docker manifest inspect webgrip/rust-ci-runner:latest # Try different tag docker pull webgrip/rust-ci-runner:latest docker pull webgrip/rust-ci-runner: $( git rev-parse HEAD ) Large image sizes 1 2 3 4 5 # Analyze image layers docker history webgrip/rust-ci-runner:latest # Use dive for detailed analysis dive webgrip/rust-ci-runner:latest Registry quota exceeded 1 2 3 4 5 6 # Check registry usage curl -s -H \"Authorization: Bearer $DOCKER_TOKEN \" \\ \"https://hub.docker.com/v2/repositories/webgrip/?page_size=100\" # Clean up old images # (See automated cleanup script above) Related Documentation \u00b6 Automated Building - How images are built and pushed Workflow Details - Detailed CI/CD workflow information Architecture Overview - Registry role in infrastructure Docker Images - Individual image documentation Assumption : Docker Hub public repositories meet current needs. Future growth may require private registries or multi-cloud registry strategy. Validation needed: Confirm long-term registry strategy with infrastructure team. Maintainer : WebGrip Ops Team Registry : Docker Hub webgrip organization Authentication : Organization-level GitHub secrets","title":"Docker Registry"},{"location":"cicd/docker-registry/#docker-registry","text":"Our Docker Registry strategy and configuration for storing and distributing infrastructure container images.","title":"Docker Registry"},{"location":"cicd/docker-registry/#overview","text":"WebGrip uses Docker Hub as the primary registry for hosting our infrastructure container images, providing: \u2705 Public accessibility for all team members and CI/CD systems \u2705 Automated pushing from GitHub Actions workflows \u2705 Version management with semantic tagging strategies \u2705 Security scanning and vulnerability management \u2705 Global CDN for fast image pulls worldwide","title":"Overview"},{"location":"cicd/docker-registry/#registry-configuration","text":"","title":"Registry Configuration"},{"location":"cicd/docker-registry/#docker-hub-organization","text":"Organization : webgrip Visibility : Public repositories Access Control : Organization-managed credentials","title":"Docker Hub Organization"},{"location":"cicd/docker-registry/#image-repositories","text":"Repository Purpose Latest Size Tags webgrip/rust-ci-runner Rust development environment ~800MB latest , commit SHAs webgrip/github-runner Self-hosted GitHub Actions runner ~500MB latest , commit SHAs webgrip/helm-deploy Kubernetes deployment tools ~150MB latest , commit SHAs webgrip/playwright-runner E2E testing environment ~2GB latest , commit SHAs webgrip/act-runner Local GitHub Actions testing ~100MB latest , commit SHAs webgrip/rust-releaser Release automation ~2GB latest , commit SHAs","title":"Image Repositories"},{"location":"cicd/docker-registry/#tagging-strategy","text":"","title":"Tagging Strategy"},{"location":"cicd/docker-registry/#standard-tags","text":"Every successful build produces consistent tags: 1 2 3 4 5 # Latest stable version (moves with each build) webgrip/rust-ci-runner:latest # Specific commit version (immutable) webgrip/rust-ci-runner:a1b2c3d4567890abcdef1234567890abcdef1234","title":"Standard Tags"},{"location":"cicd/docker-registry/#semantic-versioning-future","text":"For stable releases, we plan to implement semantic versioning: 1 2 3 4 5 6 7 8 # Major.Minor.Patch versions webgrip/rust-ci-runner:1.0.0 webgrip/rust-ci-runner:1.0.1 webgrip/rust-ci-runner:1.1.0 # Pre-release versions webgrip/rust-ci-runner:2.0.0-beta.1 webgrip/rust-ci-runner:2.0.0-rc.1","title":"Semantic Versioning (Future)"},{"location":"cicd/docker-registry/#tag-lifecycle","text":"flowchart TD COMMIT[Git Commit] --> BUILD[Automated Build] BUILD --> SHA_TAG[Create SHA Tag] BUILD --> LATEST_TAG[Update Latest Tag] SHA_TAG --> IMMUTABLE[Immutable Reference] LATEST_TAG --> MOVING[Moving Reference] IMMUTABLE --> LONG_TERM[Long-term Storage] MOVING --> CURRENT[Current Version] subgraph \"Tag Retention\" LONG_TERM --> CLEANUP[Cleanup Old SHAs] CURRENT --> ALWAYS[Always Available] end","title":"Tag Lifecycle"},{"location":"cicd/docker-registry/#authentication-and-access","text":"","title":"Authentication and Access"},{"location":"cicd/docker-registry/#registry-credentials","text":"Access to push images is controlled via GitHub organization secrets: Secret Purpose Access Level DOCKER_USERNAME Docker Hub username Organization-wide DOCKER_TOKEN Docker Hub access token Organization-wide","title":"Registry Credentials"},{"location":"cicd/docker-registry/#access-patterns","text":"1 2 3 4 5 6 7 8 9 # CI/CD Push Access - name : Login to Docker Hub uses : docker/login-action@v2 with : username : ${{ secrets.DOCKER_USERNAME }} password : ${{ secrets.DOCKER_TOKEN }} # Public Pull Access (no authentication required) docker pull webgrip/rust-ci-runner:latest","title":"Access Patterns"},{"location":"cicd/docker-registry/#permission-model","text":"flowchart LR subgraph \"GitHub Organization\" ORG_SECRETS[Organization Secrets] WORKFLOWS[GitHub Actions Workflows] end subgraph \"Docker Hub\" WEBGRIP_ORG[webgrip Organization] REPOSITORIES[Image Repositories] end subgraph \"Users\" DEVELOPERS[Developers - Pull Only] CI_CD[CI/CD - Push Access] PUBLIC[Public - Pull Only] end ORG_SECRETS --> WORKFLOWS WORKFLOWS --> CI_CD CI_CD --> WEBGRIP_ORG WEBGRIP_ORG --> REPOSITORIES DEVELOPERS --> REPOSITORIES PUBLIC --> REPOSITORIES","title":"Permission Model"},{"location":"cicd/docker-registry/#image-management","text":"","title":"Image Management"},{"location":"cicd/docker-registry/#build-and-push-process","text":"The automated pipeline follows this sequence: Change Detection : Identify modified Docker images Parallel Building : Build changed images simultaneously Security Scanning : Scan for vulnerabilities Registry Push : Upload with both tags Cleanup : Remove temporary build artifacts sequenceDiagram participant Dev as Developer participant GH as GitHub participant Actions as GitHub Actions participant Registry as Docker Hub Dev->>GH: Push Dockerfile changes GH->>Actions: Trigger workflow Actions->>Actions: Build image Actions->>Actions: Security scan Actions->>Registry: docker login Actions->>Registry: docker push image:latest Actions->>Registry: docker push image:sha Registry->>Registry: Update repository","title":"Build and Push Process"},{"location":"cicd/docker-registry/#image-size-optimization","text":"We implement several strategies to keep images small:","title":"Image Size Optimization"},{"location":"cicd/docker-registry/#multi-stage-builds","text":"1 2 3 4 5 6 # Example from rust-ci-runner FROM rust:1.87.0-slim-bookworm AS build # ... build tools and dependencies FROM debian:bookworm-slim AS final # ... copy only necessary artifacts","title":"Multi-stage Builds"},{"location":"cicd/docker-registry/#layer-optimization","text":"1 2 3 4 5 # Combine RUN commands to reduce layers RUN apt-get update -qq && \\ apt-get install -y --no-install-recommends \\ ca-certificates build-essential && \\ rm -rf /var/lib/apt/lists/*","title":"Layer Optimization"},{"location":"cicd/docker-registry/#base-image-selection","text":"Alpine Linux : For minimal footprint ( act-runner , helm-deploy ) Debian Slim : For compatibility ( rust-ci-runner ) Official Images : For feature completeness ( playwright-runner )","title":"Base Image Selection"},{"location":"cicd/docker-registry/#registry-storage-management","text":"","title":"Registry Storage Management"},{"location":"cicd/docker-registry/#automated-cleanup","text":"Current State : Manual cleanup of old SHA tags Planned : Automated retention policies 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Manual cleanup script (planned automation) #!/bin/bash # Keep last 50 SHA tags, remove older ones docker_tags = $( curl -s \"https://hub.docker.com/v2/repositories/webgrip/rust-ci-runner/tags/\" | \\ jq -r '.results[].name' | \\ grep -E '^[a-f0-9]{40}$' | \\ tail -n +51 ) for tag in $docker_tags ; do # Delete old SHA tags curl -X DELETE \\ -H \"Authorization: Bearer $DOCKER_TOKEN \" \\ \"https://hub.docker.com/v2/repositories/webgrip/rust-ci-runner/tags/ $tag /\" done","title":"Automated Cleanup"},{"location":"cicd/docker-registry/#storage-monitoring","text":"Track registry usage metrics: Total storage : Sum of all image layers across repositories Bandwidth usage : Download statistics for optimization Tag proliferation : Number of tags per repository","title":"Storage Monitoring"},{"location":"cicd/docker-registry/#security-and-compliance","text":"","title":"Security and Compliance"},{"location":"cicd/docker-registry/#image-security-scanning","text":"Images are scanned for vulnerabilities during the build process: 1 2 3 4 5 6 # Security scanning in CI pipeline - name : Scan image for vulnerabilities uses : docker/scout-action@v1 with : command : cves image : webgrip/rust-ci-runner:latest","title":"Image Security Scanning"},{"location":"cicd/docker-registry/#vulnerability-management","text":"flowchart TD BUILD[Image Build] --> SCAN[Security Scan] SCAN --> CRITICAL{Critical Vulns?} CRITICAL -->|Yes| BLOCK[Block Release] CRITICAL -->|No| HIGH{High Vulns?} HIGH -->|Yes| WARN[Warning + Release] HIGH -->|No| PASS[Pass + Release] BLOCK --> FIX[Fix Vulnerabilities] FIX --> BUILD WARN --> TRACK[Track for Next Release] PASS --> RELEASE[Release to Registry]","title":"Vulnerability Management"},{"location":"cicd/docker-registry/#supply-chain-security","text":"Base Image Verification : Use official, signed base images Dependency Scanning : Scan package dependencies for vulnerabilities SBOM Generation : Generate Software Bill of Materials Image Signing : Plan to implement image signing with cosign","title":"Supply Chain Security"},{"location":"cicd/docker-registry/#access-security","text":"Token Rotation : Regular rotation of Docker Hub access tokens Least Privilege : Minimal permissions for CI/CD access Audit Logging : Track all registry access and modifications","title":"Access Security"},{"location":"cicd/docker-registry/#performance-and-optimization","text":"","title":"Performance and Optimization"},{"location":"cicd/docker-registry/#pull-performance","text":"Optimize image pull times through:","title":"Pull Performance"},{"location":"cicd/docker-registry/#layer-caching-strategy","text":"1 2 3 4 5 6 # Order layers by change frequency (least to most) COPY requirements.txt . RUN pip install -r requirements.txt # Changes infrequently COPY . . # Changes frequently RUN python setup.py install # Changes frequently","title":"Layer Caching Strategy"},{"location":"cicd/docker-registry/#registry-proximity","text":"Global CDN : Docker Hub provides global edge locations Regional Caching : Consider additional registry mirrors for high-usage regions","title":"Registry Proximity"},{"location":"cicd/docker-registry/#build-performance","text":"","title":"Build Performance"},{"location":"cicd/docker-registry/#parallel-builds","text":"1 2 3 4 5 6 7 8 9 10 strategy : matrix : image : [ rust-ci-runner , playwright-runner , helm-deploy ] jobs : build : runs-on : ubuntu-latest steps : - name : Build ${{ matrix.image }} run : docker build ops/docker/${{ matrix.image }}","title":"Parallel Builds"},{"location":"cicd/docker-registry/#build-cache-optimization","text":"1 2 3 4 5 6 7 8 9 10 11 12 - name : Setup Docker Buildx uses : docker/setup-buildx-action@v2 with : driver-opts : | image=moby/buildkit:master network=host - name : Build with cache uses : docker/build-push-action@v4 with : cache-from : type=gha cache-to : type=gha,mode=max","title":"Build Cache Optimization"},{"location":"cicd/docker-registry/#monitoring-and-alerting","text":"","title":"Monitoring and Alerting"},{"location":"cicd/docker-registry/#registry-health-monitoring","text":"Track key metrics for registry health: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Example monitoring checks registry_metrics : - name : \"Image pull success rate\" threshold : \"> 99%\" - name : \"Average pull time\" threshold : \"< 30s\" - name : \"Storage usage growth\" threshold : \"< 10% per month\" - name : \"Security scan pass rate\" threshold : \"> 95%\"","title":"Registry Health Monitoring"},{"location":"cicd/docker-registry/#alerting-configuration","text":"Critical Alerts : - Registry authentication failures - Critical security vulnerabilities detected - Registry storage quota exceeded Warning Alerts : - Slow image pull times - High vulnerability counts - Unusual download patterns","title":"Alerting Configuration"},{"location":"cicd/docker-registry/#backup-and-disaster-recovery","text":"","title":"Backup and Disaster Recovery"},{"location":"cicd/docker-registry/#backup-strategy","text":"flowchart TD REGISTRY[Docker Hub Registry] --> MIRROR[Mirror Registry] REGISTRY --> LOCAL[Local Backup] REGISTRY --> REBUILD[Source-based Rebuild] subgraph \"Recovery Options\" MIRROR --> RESTORE1[Quick Restore] LOCAL --> RESTORE2[Offline Restore] REBUILD --> RESTORE3[Clean Rebuild] end","title":"Backup Strategy"},{"location":"cicd/docker-registry/#recovery-procedures","text":"","title":"Recovery Procedures"},{"location":"cicd/docker-registry/#quick-recovery-mirror-registry","text":"1 2 3 4 # Pull from backup registry docker pull backup-registry.com/webgrip/rust-ci-runner:latest docker tag backup-registry.com/webgrip/rust-ci-runner:latest webgrip/rust-ci-runner:latest docker push webgrip/rust-ci-runner:latest","title":"Quick Recovery (Mirror Registry)"},{"location":"cicd/docker-registry/#source-based-recovery","text":"1 2 3 4 # Rebuild from source git clone https://github.com/webgrip/infrastructure cd infrastructure make rebuild-all-images","title":"Source-based Recovery"},{"location":"cicd/docker-registry/#local-backup-recovery","text":"1 2 3 # Restore from local backup docker load < backups/webgrip-rust-ci-runner-latest.tar docker push webgrip/rust-ci-runner:latest","title":"Local Backup Recovery"},{"location":"cicd/docker-registry/#future-improvements","text":"","title":"Future Improvements"},{"location":"cicd/docker-registry/#planned-enhancements","text":"Multi-architecture Builds : Support ARM64 and other architectures Private Registry : Consider private registry for sensitive images Image Signing : Implement cosign for image verification Automated Cleanup : Implement automated tag retention policies Registry Mirrors : Deploy regional mirrors for faster access","title":"Planned Enhancements"},{"location":"cicd/docker-registry/#migration-considerations","text":"To Private Registry : - Update authentication mechanisms - Modify CI/CD workflows - Update documentation and access patterns To Multi-registry Strategy : - Implement registry selection logic - Add failover mechanisms - Update monitoring and alerting","title":"Migration Considerations"},{"location":"cicd/docker-registry/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"cicd/docker-registry/#common-issues","text":"\"Authentication failed\" errors 1 2 3 4 5 # Verify credentials docker login --username $DOCKER_USERNAME # Test with docker command echo $DOCKER_TOKEN | docker login --username $DOCKER_USERNAME --password-stdin Image pull failures 1 2 3 4 5 6 # Check image exists docker manifest inspect webgrip/rust-ci-runner:latest # Try different tag docker pull webgrip/rust-ci-runner:latest docker pull webgrip/rust-ci-runner: $( git rev-parse HEAD ) Large image sizes 1 2 3 4 5 # Analyze image layers docker history webgrip/rust-ci-runner:latest # Use dive for detailed analysis dive webgrip/rust-ci-runner:latest Registry quota exceeded 1 2 3 4 5 6 # Check registry usage curl -s -H \"Authorization: Bearer $DOCKER_TOKEN \" \\ \"https://hub.docker.com/v2/repositories/webgrip/?page_size=100\" # Clean up old images # (See automated cleanup script above)","title":"Common Issues"},{"location":"cicd/docker-registry/#related-documentation","text":"Automated Building - How images are built and pushed Workflow Details - Detailed CI/CD workflow information Architecture Overview - Registry role in infrastructure Docker Images - Individual image documentation Assumption : Docker Hub public repositories meet current needs. Future growth may require private registries or multi-cloud registry strategy. Validation needed: Confirm long-term registry strategy with infrastructure team. Maintainer : WebGrip Ops Team Registry : Docker Hub webgrip organization Authentication : Organization-level GitHub secrets","title":"Related Documentation"},{"location":"cicd/workflow-details/","text":"Workflow Details \u00b6 Detailed breakdown of our GitHub Actions workflows, their dependencies, and integration patterns. Overview \u00b6 Our CI/CD workflows are built on a foundation of reusable workflows from the webgrip/workflows repository, providing: \u2705 Standardized patterns across all WebGrip repositories \u2705 Centralized maintenance of common workflow logic \u2705 Consistent behavior for builds, tests, and deployments \u2705 Reduced duplication through reusable components \u2705 Version management of workflow dependencies Workflow Architecture \u00b6 Primary Workflow: Dockerfile Change Detection \u00b6 flowchart TD subgraph \"Main Repository\" TRIGGER[Push to main<br/>ops/docker/** changes] MAIN_WF[on_dockerfile_change.yml] end subgraph \"webgrip/workflows Repository\" DETECT_WF[determine-changed-directories.yml] BUILD_WF[docker-build-and-push.yml] end subgraph \"Execution Flow\" MATRIX[Build Matrix Generation] PARALLEL[Parallel Build Jobs] REGISTRY[Docker Registry Push] end TRIGGER --> MAIN_WF MAIN_WF --> DETECT_WF DETECT_WF --> MATRIX MATRIX --> BUILD_WF BUILD_WF --> PARALLEL PARALLEL --> REGISTRY Workflow Dependencies \u00b6 flowchart LR subgraph \"Infrastructure Repo\" ON_CHANGE[on_dockerfile_change.yml] end subgraph \"webgrip/workflows Repo\" DETECT[determine-changed-directories] BUILD[docker-build-and-push] COMMON[common-actions] end subgraph \"External Dependencies\" DOCKER_HUB[Docker Hub Registry] GITHUB_API[GitHub API] ACTION_MARKETPLACE[GitHub Actions Marketplace] end ON_CHANGE --> DETECT ON_CHANGE --> BUILD DETECT --> COMMON BUILD --> COMMON BUILD --> DOCKER_HUB DETECT --> GITHUB_API COMMON --> ACTION_MARKETPLACE Workflow Breakdown \u00b6 1. Trigger Configuration \u00b6 1 2 3 4 5 # .github/workflows/on_dockerfile_change.yml on : push : branches : [ main ] paths : [ 'ops/docker/**' ] Trigger Logic : - Branch Filter : Only main branch pushes - Path Filter : Only changes to ops/docker/** - File Types : Any file changes in Docker image directories Concurrency Control : 1 2 3 concurrency : group : push-${{ github.branch }} cancel-in-progress : true 2. Change Detection Job \u00b6 1 2 3 4 determine-changed-directories : uses : webgrip/workflows/.github/workflows/determine-changed-directories.yml@ubuntu-latest with : inside-dir : 'ops/docker' Purpose : Identify which Docker image directories contain changes Inputs : - inside-dir : Directory to scan for changes ( ops/docker ) Outputs : - matrix : JSON array of changed directories for parallel building Algorithm : 1. Compare current commit with previous commit 2. Filter changes to specified directory 3. Group changes by subdirectory 4. Generate matrix for parallel execution 3. Build and Push Job \u00b6 1 2 3 4 5 6 7 8 build-and-push-changed-dirs : needs : [ determine-changed-directories ] if : needs.determine-changed-directories.outputs.matrix != '[]' strategy : fail-fast : false matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} uses : webgrip/workflows/.github/workflows/docker-build-and-push.yml@ubuntu-latest Conditional Execution : Only runs if changes detected Parallel Strategy : - fail-fast: false : Continue building other images if one fails - Dynamic matrix from change detection output Per-Image Inputs : 1 2 3 4 5 6 with : docker-context : ${{ matrix.path }} docker-file : Dockerfile docker-tags : | ${{ github.repository_owner }}/${{ matrix.basename }}:latest ${{ github.repository_owner }}/${{ matrix.basename }}:${{ github.sha }} Reusable Workflow Details \u00b6 determine-changed-directories.yml \u00b6 Location : webgrip/workflows/.github/workflows/determine-changed-directories.yml Purpose : Detect which directories have changes and create build matrix Inputs : | Input | Required | Description | Default | |-------|----------|-------------|---------| | inside-dir | Yes | Directory to scan for changes | N/A | | exclude-dirs | No | Directories to exclude | \"\" | Outputs : | Output | Description | Example | |--------|-------------|---------| | matrix | JSON build matrix | [{\"path\": \"ops/docker/rust-ci\", \"basename\": \"rust-ci\"}] | | changed-count | Number of changed directories | 2 | Implementation Logic : 1 2 3 4 5 6 # Simplified logic git diff --name-only HEAD~1 HEAD | \\ grep \"^ ${ inside_dir } /\" | \\ cut -d '/' -f1-3 | \\ sort -u | \\ jq -R -s 'split(\"\\n\") | map(select(length > 0)) | map({\"path\": ., \"basename\": split(\"/\")[-1]})' docker-build-and-push.yml \u00b6 Location : webgrip/workflows/.github/workflows/docker-build-and-push.yml Purpose : Build and push individual Docker images Inputs : | Input | Required | Description | Default | |-------|----------|-------------|---------| | docker-context | Yes | Build context directory | N/A | | docker-file | No | Dockerfile name | Dockerfile | | docker-tags | Yes | Newline-separated tags | N/A | | platforms | No | Target platforms | linux/amd64 | | build-args | No | Build arguments | \"\" | Secrets : | Secret | Required | Description | |--------|----------|-------------| | DOCKER_USERNAME | Yes | Docker Hub username | | DOCKER_TOKEN | Yes | Docker Hub access token | Workflow Steps : 1. Checkout : Source code checkout 2. Setup : Docker Buildx setup for advanced features 3. Login : Authenticate with Docker registry 4. Build : Build image with specified context and tags 5. Push : Push to registry with all specified tags 6. Cleanup : Clean up build artifacts Advanced Workflow Features \u00b6 Multi-Platform Builds \u00b6 1 2 3 4 5 6 7 8 9 # Example multi-platform configuration with : docker-context : ops/docker/rust-ci-runner platforms : | linux/amd64 linux/arm64 docker-tags : | webgrip/rust-ci-runner:latest webgrip/rust-ci-runner:${{ github.sha }} Supported Platforms : - linux/amd64 - Intel/AMD 64-bit (primary) - linux/arm64 - ARM 64-bit (experimental) - linux/arm/v7 - ARM 32-bit (on request) Build Arguments \u00b6 1 2 3 4 5 6 # Pass build-time arguments with : build-args : | RUST_VERSION=1.87.0 NODE_VERSION=20 BUILD_DATE=${{ github.event.head_commit.timestamp }} Registry Configuration \u00b6 1 2 3 4 5 6 7 8 9 # Alternative registry configuration with : registry : ghcr.io docker-tags : | ghcr.io/webgrip/rust-ci-runner:latest ghcr.io/webgrip/rust-ci-runner:${{ github.sha }} secrets : DOCKER_USERNAME : ${{ github.actor }} DOCKER_TOKEN : ${{ secrets.GITHUB_TOKEN }} Workflow Security \u00b6 Secret Management \u00b6 flowchart TD subgraph \"GitHub Organization\" ORG_SECRETS[Organization Secrets] REPO_SECRETS[Repository Secrets] end subgraph \"Workflow Execution\" WF_CONTEXT[Workflow Context] JOB_CONTEXT[Job Context] end subgraph \"External Services\" DOCKER_HUB[Docker Hub] REGISTRIES[Other Registries] end ORG_SECRETS --> WF_CONTEXT REPO_SECRETS --> WF_CONTEXT WF_CONTEXT --> JOB_CONTEXT JOB_CONTEXT --> DOCKER_HUB JOB_CONTEXT --> REGISTRIES Permission Model \u00b6 Workflow Permissions : 1 2 3 4 permissions : contents : read # Read repository contents packages : write # Push to GitHub Packages (if needed) actions : read # Read workflow status Secret Access : - Organization Level : DOCKER_USERNAME , DOCKER_TOKEN - Repository Level : Project-specific secrets - Environment Level : Environment-specific overrides Security Best Practices \u00b6 Minimal Permissions : Workflows use least-privilege access Secret Rotation : Regular rotation of access tokens Audit Logging : All workflow executions logged and auditable Branch Protection : Only protected branches can trigger builds Workflow Monitoring \u00b6 Execution Tracking \u00b6 1 2 3 4 5 6 7 # Built-in monitoring via GitHub Actions - name : Report build status if : always() run : | echo \"Workflow: ${{ github.workflow }}\" echo \"Run ID: ${{ github.run_id }}\" echo \"Status: ${{ job.status }}\" Performance Metrics \u00b6 Track key workflow performance indicators: Metric Target Current Monitoring Build Time < 10 minutes ~5 minutes GitHub Actions UI Success Rate > 95% ~98% Workflow status API Parallel Efficiency > 80% ~85% Job duration analysis Cache Hit Rate > 70% ~75% Build logs analysis Alerting Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 # Example workflow notification - name : Notify on failure if : failure() uses : 8398a7/action-slack@v3 with : status : failure webhook_url : ${{ secrets.SLACK_WEBHOOK }} message : | Docker build failed for ${{ matrix.basename }} Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }} Troubleshooting Workflows \u00b6 Common Issues \u00b6 Matrix generation empty 1 2 3 4 5 # Debug matrix output - name : Debug Matrix run : | echo \"Matrix: ${{ needs.determine-changed-directories.outputs.matrix }}\" echo \"Changed count: ${{ needs.determine-changed-directories.outputs.changed-count }}\" Build context errors 1 2 3 4 5 6 # Verify build context - name : List build context run : | echo \"Context: ${{ matrix.path }}\" ls -la ${{ matrix.path }}/ cat ${{ matrix.path }}/Dockerfile Registry authentication failures 1 2 3 4 5 6 # Test registry access - name : Test Docker login run : | echo \"Testing Docker Hub connection...\" docker info echo \"${{ secrets.DOCKER_TOKEN }}\" | docker login --username \"${{ secrets.DOCKER_USERNAME }}\" --password-stdin Workflow dependency issues 1 2 3 4 5 # Check reusable workflow versions - name : Check workflow versions run : | echo \"Using workflows from: webgrip/workflows@ubuntu-latest\" # Consider pinning to specific versions for stability Debugging Strategies \u00b6 Enable Debug Logging : 1 2 3 env : ACTIONS_STEP_DEBUG : true ACTIONS_RUNNER_DEBUG : true Add Debug Steps : 1 2 3 4 5 6 - name : Debug Environment run : | echo \"GitHub Context:\" echo \"${{ toJson(github) }}\" echo \"Matrix Context:\" echo \"${{ toJson(matrix) }}\" Local Testing : 1 2 3 4 # Use ACT for local workflow testing docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/on_dockerfile_change.yml Workflow Optimization \u00b6 Performance Improvements \u00b6 Build Caching : 1 2 3 4 5 6 7 8 9 10 - name : Setup Docker Buildx uses : docker/setup-buildx-action@v2 with : driver-opts : network=host - name : Build with cache uses : docker/build-push-action@v4 with : cache-from : type=gha cache-to : type=gha,mode=max Parallel Execution : 1 2 3 strategy : fail-fast : false max-parallel : 4 # Limit concurrent jobs Conditional Execution : 1 2 3 if : | needs.determine-changed-directories.outputs.matrix != '[]' && !contains(github.event.head_commit.message, '[skip ci]') Resource Optimization \u00b6 1 2 3 4 # Optimize runner resources runs-on : ubuntu-latest # Use GitHub-hosted runners # Consider self-hosted for heavy builds: # runs-on: [self-hosted, linux, x64] Future Enhancements \u00b6 Planned Improvements \u00b6 Workflow Versioning : Pin reusable workflows to specific versions Advanced Caching : Implement cross-workflow caching strategies Multi-Registry : Support multiple Docker registries Security Scanning : Integrate security scanning into workflows Notification Integration : Enhanced Slack/email notifications Workflow Evolution \u00b6 flowchart TD CURRENT[Current Workflow] --> VERSIONED[Versioned Workflows] VERSIONED --> CACHED[Advanced Caching] CACHED --> SECURITY[Security Integration] SECURITY --> MULTI_REG[Multi-Registry] MULTI_REG --> NOTIFICATIONS[Enhanced Notifications] subgraph \"Version 1.0\" CURRENT end subgraph \"Version 2.0\" VERSIONED CACHED end subgraph \"Version 3.0\" SECURITY MULTI_REG NOTIFICATIONS end Related Documentation \u00b6 Automated Building - High-level build process overview Docker Registry - Registry configuration and management ACT Runner - Local workflow testing Architecture Overview - CI/CD in our infrastructure Assumption : Reusable workflows from webgrip/workflows repository remain stable and backward-compatible. Major changes should be coordinated across all consuming repositories. Validation needed: Establish workflow versioning and compatibility policies. Maintainer : WebGrip Ops Team Source : .github/workflows/on_dockerfile_change.yml Dependencies : webgrip/workflows","title":"Workflow Details"},{"location":"cicd/workflow-details/#workflow-details","text":"Detailed breakdown of our GitHub Actions workflows, their dependencies, and integration patterns.","title":"Workflow Details"},{"location":"cicd/workflow-details/#overview","text":"Our CI/CD workflows are built on a foundation of reusable workflows from the webgrip/workflows repository, providing: \u2705 Standardized patterns across all WebGrip repositories \u2705 Centralized maintenance of common workflow logic \u2705 Consistent behavior for builds, tests, and deployments \u2705 Reduced duplication through reusable components \u2705 Version management of workflow dependencies","title":"Overview"},{"location":"cicd/workflow-details/#workflow-architecture","text":"","title":"Workflow Architecture"},{"location":"cicd/workflow-details/#primary-workflow-dockerfile-change-detection","text":"flowchart TD subgraph \"Main Repository\" TRIGGER[Push to main<br/>ops/docker/** changes] MAIN_WF[on_dockerfile_change.yml] end subgraph \"webgrip/workflows Repository\" DETECT_WF[determine-changed-directories.yml] BUILD_WF[docker-build-and-push.yml] end subgraph \"Execution Flow\" MATRIX[Build Matrix Generation] PARALLEL[Parallel Build Jobs] REGISTRY[Docker Registry Push] end TRIGGER --> MAIN_WF MAIN_WF --> DETECT_WF DETECT_WF --> MATRIX MATRIX --> BUILD_WF BUILD_WF --> PARALLEL PARALLEL --> REGISTRY","title":"Primary Workflow: Dockerfile Change Detection"},{"location":"cicd/workflow-details/#workflow-dependencies","text":"flowchart LR subgraph \"Infrastructure Repo\" ON_CHANGE[on_dockerfile_change.yml] end subgraph \"webgrip/workflows Repo\" DETECT[determine-changed-directories] BUILD[docker-build-and-push] COMMON[common-actions] end subgraph \"External Dependencies\" DOCKER_HUB[Docker Hub Registry] GITHUB_API[GitHub API] ACTION_MARKETPLACE[GitHub Actions Marketplace] end ON_CHANGE --> DETECT ON_CHANGE --> BUILD DETECT --> COMMON BUILD --> COMMON BUILD --> DOCKER_HUB DETECT --> GITHUB_API COMMON --> ACTION_MARKETPLACE","title":"Workflow Dependencies"},{"location":"cicd/workflow-details/#workflow-breakdown","text":"","title":"Workflow Breakdown"},{"location":"cicd/workflow-details/#1-trigger-configuration","text":"1 2 3 4 5 # .github/workflows/on_dockerfile_change.yml on : push : branches : [ main ] paths : [ 'ops/docker/**' ] Trigger Logic : - Branch Filter : Only main branch pushes - Path Filter : Only changes to ops/docker/** - File Types : Any file changes in Docker image directories Concurrency Control : 1 2 3 concurrency : group : push-${{ github.branch }} cancel-in-progress : true","title":"1. Trigger Configuration"},{"location":"cicd/workflow-details/#2-change-detection-job","text":"1 2 3 4 determine-changed-directories : uses : webgrip/workflows/.github/workflows/determine-changed-directories.yml@ubuntu-latest with : inside-dir : 'ops/docker' Purpose : Identify which Docker image directories contain changes Inputs : - inside-dir : Directory to scan for changes ( ops/docker ) Outputs : - matrix : JSON array of changed directories for parallel building Algorithm : 1. Compare current commit with previous commit 2. Filter changes to specified directory 3. Group changes by subdirectory 4. Generate matrix for parallel execution","title":"2. Change Detection Job"},{"location":"cicd/workflow-details/#3-build-and-push-job","text":"1 2 3 4 5 6 7 8 build-and-push-changed-dirs : needs : [ determine-changed-directories ] if : needs.determine-changed-directories.outputs.matrix != '[]' strategy : fail-fast : false matrix : include : ${{ fromJson(needs.determine-changed-directories.outputs.matrix) }} uses : webgrip/workflows/.github/workflows/docker-build-and-push.yml@ubuntu-latest Conditional Execution : Only runs if changes detected Parallel Strategy : - fail-fast: false : Continue building other images if one fails - Dynamic matrix from change detection output Per-Image Inputs : 1 2 3 4 5 6 with : docker-context : ${{ matrix.path }} docker-file : Dockerfile docker-tags : | ${{ github.repository_owner }}/${{ matrix.basename }}:latest ${{ github.repository_owner }}/${{ matrix.basename }}:${{ github.sha }}","title":"3. Build and Push Job"},{"location":"cicd/workflow-details/#reusable-workflow-details","text":"","title":"Reusable Workflow Details"},{"location":"cicd/workflow-details/#determine-changed-directoriesyml","text":"Location : webgrip/workflows/.github/workflows/determine-changed-directories.yml Purpose : Detect which directories have changes and create build matrix Inputs : | Input | Required | Description | Default | |-------|----------|-------------|---------| | inside-dir | Yes | Directory to scan for changes | N/A | | exclude-dirs | No | Directories to exclude | \"\" | Outputs : | Output | Description | Example | |--------|-------------|---------| | matrix | JSON build matrix | [{\"path\": \"ops/docker/rust-ci\", \"basename\": \"rust-ci\"}] | | changed-count | Number of changed directories | 2 | Implementation Logic : 1 2 3 4 5 6 # Simplified logic git diff --name-only HEAD~1 HEAD | \\ grep \"^ ${ inside_dir } /\" | \\ cut -d '/' -f1-3 | \\ sort -u | \\ jq -R -s 'split(\"\\n\") | map(select(length > 0)) | map({\"path\": ., \"basename\": split(\"/\")[-1]})'","title":"determine-changed-directories.yml"},{"location":"cicd/workflow-details/#docker-build-and-pushyml","text":"Location : webgrip/workflows/.github/workflows/docker-build-and-push.yml Purpose : Build and push individual Docker images Inputs : | Input | Required | Description | Default | |-------|----------|-------------|---------| | docker-context | Yes | Build context directory | N/A | | docker-file | No | Dockerfile name | Dockerfile | | docker-tags | Yes | Newline-separated tags | N/A | | platforms | No | Target platforms | linux/amd64 | | build-args | No | Build arguments | \"\" | Secrets : | Secret | Required | Description | |--------|----------|-------------| | DOCKER_USERNAME | Yes | Docker Hub username | | DOCKER_TOKEN | Yes | Docker Hub access token | Workflow Steps : 1. Checkout : Source code checkout 2. Setup : Docker Buildx setup for advanced features 3. Login : Authenticate with Docker registry 4. Build : Build image with specified context and tags 5. Push : Push to registry with all specified tags 6. Cleanup : Clean up build artifacts","title":"docker-build-and-push.yml"},{"location":"cicd/workflow-details/#advanced-workflow-features","text":"","title":"Advanced Workflow Features"},{"location":"cicd/workflow-details/#multi-platform-builds","text":"1 2 3 4 5 6 7 8 9 # Example multi-platform configuration with : docker-context : ops/docker/rust-ci-runner platforms : | linux/amd64 linux/arm64 docker-tags : | webgrip/rust-ci-runner:latest webgrip/rust-ci-runner:${{ github.sha }} Supported Platforms : - linux/amd64 - Intel/AMD 64-bit (primary) - linux/arm64 - ARM 64-bit (experimental) - linux/arm/v7 - ARM 32-bit (on request)","title":"Multi-Platform Builds"},{"location":"cicd/workflow-details/#build-arguments","text":"1 2 3 4 5 6 # Pass build-time arguments with : build-args : | RUST_VERSION=1.87.0 NODE_VERSION=20 BUILD_DATE=${{ github.event.head_commit.timestamp }}","title":"Build Arguments"},{"location":"cicd/workflow-details/#registry-configuration","text":"1 2 3 4 5 6 7 8 9 # Alternative registry configuration with : registry : ghcr.io docker-tags : | ghcr.io/webgrip/rust-ci-runner:latest ghcr.io/webgrip/rust-ci-runner:${{ github.sha }} secrets : DOCKER_USERNAME : ${{ github.actor }} DOCKER_TOKEN : ${{ secrets.GITHUB_TOKEN }}","title":"Registry Configuration"},{"location":"cicd/workflow-details/#workflow-security","text":"","title":"Workflow Security"},{"location":"cicd/workflow-details/#secret-management","text":"flowchart TD subgraph \"GitHub Organization\" ORG_SECRETS[Organization Secrets] REPO_SECRETS[Repository Secrets] end subgraph \"Workflow Execution\" WF_CONTEXT[Workflow Context] JOB_CONTEXT[Job Context] end subgraph \"External Services\" DOCKER_HUB[Docker Hub] REGISTRIES[Other Registries] end ORG_SECRETS --> WF_CONTEXT REPO_SECRETS --> WF_CONTEXT WF_CONTEXT --> JOB_CONTEXT JOB_CONTEXT --> DOCKER_HUB JOB_CONTEXT --> REGISTRIES","title":"Secret Management"},{"location":"cicd/workflow-details/#permission-model","text":"Workflow Permissions : 1 2 3 4 permissions : contents : read # Read repository contents packages : write # Push to GitHub Packages (if needed) actions : read # Read workflow status Secret Access : - Organization Level : DOCKER_USERNAME , DOCKER_TOKEN - Repository Level : Project-specific secrets - Environment Level : Environment-specific overrides","title":"Permission Model"},{"location":"cicd/workflow-details/#security-best-practices","text":"Minimal Permissions : Workflows use least-privilege access Secret Rotation : Regular rotation of access tokens Audit Logging : All workflow executions logged and auditable Branch Protection : Only protected branches can trigger builds","title":"Security Best Practices"},{"location":"cicd/workflow-details/#workflow-monitoring","text":"","title":"Workflow Monitoring"},{"location":"cicd/workflow-details/#execution-tracking","text":"1 2 3 4 5 6 7 # Built-in monitoring via GitHub Actions - name : Report build status if : always() run : | echo \"Workflow: ${{ github.workflow }}\" echo \"Run ID: ${{ github.run_id }}\" echo \"Status: ${{ job.status }}\"","title":"Execution Tracking"},{"location":"cicd/workflow-details/#performance-metrics","text":"Track key workflow performance indicators: Metric Target Current Monitoring Build Time < 10 minutes ~5 minutes GitHub Actions UI Success Rate > 95% ~98% Workflow status API Parallel Efficiency > 80% ~85% Job duration analysis Cache Hit Rate > 70% ~75% Build logs analysis","title":"Performance Metrics"},{"location":"cicd/workflow-details/#alerting-configuration","text":"1 2 3 4 5 6 7 8 9 10 # Example workflow notification - name : Notify on failure if : failure() uses : 8398a7/action-slack@v3 with : status : failure webhook_url : ${{ secrets.SLACK_WEBHOOK }} message : | Docker build failed for ${{ matrix.basename }} Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}","title":"Alerting Configuration"},{"location":"cicd/workflow-details/#troubleshooting-workflows","text":"","title":"Troubleshooting Workflows"},{"location":"cicd/workflow-details/#common-issues","text":"Matrix generation empty 1 2 3 4 5 # Debug matrix output - name : Debug Matrix run : | echo \"Matrix: ${{ needs.determine-changed-directories.outputs.matrix }}\" echo \"Changed count: ${{ needs.determine-changed-directories.outputs.changed-count }}\" Build context errors 1 2 3 4 5 6 # Verify build context - name : List build context run : | echo \"Context: ${{ matrix.path }}\" ls -la ${{ matrix.path }}/ cat ${{ matrix.path }}/Dockerfile Registry authentication failures 1 2 3 4 5 6 # Test registry access - name : Test Docker login run : | echo \"Testing Docker Hub connection...\" docker info echo \"${{ secrets.DOCKER_TOKEN }}\" | docker login --username \"${{ secrets.DOCKER_USERNAME }}\" --password-stdin Workflow dependency issues 1 2 3 4 5 # Check reusable workflow versions - name : Check workflow versions run : | echo \"Using workflows from: webgrip/workflows@ubuntu-latest\" # Consider pinning to specific versions for stability","title":"Common Issues"},{"location":"cicd/workflow-details/#debugging-strategies","text":"Enable Debug Logging : 1 2 3 env : ACTIONS_STEP_DEBUG : true ACTIONS_RUNNER_DEBUG : true Add Debug Steps : 1 2 3 4 5 6 - name : Debug Environment run : | echo \"GitHub Context:\" echo \"${{ toJson(github) }}\" echo \"Matrix Context:\" echo \"${{ toJson(matrix) }}\" Local Testing : 1 2 3 4 # Use ACT for local workflow testing docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/on_dockerfile_change.yml","title":"Debugging Strategies"},{"location":"cicd/workflow-details/#workflow-optimization","text":"","title":"Workflow Optimization"},{"location":"cicd/workflow-details/#performance-improvements","text":"Build Caching : 1 2 3 4 5 6 7 8 9 10 - name : Setup Docker Buildx uses : docker/setup-buildx-action@v2 with : driver-opts : network=host - name : Build with cache uses : docker/build-push-action@v4 with : cache-from : type=gha cache-to : type=gha,mode=max Parallel Execution : 1 2 3 strategy : fail-fast : false max-parallel : 4 # Limit concurrent jobs Conditional Execution : 1 2 3 if : | needs.determine-changed-directories.outputs.matrix != '[]' && !contains(github.event.head_commit.message, '[skip ci]')","title":"Performance Improvements"},{"location":"cicd/workflow-details/#resource-optimization","text":"1 2 3 4 # Optimize runner resources runs-on : ubuntu-latest # Use GitHub-hosted runners # Consider self-hosted for heavy builds: # runs-on: [self-hosted, linux, x64]","title":"Resource Optimization"},{"location":"cicd/workflow-details/#future-enhancements","text":"","title":"Future Enhancements"},{"location":"cicd/workflow-details/#planned-improvements","text":"Workflow Versioning : Pin reusable workflows to specific versions Advanced Caching : Implement cross-workflow caching strategies Multi-Registry : Support multiple Docker registries Security Scanning : Integrate security scanning into workflows Notification Integration : Enhanced Slack/email notifications","title":"Planned Improvements"},{"location":"cicd/workflow-details/#workflow-evolution","text":"flowchart TD CURRENT[Current Workflow] --> VERSIONED[Versioned Workflows] VERSIONED --> CACHED[Advanced Caching] CACHED --> SECURITY[Security Integration] SECURITY --> MULTI_REG[Multi-Registry] MULTI_REG --> NOTIFICATIONS[Enhanced Notifications] subgraph \"Version 1.0\" CURRENT end subgraph \"Version 2.0\" VERSIONED CACHED end subgraph \"Version 3.0\" SECURITY MULTI_REG NOTIFICATIONS end","title":"Workflow Evolution"},{"location":"cicd/workflow-details/#related-documentation","text":"Automated Building - High-level build process overview Docker Registry - Registry configuration and management ACT Runner - Local workflow testing Architecture Overview - CI/CD in our infrastructure Assumption : Reusable workflows from webgrip/workflows repository remain stable and backward-compatible. Major changes should be coordinated across all consuming repositories. Validation needed: Establish workflow versioning and compatibility policies. Maintainer : WebGrip Ops Team Source : .github/workflows/on_dockerfile_change.yml Dependencies : webgrip/workflows","title":"Related Documentation"},{"location":"docker-images/act-runner/","text":"ACT Runner \u00b6 A lightweight Alpine-based container for running GitHub Actions workflows locally using the ACT (Actions Container Toolkit) tool. Purpose \u00b6 The ACT Runner enables local GitHub Actions testing by providing: \u2705 Local workflow execution without pushing to GitHub \u2705 Fast iteration cycles for workflow development \u2705 Debugging capabilities for complex GitHub Actions \u2705 Cost reduction by testing locally before using GitHub Actions minutes \u2705 Offline development when internet connectivity is limited Image Details \u00b6 Property Value Base Image alpine:3.22.1 Size ~100MB (minimal Alpine + ACT + Docker CLI) Architecture AMD64 Registry webgrip/act-runner Dockerfile ops/docker/act-runner/Dockerfile Installed Tools \u00b6 Core Tools \u00b6 Tool Purpose Installation Method ACT GitHub Actions local runner Official install script Docker CLI Container management Alpine package Git Version control integration Alpine package Bash Shell scripting environment Alpine package curl HTTP client for API calls Alpine package System Components \u00b6 Alpine Linux 3.22.1 - Minimal, security-focused base OS Docker socket access - Required for running containerized actions Workspace directory - /workspace for project files Architecture \u00b6 Local Workflow Execution \u00b6 flowchart TD DEV[Developer] --> ACT_CMD[act command] ACT_CMD --> ACT_RUNNER[ACT Runner Container] ACT_RUNNER --> DOCKER_HOST[Docker Host] DOCKER_HOST --> ACTION_CONTAINERS[Action Containers] ACTION_CONTAINERS --> WORKSPACE[Workspace Volume] WORKSPACE --> RESULTS[Execution Results] RESULTS --> DEV subgraph \"ACT Runner Container\" ACT_BINARY[ACT Binary] DOCKER_CLI[Docker CLI] GIT[Git] end subgraph \"Action Execution\" CHECKOUT[actions/checkout] SETUP[actions/setup-*] CUSTOM[Custom Actions] SCRIPTS[Run Scripts] end ACT_RUNNER --> ACT_BINARY ACT_BINARY --> ACTION_EXECUTION ACTION_EXECUTION --> CHECKOUT ACTION_EXECUTION --> SETUP ACTION_EXECUTION --> CUSTOM ACTION_EXECUTION --> SCRIPTS Docker-in-Docker Pattern \u00b6 flowchart LR subgraph \"Host System\" DOCKER_DAEMON[Docker Daemon] HOST_WORKSPACE[Host Workspace] end subgraph \"ACT Runner Container\" ACT[ACT Process] DOCKER_CLI[Docker CLI] WORKSPACE_MOUNT[/workspace] end subgraph \"Action Containers\" UBUNTU[ubuntu-latest] NODE[actions/setup-node] CUSTOM_ACTION[Custom Actions] end ACT --> DOCKER_CLI DOCKER_CLI -.->|Socket| DOCKER_DAEMON DOCKER_DAEMON --> UBUNTU DOCKER_DAEMON --> NODE DOCKER_DAEMON --> CUSTOM_ACTION HOST_WORKSPACE --> WORKSPACE_MOUNT Usage Examples \u00b6 Basic Workflow Testing \u00b6 1 2 3 4 5 6 # Run all workflows in the current repository docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest Specific Workflow Execution \u00b6 1 2 3 4 5 6 7 # Run a specific workflow file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/ci.yml Event-specific Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Test push event docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ push # Test pull request event docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ pull_request Job-specific Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Run specific job docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -j test # List available jobs docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -l Advanced Usage \u00b6 Custom Platform Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create custom platform mapping cat > .actrc << EOF -P ubuntu-latest=catthehacker/ubuntu:act-latest -P ubuntu-20.04=catthehacker/ubuntu:act-20.04 -P ubuntu-18.04=catthehacker/ubuntu:act-18.04 EOF # Use custom platforms docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --platform-file .actrc Environment Variables and Secrets \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Pass environment variables docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = your_token \\ webgrip/act-runner:latest \\ --env GITHUB_TOKEN # Use secrets file echo \"GITHUB_TOKEN=your_token\" > .secrets docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --secret-file .secrets Interactive Debugging \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 # Run interactively for debugging docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ --entrypoint = /bin/bash \\ webgrip/act-runner:latest # Inside container - manual ACT execution act --help act -l act -n # Dry run Development Workflow Integration \u00b6 Pre-commit Hook \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash # .git/hooks/pre-commit echo \"\ud83e\uddea Testing GitHub Actions locally with ACT...\" docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -n --verbose if [ $? -ne 0 ] ; then echo \"\u274c GitHub Actions workflow validation failed!\" exit 1 fi echo \"\u2705 GitHub Actions workflows validated successfully!\" Makefile Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Makefile .PHONY : test - actions test-actions : @echo \"Testing GitHub Actions locally...\" docker run --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -n .PHONY : run - actions run-actions : @echo \"Running GitHub Actions locally...\" docker run --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest .PHONY : debug - actions debug-actions : @echo \"Debugging GitHub Actions...\" docker run -it --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ --entrypoint = /bin/bash \\ webgrip/act-runner:latest VS Code Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // .vscode/tasks.json { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Test GitHub Actions\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"run\" , \"--rm\" , \"-v\" , \"${workspaceFolder}:/workspace\" , \"-v\" , \"/var/run/docker.sock:/var/run/docker.sock\" , \"-w\" , \"/workspace\" , \"webgrip/act-runner:latest\" , \"-n\" ], \"group\" : \"test\" , \"presentation\" : { \"echo\" : true , \"reveal\" : \"always\" , \"focus\" : false , \"panel\" : \"shared\" } } ] } Configuration \u00b6 ACT Configuration File \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # .actrc or ~/.actrc # Platform mappings -P ubuntu-latest=catthehacker/ubuntu:act-latest -P ubuntu-20.04=catthehacker/ubuntu:act-20.04 # Default secrets --secret-file .secrets # Default environment --env-file .env # Verbose output --verbose # Reuse containers for faster execution --reuse Docker Compose Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # docker-compose.yml version : '3.8' services : act-runner : image : webgrip/act-runner:latest volumes : - .:/workspace - /var/run/docker.sock:/var/run/docker.sock working_dir : /workspace command : [ \"--list\" ] act-test : extends : act-runner command : [ \"--dryrun\" ] act-debug : extends : act-runner entrypoint : [ \"/bin/bash\" ] stdin_open : true tty : true Usage: 1 2 3 4 5 6 7 8 # List workflows docker-compose run act-runner # Test workflows (dry run) docker-compose run act-test # Debug interactively docker-compose run act-debug Testing Specific WebGrip Workflows \u00b6 Rust CI Testing \u00b6 1 2 3 4 5 6 7 8 # Test Rust CI workflow with custom image docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = webgrip/rust-ci-runner:latest \\ -j test Dockerfile Build Testing \u00b6 1 2 3 4 5 6 7 8 # Test Docker image building workflow docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/on_dockerfile_change.yml \\ push E2E Testing with Playwright \u00b6 1 2 3 4 5 6 7 8 # Test E2E workflow docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = webgrip/playwright-runner:latest \\ -j e2e-test Troubleshooting \u00b6 Common Issues \u00b6 Docker socket permission denied 1 2 3 4 5 6 7 8 9 10 11 # Ensure Docker socket is accessible ls -la /var/run/docker.sock # On some systems, add to docker group sudo usermod -aG docker $USER # Or run with elevated privileges docker run --rm --privileged \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/act-runner:latest ACT runner image not found 1 2 3 4 5 6 7 8 9 10 11 # Pull missing runner images docker pull catthehacker/ubuntu:act-latest docker pull catthehacker/ubuntu:act-20.04 # Or use custom platform mapping docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = ubuntu:20.04 Workflow file not found 1 2 3 4 5 6 7 8 9 10 # Check workflow file paths ls -la .github/workflows/ # Specify exact workflow file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/ci.yml Action execution failures 1 2 3 4 5 6 7 8 9 10 # Debug with verbose output docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --verbose --dryrun # Check action logs docker logs <action-container-id> Performance Issues \u00b6 Slow container startup 1 2 3 4 5 6 7 8 9 10 # Reuse containers between runs docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --reuse # Use smaller base images -P ubuntu-latest = alpine:latest Network timeouts 1 2 3 4 5 6 7 # Increase timeouts docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --container-timeout 10m Security Considerations \u00b6 Docker Socket Security \u00b6 Risk : Mounting Docker socket provides root access to host system. Mitigations : 1. Rootless Docker : Use rootless Docker daemon when possible 2. User namespaces : Configure user namespace remapping 3. Restricted environments : Only run on development machines, not production 4. Network isolation : Use isolated networks for ACT execution 1 2 3 4 5 6 7 8 9 # Safer execution with network isolation docker network create act-network docker run --rm \\ --network act-network \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest Secrets Management \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Use environment-specific secrets echo \"DEV_API_KEY=dev_key_value\" > .secrets.dev echo \"STAGING_API_KEY=staging_key_value\" > .secrets.staging # Never commit secrets files echo \".secrets*\" >> .gitignore # Use secrets file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --secret-file .secrets.dev Customization \u00b6 Extended ACT Runner \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Dockerfile.custom FROM webgrip/act-runner:latest # Add additional tools RUN apk add --no-cache \\ jq \\ yq \\ python3 \\ py3-pip # Add GitHub CLI RUN apk add --no-cache --repository = https://dl-cdn.alpinelinux.org/alpine/edge/community \\ github-cli # Custom ACT configuration COPY .actrc /root/.actrc Project-specific Runner \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 FROM webgrip/act-runner:latest # Add project-specific tools RUN apk add --no-cache nodejs npm # Pre-configure for project COPY package.json package-lock.json ./ RUN npm ci # Custom entry point COPY act-entrypoint.sh /usr/local/bin/ ENTRYPOINT [ \"/usr/local/bin/act-entrypoint.sh\" ] Related Documentation \u00b6 Architecture Overview - Local development in our infrastructure GitHub Runner - Production GitHub Actions runner CI/CD Pipeline - Our GitHub Actions workflows Quick Start Guide - Getting started with local testing Maintenance \u00b6 Update Schedule \u00b6 ACT version : Updated quarterly or when new features needed Alpine version : Updated when new Alpine releases available Docker CLI : Updated with Alpine package updates Version Compatibility \u00b6 Image Version ACT Alpine Docker CLI Status latest Latest 3.22.1 Latest Active v0.2 v0.2.x 3.22.x 24.x Supported v0.1 v0.1.x 3.21.x 23.x Deprecated Assumption : Developers have Docker installed locally and are comfortable with command-line tools. ACT runner is primarily for development/testing, not production CI/CD. Validation needed: Confirm developer tooling standards and local development practices. Maintainer : WebGrip Ops Team Source : ops/docker/act-runner/Dockerfile Registry : webgrip/act-runner","title":"ACT Runner"},{"location":"docker-images/act-runner/#act-runner","text":"A lightweight Alpine-based container for running GitHub Actions workflows locally using the ACT (Actions Container Toolkit) tool.","title":"ACT Runner"},{"location":"docker-images/act-runner/#purpose","text":"The ACT Runner enables local GitHub Actions testing by providing: \u2705 Local workflow execution without pushing to GitHub \u2705 Fast iteration cycles for workflow development \u2705 Debugging capabilities for complex GitHub Actions \u2705 Cost reduction by testing locally before using GitHub Actions minutes \u2705 Offline development when internet connectivity is limited","title":"Purpose"},{"location":"docker-images/act-runner/#image-details","text":"Property Value Base Image alpine:3.22.1 Size ~100MB (minimal Alpine + ACT + Docker CLI) Architecture AMD64 Registry webgrip/act-runner Dockerfile ops/docker/act-runner/Dockerfile","title":"Image Details"},{"location":"docker-images/act-runner/#installed-tools","text":"","title":"Installed Tools"},{"location":"docker-images/act-runner/#core-tools","text":"Tool Purpose Installation Method ACT GitHub Actions local runner Official install script Docker CLI Container management Alpine package Git Version control integration Alpine package Bash Shell scripting environment Alpine package curl HTTP client for API calls Alpine package","title":"Core Tools"},{"location":"docker-images/act-runner/#system-components","text":"Alpine Linux 3.22.1 - Minimal, security-focused base OS Docker socket access - Required for running containerized actions Workspace directory - /workspace for project files","title":"System Components"},{"location":"docker-images/act-runner/#architecture","text":"","title":"Architecture"},{"location":"docker-images/act-runner/#local-workflow-execution","text":"flowchart TD DEV[Developer] --> ACT_CMD[act command] ACT_CMD --> ACT_RUNNER[ACT Runner Container] ACT_RUNNER --> DOCKER_HOST[Docker Host] DOCKER_HOST --> ACTION_CONTAINERS[Action Containers] ACTION_CONTAINERS --> WORKSPACE[Workspace Volume] WORKSPACE --> RESULTS[Execution Results] RESULTS --> DEV subgraph \"ACT Runner Container\" ACT_BINARY[ACT Binary] DOCKER_CLI[Docker CLI] GIT[Git] end subgraph \"Action Execution\" CHECKOUT[actions/checkout] SETUP[actions/setup-*] CUSTOM[Custom Actions] SCRIPTS[Run Scripts] end ACT_RUNNER --> ACT_BINARY ACT_BINARY --> ACTION_EXECUTION ACTION_EXECUTION --> CHECKOUT ACTION_EXECUTION --> SETUP ACTION_EXECUTION --> CUSTOM ACTION_EXECUTION --> SCRIPTS","title":"Local Workflow Execution"},{"location":"docker-images/act-runner/#docker-in-docker-pattern","text":"flowchart LR subgraph \"Host System\" DOCKER_DAEMON[Docker Daemon] HOST_WORKSPACE[Host Workspace] end subgraph \"ACT Runner Container\" ACT[ACT Process] DOCKER_CLI[Docker CLI] WORKSPACE_MOUNT[/workspace] end subgraph \"Action Containers\" UBUNTU[ubuntu-latest] NODE[actions/setup-node] CUSTOM_ACTION[Custom Actions] end ACT --> DOCKER_CLI DOCKER_CLI -.->|Socket| DOCKER_DAEMON DOCKER_DAEMON --> UBUNTU DOCKER_DAEMON --> NODE DOCKER_DAEMON --> CUSTOM_ACTION HOST_WORKSPACE --> WORKSPACE_MOUNT","title":"Docker-in-Docker Pattern"},{"location":"docker-images/act-runner/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/act-runner/#basic-workflow-testing","text":"1 2 3 4 5 6 # Run all workflows in the current repository docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest","title":"Basic Workflow Testing"},{"location":"docker-images/act-runner/#specific-workflow-execution","text":"1 2 3 4 5 6 7 # Run a specific workflow file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/ci.yml","title":"Specific Workflow Execution"},{"location":"docker-images/act-runner/#event-specific-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Test push event docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ push # Test pull request event docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ pull_request","title":"Event-specific Testing"},{"location":"docker-images/act-runner/#job-specific-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Run specific job docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -j test # List available jobs docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -l","title":"Job-specific Execution"},{"location":"docker-images/act-runner/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"docker-images/act-runner/#custom-platform-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create custom platform mapping cat > .actrc << EOF -P ubuntu-latest=catthehacker/ubuntu:act-latest -P ubuntu-20.04=catthehacker/ubuntu:act-20.04 -P ubuntu-18.04=catthehacker/ubuntu:act-18.04 EOF # Use custom platforms docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --platform-file .actrc","title":"Custom Platform Configuration"},{"location":"docker-images/act-runner/#environment-variables-and-secrets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Pass environment variables docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = your_token \\ webgrip/act-runner:latest \\ --env GITHUB_TOKEN # Use secrets file echo \"GITHUB_TOKEN=your_token\" > .secrets docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --secret-file .secrets","title":"Environment Variables and Secrets"},{"location":"docker-images/act-runner/#interactive-debugging","text":"1 2 3 4 5 6 7 8 9 10 11 12 # Run interactively for debugging docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ --entrypoint = /bin/bash \\ webgrip/act-runner:latest # Inside container - manual ACT execution act --help act -l act -n # Dry run","title":"Interactive Debugging"},{"location":"docker-images/act-runner/#development-workflow-integration","text":"","title":"Development Workflow Integration"},{"location":"docker-images/act-runner/#pre-commit-hook","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash # .git/hooks/pre-commit echo \"\ud83e\uddea Testing GitHub Actions locally with ACT...\" docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -n --verbose if [ $? -ne 0 ] ; then echo \"\u274c GitHub Actions workflow validation failed!\" exit 1 fi echo \"\u2705 GitHub Actions workflows validated successfully!\"","title":"Pre-commit Hook"},{"location":"docker-images/act-runner/#makefile-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Makefile .PHONY : test - actions test-actions : @echo \"Testing GitHub Actions locally...\" docker run --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -n .PHONY : run - actions run-actions : @echo \"Running GitHub Actions locally...\" docker run --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest .PHONY : debug - actions debug-actions : @echo \"Debugging GitHub Actions...\" docker run -it --rm \\ -v $( PWD ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ --entrypoint = /bin/bash \\ webgrip/act-runner:latest","title":"Makefile Integration"},{"location":"docker-images/act-runner/#vs-code-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // .vscode/tasks.json { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Test GitHub Actions\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"run\" , \"--rm\" , \"-v\" , \"${workspaceFolder}:/workspace\" , \"-v\" , \"/var/run/docker.sock:/var/run/docker.sock\" , \"-w\" , \"/workspace\" , \"webgrip/act-runner:latest\" , \"-n\" ], \"group\" : \"test\" , \"presentation\" : { \"echo\" : true , \"reveal\" : \"always\" , \"focus\" : false , \"panel\" : \"shared\" } } ] }","title":"VS Code Integration"},{"location":"docker-images/act-runner/#configuration","text":"","title":"Configuration"},{"location":"docker-images/act-runner/#act-configuration-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # .actrc or ~/.actrc # Platform mappings -P ubuntu-latest=catthehacker/ubuntu:act-latest -P ubuntu-20.04=catthehacker/ubuntu:act-20.04 # Default secrets --secret-file .secrets # Default environment --env-file .env # Verbose output --verbose # Reuse containers for faster execution --reuse","title":"ACT Configuration File"},{"location":"docker-images/act-runner/#docker-compose-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # docker-compose.yml version : '3.8' services : act-runner : image : webgrip/act-runner:latest volumes : - .:/workspace - /var/run/docker.sock:/var/run/docker.sock working_dir : /workspace command : [ \"--list\" ] act-test : extends : act-runner command : [ \"--dryrun\" ] act-debug : extends : act-runner entrypoint : [ \"/bin/bash\" ] stdin_open : true tty : true Usage: 1 2 3 4 5 6 7 8 # List workflows docker-compose run act-runner # Test workflows (dry run) docker-compose run act-test # Debug interactively docker-compose run act-debug","title":"Docker Compose Integration"},{"location":"docker-images/act-runner/#testing-specific-webgrip-workflows","text":"","title":"Testing Specific WebGrip Workflows"},{"location":"docker-images/act-runner/#rust-ci-testing","text":"1 2 3 4 5 6 7 8 # Test Rust CI workflow with custom image docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = webgrip/rust-ci-runner:latest \\ -j test","title":"Rust CI Testing"},{"location":"docker-images/act-runner/#dockerfile-build-testing","text":"1 2 3 4 5 6 7 8 # Test Docker image building workflow docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/on_dockerfile_change.yml \\ push","title":"Dockerfile Build Testing"},{"location":"docker-images/act-runner/#e2e-testing-with-playwright","text":"1 2 3 4 5 6 7 8 # Test E2E workflow docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = webgrip/playwright-runner:latest \\ -j e2e-test","title":"E2E Testing with Playwright"},{"location":"docker-images/act-runner/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/act-runner/#common-issues","text":"Docker socket permission denied 1 2 3 4 5 6 7 8 9 10 11 # Ensure Docker socket is accessible ls -la /var/run/docker.sock # On some systems, add to docker group sudo usermod -aG docker $USER # Or run with elevated privileges docker run --rm --privileged \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/act-runner:latest ACT runner image not found 1 2 3 4 5 6 7 8 9 10 11 # Pull missing runner images docker pull catthehacker/ubuntu:act-latest docker pull catthehacker/ubuntu:act-20.04 # Or use custom platform mapping docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -P ubuntu-latest = ubuntu:20.04 Workflow file not found 1 2 3 4 5 6 7 8 9 10 # Check workflow file paths ls -la .github/workflows/ # Specify exact workflow file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ -W .github/workflows/ci.yml Action execution failures 1 2 3 4 5 6 7 8 9 10 # Debug with verbose output docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --verbose --dryrun # Check action logs docker logs <action-container-id>","title":"Common Issues"},{"location":"docker-images/act-runner/#performance-issues","text":"Slow container startup 1 2 3 4 5 6 7 8 9 10 # Reuse containers between runs docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --reuse # Use smaller base images -P ubuntu-latest = alpine:latest Network timeouts 1 2 3 4 5 6 7 # Increase timeouts docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --container-timeout 10m","title":"Performance Issues"},{"location":"docker-images/act-runner/#security-considerations","text":"","title":"Security Considerations"},{"location":"docker-images/act-runner/#docker-socket-security","text":"Risk : Mounting Docker socket provides root access to host system. Mitigations : 1. Rootless Docker : Use rootless Docker daemon when possible 2. User namespaces : Configure user namespace remapping 3. Restricted environments : Only run on development machines, not production 4. Network isolation : Use isolated networks for ACT execution 1 2 3 4 5 6 7 8 9 # Safer execution with network isolation docker network create act-network docker run --rm \\ --network act-network \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest","title":"Docker Socket Security"},{"location":"docker-images/act-runner/#secrets-management","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Use environment-specific secrets echo \"DEV_API_KEY=dev_key_value\" > .secrets.dev echo \"STAGING_API_KEY=staging_key_value\" > .secrets.staging # Never commit secrets files echo \".secrets*\" >> .gitignore # Use secrets file docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ --secret-file .secrets.dev","title":"Secrets Management"},{"location":"docker-images/act-runner/#customization","text":"","title":"Customization"},{"location":"docker-images/act-runner/#extended-act-runner","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Dockerfile.custom FROM webgrip/act-runner:latest # Add additional tools RUN apk add --no-cache \\ jq \\ yq \\ python3 \\ py3-pip # Add GitHub CLI RUN apk add --no-cache --repository = https://dl-cdn.alpinelinux.org/alpine/edge/community \\ github-cli # Custom ACT configuration COPY .actrc /root/.actrc","title":"Extended ACT Runner"},{"location":"docker-images/act-runner/#project-specific-runner","text":"1 2 3 4 5 6 7 8 9 10 11 12 FROM webgrip/act-runner:latest # Add project-specific tools RUN apk add --no-cache nodejs npm # Pre-configure for project COPY package.json package-lock.json ./ RUN npm ci # Custom entry point COPY act-entrypoint.sh /usr/local/bin/ ENTRYPOINT [ \"/usr/local/bin/act-entrypoint.sh\" ]","title":"Project-specific Runner"},{"location":"docker-images/act-runner/#related-documentation","text":"Architecture Overview - Local development in our infrastructure GitHub Runner - Production GitHub Actions runner CI/CD Pipeline - Our GitHub Actions workflows Quick Start Guide - Getting started with local testing","title":"Related Documentation"},{"location":"docker-images/act-runner/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/act-runner/#update-schedule","text":"ACT version : Updated quarterly or when new features needed Alpine version : Updated when new Alpine releases available Docker CLI : Updated with Alpine package updates","title":"Update Schedule"},{"location":"docker-images/act-runner/#version-compatibility","text":"Image Version ACT Alpine Docker CLI Status latest Latest 3.22.1 Latest Active v0.2 v0.2.x 3.22.x 24.x Supported v0.1 v0.1.x 3.21.x 23.x Deprecated Assumption : Developers have Docker installed locally and are comfortable with command-line tools. ACT runner is primarily for development/testing, not production CI/CD. Validation needed: Confirm developer tooling standards and local development practices. Maintainer : WebGrip Ops Team Source : ops/docker/act-runner/Dockerfile Registry : webgrip/act-runner","title":"Version Compatibility"},{"location":"docker-images/github-runner/","text":"GitHub Actions Runner \u00b6 A self-hosted GitHub Actions runner with enhanced tooling for PHP development and general CI/CD workflows. Purpose \u00b6 This image provides a self-hosted GitHub Actions runner that extends the official Actions runner with additional tools commonly needed in WebGrip's development workflows: \u2705 Self-hosted execution for faster builds and custom environments \u2705 PHP 8.3 ecosystem with Composer for PHP projects \u2705 Standard CI tools (git, curl, jq) for automation workflows \u2705 Custom runner configuration tailored to WebGrip's needs Image Details \u00b6 Property Value Base Image ghcr.io/actions/actions-runner:2.328.0 PHP Version 8.3 with common extensions Architecture AMD64 Registry webgrip/github-runner Dockerfile ops/docker/github-runner/Dockerfile Installed Tools & Software \u00b6 Core Runner Components \u00b6 GitHub Actions Runner : Version 2.328.0 from official Microsoft image Runner User : Non-root runner user for security Development Tools \u00b6 Tool Version Purpose PHP 8.3 PHP development and application runtime Composer Latest PHP dependency management Git System default Version control curl System default HTTP client for API calls jq System default JSON processing bash System default Shell scripting rsync System default File synchronization unzip System default Archive extraction PHP Extensions \u00b6 Complete PHP 8.3 setup with commonly used extensions: php8.3-cli - Command line interface php8.3-common - Common functionality php8.3-bcmath - Arbitrary precision mathematics php8.3-curl - cURL support php8.3-gd - Image processing php8.3-intl - Internationalization php8.3-mbstring - Multibyte string handling php8.3-mysql - MySQL database support php8.3-soap - SOAP protocol support php8.3-sockets - Socket communication php8.3-xml - XML processing php8.3-zip - ZIP archive handling Architecture \u00b6 Runner Lifecycle \u00b6 sequenceDiagram participant GH as GitHub Repository participant Runner as Self-hosted Runner participant Container as Runner Container participant Tools as PHP/Composer Tools GH->>Runner: Workflow triggered Runner->>Container: Start job container Container->>Tools: Execute PHP commands Tools->>Container: Process results Container->>Runner: Job completion Runner->>GH: Report results Integration Points \u00b6 flowchart TB subgraph \"GitHub\" REPO[Repository] ACTIONS[GitHub Actions] end subgraph \"Self-hosted Infrastructure\" RUNNER[GitHub Runner Container] PHP[PHP 8.3 Runtime] COMPOSER[Composer] TOOLS[CI Tools] end subgraph \"External Services\" PACKAGIST[Packagist.org] DOCKER_HUB[Docker Hub] end REPO --> ACTIONS ACTIONS --> RUNNER RUNNER --> PHP RUNNER --> COMPOSER RUNNER --> TOOLS COMPOSER --> PACKAGIST RUNNER --> DOCKER_HUB Usage Examples \u00b6 Self-hosted Runner Setup \u00b6 Note : This image requires proper runner registration with GitHub. It cannot be run directly without GitHub Actions runner token. 1 2 3 4 5 6 # Example runner registration (requires GitHub token) docker run -d --name github-runner \\ -e GITHUB_URL = https://github.com/webgrip/your-repo \\ -e GITHUB_TOKEN = your_runner_token \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/github-runner:latest Workflow Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # .github/workflows/php-ci.yml name : PHP CI on : [ push , pull_request ] jobs : test : runs-on : [ self-hosted , webgrip-runner ] steps : - uses : actions/checkout@v4 - name : Validate Composer run : composer validate --strict - name : Install dependencies run : composer install --prefer-dist --no-progress - name : Run tests run : | vendor/bin/phpunit vendor/bin/phpstan analyse - name : Check code style run : vendor/bin/php-cs-fixer fix --dry-run --diff PHP Project Examples \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Inside the runner container - PHP development workflow composer create-project laravel/laravel my-app cd my-app # Install dependencies composer install # Run PHP-specific tools php artisan migrate php artisan test # Quality assurance composer run-script phpstan composer run-script php-cs-fixer Configuration \u00b6 Environment Variables \u00b6 During runner registration: Variable Required Purpose GITHUB_URL Yes Repository or organization URL GITHUB_TOKEN Yes Runner registration token RUNNER_NAME No Custom runner name (default: hostname) RUNNER_LABELS No Additional runner labels PHP Configuration \u00b6 The image uses system default PHP configuration. For custom settings: 1 2 3 4 # Custom php.ini settings via environment docker run -e \"PHP_INI_SCAN_DIR=/usr/local/etc/php/conf.d\" \\ -v $( pwd ) /php.ini:/usr/local/etc/php/conf.d/custom.ini \\ webgrip/github-runner:latest Security Considerations \u00b6 Runner Security \u00b6 Non-root execution : Runner operates as runner user Isolated environments : Each job runs in isolated containers Token management : Registration tokens should be short-lived Network isolation : Consider firewall rules for runner hosts PHP Security \u00b6 Updated packages : PHP 8.3 with latest security patches Minimal extensions : Only necessary PHP extensions installed Composer security : Always use composer audit in workflows Best Practices \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Secure workflow example jobs : secure-php : runs-on : [ self-hosted , webgrip-runner ] steps : - uses : actions/checkout@v4 # Security checks first - name : Audit dependencies run : composer audit - name : Check for vulnerabilities run : | composer require --dev roave/security-advisories composer install # Then proceed with normal workflow - name : Run tests run : vendor/bin/phpunit Performance Optimization \u00b6 Runner Performance \u00b6 Persistent cache : Use runner-local caches for Composer 1 2 3 4 5 - name : Cache Composer dependencies uses : actions/cache@v3 with : path : ~/.composer/cache key : composer-${{ hashFiles('**/composer.lock') }} Parallel execution : Configure multiple runner instances 1 2 3 4 5 6 # Run multiple runner containers for i in { 1 ..3 } ; do docker run -d --name \"github-runner- $i \" \\ -e RUNNER_NAME = \"webgrip-runner- $i \" \\ webgrip/github-runner:latest done PHP Performance \u00b6 OPcache configuration : Enable OPcache for production-like testing Memory limits : Adjust PHP memory limits for large applications Composer optimization : Use --optimize-autoloader flag Troubleshooting \u00b6 Common Issues \u00b6 Runner registration fails 1 2 3 4 5 6 # Check runner logs docker logs github-runner # Verify token and URL echo \"URL: $GITHUB_URL \" echo \"Token: ${ GITHUB_TOKEN : 0 : 4 } ...\" # Only show first 4 chars PHP memory errors 1 2 3 4 # Increase PHP memory limit echo \"memory_limit = 512M\" > custom-php.ini docker run -v $( pwd ) /custom-php.ini:/etc/php/8.3/cli/conf.d/99-custom.ini \\ webgrip/github-runner:latest php -m Composer timeouts 1 2 # Configure Composer timeout composer config --global process-timeout 2000 Permission issues 1 2 3 # Check runner user permissions docker exec github-runner id runner docker exec github-runner ls -la /home/runner Debugging \u00b6 1 2 3 4 5 6 7 # Interactive debugging session docker run -it --entrypoint = /bin/bash webgrip/github-runner:latest # Inside container - verify tools php --version composer --version which git curl jq Customization \u00b6 Adding Additional Tools \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/github-runner:latest USER root # Add Node.js for frontend builds RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \\ apt-get install -y nodejs # Add database clients RUN apt-get install -y postgresql-client mysql-client USER runner Custom Runner Configuration \u00b6 1 2 3 4 5 6 7 8 9 # Environment file for runner configuration cat > runner.env << EOF GITHUB_URL=https://github.com/webgrip/infrastructure RUNNER_NAME=webgrip-infra-runner RUNNER_LABELS=php,infra,webgrip RUNNER_WORKDIR=/tmp/runner-work EOF docker run --env-file runner.env webgrip/github-runner:latest Maintenance \u00b6 Update Schedule \u00b6 Runner version : Updated monthly following GitHub Actions runner releases PHP version : Updated when new PHP 8.3.x releases available Security patches : Applied immediately when available Monitoring \u00b6 1 2 3 # Check runner health docker exec github-runner ps aux | grep Runner.Listener docker exec github-runner systemctl status actions.runner.service Backup & Recovery \u00b6 Runner configuration : Stored in GitHub organization settings Custom configurations : Version controlled in this repository Data persistence : Use volumes for persistent runner data Integration with WebGrip Infrastructure \u00b6 Related Services \u00b6 Rust CI Runner : For Rust projects that also need PHP components Playwright Runner : Shares PHP tooling for full-stack testing Helm Deploy : Used by this runner for Kubernetes deployments Workflow Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Multi-stage workflow using multiple WebGrip images jobs : php-build : runs-on : [ self-hosted , webgrip-runner ] steps : - name : Build PHP application run : composer install --no-dev --optimize-autoloader rust-build : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - name : Build Rust components run : cargo build --release deploy : needs : [ php-build , rust-build ] runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - name : Deploy to Kubernetes run : helm upgrade --install myapp ./charts/myapp Related Documentation \u00b6 Architecture Overview - How runners fit into our CI/CD CI/CD Pipeline - Automated runner image building Playwright Runner - Complementary testing image with PHP Operations Guide - Contributing to runner improvements Assumption : Self-hosted runners are deployed in secure, managed environments with proper network isolation and monitoring. Validation needed: Confirm runner deployment strategy and security requirements with ops team. Maintainer : WebGrip Ops Team Source : ops/docker/github-runner/Dockerfile Registry : webgrip/github-runner","title":"GitHub Actions Runner"},{"location":"docker-images/github-runner/#github-actions-runner","text":"A self-hosted GitHub Actions runner with enhanced tooling for PHP development and general CI/CD workflows.","title":"GitHub Actions Runner"},{"location":"docker-images/github-runner/#purpose","text":"This image provides a self-hosted GitHub Actions runner that extends the official Actions runner with additional tools commonly needed in WebGrip's development workflows: \u2705 Self-hosted execution for faster builds and custom environments \u2705 PHP 8.3 ecosystem with Composer for PHP projects \u2705 Standard CI tools (git, curl, jq) for automation workflows \u2705 Custom runner configuration tailored to WebGrip's needs","title":"Purpose"},{"location":"docker-images/github-runner/#image-details","text":"Property Value Base Image ghcr.io/actions/actions-runner:2.328.0 PHP Version 8.3 with common extensions Architecture AMD64 Registry webgrip/github-runner Dockerfile ops/docker/github-runner/Dockerfile","title":"Image Details"},{"location":"docker-images/github-runner/#installed-tools-software","text":"","title":"Installed Tools &amp; Software"},{"location":"docker-images/github-runner/#core-runner-components","text":"GitHub Actions Runner : Version 2.328.0 from official Microsoft image Runner User : Non-root runner user for security","title":"Core Runner Components"},{"location":"docker-images/github-runner/#development-tools","text":"Tool Version Purpose PHP 8.3 PHP development and application runtime Composer Latest PHP dependency management Git System default Version control curl System default HTTP client for API calls jq System default JSON processing bash System default Shell scripting rsync System default File synchronization unzip System default Archive extraction","title":"Development Tools"},{"location":"docker-images/github-runner/#php-extensions","text":"Complete PHP 8.3 setup with commonly used extensions: php8.3-cli - Command line interface php8.3-common - Common functionality php8.3-bcmath - Arbitrary precision mathematics php8.3-curl - cURL support php8.3-gd - Image processing php8.3-intl - Internationalization php8.3-mbstring - Multibyte string handling php8.3-mysql - MySQL database support php8.3-soap - SOAP protocol support php8.3-sockets - Socket communication php8.3-xml - XML processing php8.3-zip - ZIP archive handling","title":"PHP Extensions"},{"location":"docker-images/github-runner/#architecture","text":"","title":"Architecture"},{"location":"docker-images/github-runner/#runner-lifecycle","text":"sequenceDiagram participant GH as GitHub Repository participant Runner as Self-hosted Runner participant Container as Runner Container participant Tools as PHP/Composer Tools GH->>Runner: Workflow triggered Runner->>Container: Start job container Container->>Tools: Execute PHP commands Tools->>Container: Process results Container->>Runner: Job completion Runner->>GH: Report results","title":"Runner Lifecycle"},{"location":"docker-images/github-runner/#integration-points","text":"flowchart TB subgraph \"GitHub\" REPO[Repository] ACTIONS[GitHub Actions] end subgraph \"Self-hosted Infrastructure\" RUNNER[GitHub Runner Container] PHP[PHP 8.3 Runtime] COMPOSER[Composer] TOOLS[CI Tools] end subgraph \"External Services\" PACKAGIST[Packagist.org] DOCKER_HUB[Docker Hub] end REPO --> ACTIONS ACTIONS --> RUNNER RUNNER --> PHP RUNNER --> COMPOSER RUNNER --> TOOLS COMPOSER --> PACKAGIST RUNNER --> DOCKER_HUB","title":"Integration Points"},{"location":"docker-images/github-runner/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/github-runner/#self-hosted-runner-setup","text":"Note : This image requires proper runner registration with GitHub. It cannot be run directly without GitHub Actions runner token. 1 2 3 4 5 6 # Example runner registration (requires GitHub token) docker run -d --name github-runner \\ -e GITHUB_URL = https://github.com/webgrip/your-repo \\ -e GITHUB_TOKEN = your_runner_token \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/github-runner:latest","title":"Self-hosted Runner Setup"},{"location":"docker-images/github-runner/#workflow-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # .github/workflows/php-ci.yml name : PHP CI on : [ push , pull_request ] jobs : test : runs-on : [ self-hosted , webgrip-runner ] steps : - uses : actions/checkout@v4 - name : Validate Composer run : composer validate --strict - name : Install dependencies run : composer install --prefer-dist --no-progress - name : Run tests run : | vendor/bin/phpunit vendor/bin/phpstan analyse - name : Check code style run : vendor/bin/php-cs-fixer fix --dry-run --diff","title":"Workflow Configuration"},{"location":"docker-images/github-runner/#php-project-examples","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Inside the runner container - PHP development workflow composer create-project laravel/laravel my-app cd my-app # Install dependencies composer install # Run PHP-specific tools php artisan migrate php artisan test # Quality assurance composer run-script phpstan composer run-script php-cs-fixer","title":"PHP Project Examples"},{"location":"docker-images/github-runner/#configuration","text":"","title":"Configuration"},{"location":"docker-images/github-runner/#environment-variables","text":"During runner registration: Variable Required Purpose GITHUB_URL Yes Repository or organization URL GITHUB_TOKEN Yes Runner registration token RUNNER_NAME No Custom runner name (default: hostname) RUNNER_LABELS No Additional runner labels","title":"Environment Variables"},{"location":"docker-images/github-runner/#php-configuration","text":"The image uses system default PHP configuration. For custom settings: 1 2 3 4 # Custom php.ini settings via environment docker run -e \"PHP_INI_SCAN_DIR=/usr/local/etc/php/conf.d\" \\ -v $( pwd ) /php.ini:/usr/local/etc/php/conf.d/custom.ini \\ webgrip/github-runner:latest","title":"PHP Configuration"},{"location":"docker-images/github-runner/#security-considerations","text":"","title":"Security Considerations"},{"location":"docker-images/github-runner/#runner-security","text":"Non-root execution : Runner operates as runner user Isolated environments : Each job runs in isolated containers Token management : Registration tokens should be short-lived Network isolation : Consider firewall rules for runner hosts","title":"Runner Security"},{"location":"docker-images/github-runner/#php-security","text":"Updated packages : PHP 8.3 with latest security patches Minimal extensions : Only necessary PHP extensions installed Composer security : Always use composer audit in workflows","title":"PHP Security"},{"location":"docker-images/github-runner/#best-practices","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Secure workflow example jobs : secure-php : runs-on : [ self-hosted , webgrip-runner ] steps : - uses : actions/checkout@v4 # Security checks first - name : Audit dependencies run : composer audit - name : Check for vulnerabilities run : | composer require --dev roave/security-advisories composer install # Then proceed with normal workflow - name : Run tests run : vendor/bin/phpunit","title":"Best Practices"},{"location":"docker-images/github-runner/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"docker-images/github-runner/#runner-performance","text":"Persistent cache : Use runner-local caches for Composer 1 2 3 4 5 - name : Cache Composer dependencies uses : actions/cache@v3 with : path : ~/.composer/cache key : composer-${{ hashFiles('**/composer.lock') }} Parallel execution : Configure multiple runner instances 1 2 3 4 5 6 # Run multiple runner containers for i in { 1 ..3 } ; do docker run -d --name \"github-runner- $i \" \\ -e RUNNER_NAME = \"webgrip-runner- $i \" \\ webgrip/github-runner:latest done","title":"Runner Performance"},{"location":"docker-images/github-runner/#php-performance","text":"OPcache configuration : Enable OPcache for production-like testing Memory limits : Adjust PHP memory limits for large applications Composer optimization : Use --optimize-autoloader flag","title":"PHP Performance"},{"location":"docker-images/github-runner/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/github-runner/#common-issues","text":"Runner registration fails 1 2 3 4 5 6 # Check runner logs docker logs github-runner # Verify token and URL echo \"URL: $GITHUB_URL \" echo \"Token: ${ GITHUB_TOKEN : 0 : 4 } ...\" # Only show first 4 chars PHP memory errors 1 2 3 4 # Increase PHP memory limit echo \"memory_limit = 512M\" > custom-php.ini docker run -v $( pwd ) /custom-php.ini:/etc/php/8.3/cli/conf.d/99-custom.ini \\ webgrip/github-runner:latest php -m Composer timeouts 1 2 # Configure Composer timeout composer config --global process-timeout 2000 Permission issues 1 2 3 # Check runner user permissions docker exec github-runner id runner docker exec github-runner ls -la /home/runner","title":"Common Issues"},{"location":"docker-images/github-runner/#debugging","text":"1 2 3 4 5 6 7 # Interactive debugging session docker run -it --entrypoint = /bin/bash webgrip/github-runner:latest # Inside container - verify tools php --version composer --version which git curl jq","title":"Debugging"},{"location":"docker-images/github-runner/#customization","text":"","title":"Customization"},{"location":"docker-images/github-runner/#adding-additional-tools","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/github-runner:latest USER root # Add Node.js for frontend builds RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \\ apt-get install -y nodejs # Add database clients RUN apt-get install -y postgresql-client mysql-client USER runner","title":"Adding Additional Tools"},{"location":"docker-images/github-runner/#custom-runner-configuration","text":"1 2 3 4 5 6 7 8 9 # Environment file for runner configuration cat > runner.env << EOF GITHUB_URL=https://github.com/webgrip/infrastructure RUNNER_NAME=webgrip-infra-runner RUNNER_LABELS=php,infra,webgrip RUNNER_WORKDIR=/tmp/runner-work EOF docker run --env-file runner.env webgrip/github-runner:latest","title":"Custom Runner Configuration"},{"location":"docker-images/github-runner/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/github-runner/#update-schedule","text":"Runner version : Updated monthly following GitHub Actions runner releases PHP version : Updated when new PHP 8.3.x releases available Security patches : Applied immediately when available","title":"Update Schedule"},{"location":"docker-images/github-runner/#monitoring","text":"1 2 3 # Check runner health docker exec github-runner ps aux | grep Runner.Listener docker exec github-runner systemctl status actions.runner.service","title":"Monitoring"},{"location":"docker-images/github-runner/#backup-recovery","text":"Runner configuration : Stored in GitHub organization settings Custom configurations : Version controlled in this repository Data persistence : Use volumes for persistent runner data","title":"Backup &amp; Recovery"},{"location":"docker-images/github-runner/#integration-with-webgrip-infrastructure","text":"","title":"Integration with WebGrip Infrastructure"},{"location":"docker-images/github-runner/#related-services","text":"Rust CI Runner : For Rust projects that also need PHP components Playwright Runner : Shares PHP tooling for full-stack testing Helm Deploy : Used by this runner for Kubernetes deployments","title":"Related Services"},{"location":"docker-images/github-runner/#workflow-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Multi-stage workflow using multiple WebGrip images jobs : php-build : runs-on : [ self-hosted , webgrip-runner ] steps : - name : Build PHP application run : composer install --no-dev --optimize-autoloader rust-build : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - name : Build Rust components run : cargo build --release deploy : needs : [ php-build , rust-build ] runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - name : Deploy to Kubernetes run : helm upgrade --install myapp ./charts/myapp","title":"Workflow Integration"},{"location":"docker-images/github-runner/#related-documentation","text":"Architecture Overview - How runners fit into our CI/CD CI/CD Pipeline - Automated runner image building Playwright Runner - Complementary testing image with PHP Operations Guide - Contributing to runner improvements Assumption : Self-hosted runners are deployed in secure, managed environments with proper network isolation and monitoring. Validation needed: Confirm runner deployment strategy and security requirements with ops team. Maintainer : WebGrip Ops Team Source : ops/docker/github-runner/Dockerfile Registry : webgrip/github-runner","title":"Related Documentation"},{"location":"docker-images/helm-deploy/","text":"Helm Deploy \u00b6 A lightweight, Alpine-based container optimized for Kubernetes deployments using Helm, kubectl, and additional DevOps tooling. Purpose \u00b6 The Helm Deploy image serves as a specialized deployment environment for Kubernetes infrastructure, providing: \u2705 Kubernetes deployment via Helm charts and kubectl \u2705 Multi-cloud support with DigitalOcean CLI integration \u2705 Secrets management using SOPS for encrypted configurations \u2705 YAML processing capabilities for configuration manipulation \u2705 Minimal footprint based on Alpine Linux for fast execution Image Details \u00b6 Property Value Base Image alpine:3.21.3 Size ~150MB (minimal Alpine + tools) Architecture AMD64 Registry webgrip/helm-deploy Dockerfile ops/docker/helm-deploy/Dockerfile Installed Tools & Versions \u00b6 Core Deployment Tools \u00b6 Tool Version Purpose kubectl v1.32.2 Kubernetes command-line tool Helm 3.17.1 Kubernetes package manager doctl 1.123.0 DigitalOcean CLI SOPS 3.7.3 Secrets encryption/decryption yq 4.45.1 YAML processing tool System Utilities \u00b6 git - Version control for chart repositories curl/wget - HTTP clients for API interactions bash - Shell scripting environment tar - Archive handling gnupg - GPG encryption for SOPS openssl - SSL/TLS utilities ca-certificates - Certificate authority bundle Architecture \u00b6 Deployment Workflow \u00b6 flowchart TD START[Deployment Start] --> FETCH[Fetch Helm Charts] FETCH --> DECRYPT[Decrypt Secrets with SOPS] DECRYPT --> TEMPLATE[Template with yq/Helm] TEMPLATE --> VALIDATE[Validate with kubectl] VALIDATE --> DEPLOY[Deploy with Helm] DEPLOY --> VERIFY[Verify Deployment] VERIFY --> END[Deployment Complete] subgraph \"Tools Used\" GIT[git] --> FETCH SOPS[sops] --> DECRYPT YQ[yq] --> TEMPLATE HELM[helm] --> TEMPLATE KUBECTL[kubectl] --> VALIDATE HELM --> DEPLOY KUBECTL --> VERIFY end Multi-Cloud Architecture \u00b6 flowchart LR subgraph \"Deployment Container\" HELM_DEPLOY[Helm Deploy Image] KUBECTL[kubectl] HELM[helm] DOCTL[doctl] SOPS[sops] end subgraph \"Target Environments\" DO_K8S[DigitalOcean Kubernetes] OTHER_K8S[Other K8s Clusters] end subgraph \"Configuration Sources\" CHARTS[Helm Charts Repository] SECRETS[Encrypted Secrets] CONFIGS[Configuration Files] end HELM_DEPLOY --> DO_K8S HELM_DEPLOY --> OTHER_K8S CHARTS --> HELM_DEPLOY SECRETS --> HELM_DEPLOY CONFIGS --> HELM_DEPLOY Usage Examples \u00b6 Basic Helm Deployment \u00b6 1 2 3 4 5 6 7 # Deploy a Helm chart to Kubernetes docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp DigitalOcean Kubernetes Deployment \u00b6 1 2 3 4 5 6 7 8 9 10 # Deploy to DigitalOcean managed Kubernetes docker run --rm \\ -v $( pwd ) :/workspace \\ -e DIGITALOCEAN_ACCESS_TOKEN = $DO_TOKEN \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" doctl kubernetes cluster kubeconfig save my-cluster helm upgrade --install myapp ./charts/myapp --namespace production \" Secrets Management with SOPS \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Decrypt secrets and deploy docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -v ~/.gnupg:/root/.gnupg \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Decrypt secrets sops -d secrets/production.enc.yaml > secrets/production.yaml # Deploy with decrypted secrets helm upgrade --install myapp ./charts/myapp \\ --values secrets/production.yaml \\ --namespace production \" Configuration Processing with yq \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Process YAML configurations before deployment docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Modify configuration using yq yq eval '.image.tag = \\\"v1.2.3\\\"' values.yaml > values-updated.yaml # Deploy with updated values helm upgrade --install myapp ./charts/myapp \\ --values values-updated.yaml \" CI/CD Integration \u00b6 GitHub Actions Workflow \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # .github/workflows/deploy.yml name : Deploy to Kubernetes on : push : branches : [ main ] jobs : deploy : runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - uses : actions/checkout@v4 - name : Setup DigitalOcean CLI env : DIGITALOCEAN_ACCESS_TOKEN : ${{ secrets.DO_TOKEN }} run : | doctl kubernetes cluster kubeconfig save ${{ vars.CLUSTER_NAME }} - name : Decrypt secrets env : SOPS_AGE_KEY : ${{ secrets.SOPS_AGE_KEY }} run : | echo \"$SOPS_AGE_KEY\" > /tmp/age-key export SOPS_AGE_KEY_FILE=/tmp/age-key sops -d secrets/production.enc.yaml > secrets/production.yaml - name : Deploy application run : | helm dependency update ./charts/myapp helm upgrade --install myapp ./charts/myapp \\ --namespace production \\ --create-namespace \\ --values secrets/production.yaml \\ --set image.tag=${{ github.sha }} - name : Verify deployment run : | kubectl rollout status deployment/myapp -n production kubectl get pods -n production Multi-Environment Deployment \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Deploy to multiple environments strategy : matrix : environment : [ staging , production ] steps : - name : Deploy to ${{ matrix.environment }} run : | # Setup environment-specific configuration export NAMESPACE=${{ matrix.environment }} export VALUES_FILE=values-${{ matrix.environment }}.yaml # Decrypt environment-specific secrets sops -d secrets/${{ matrix.environment }}.enc.yaml > secrets/${{ matrix.environment }}.yaml # Deploy with environment-specific settings helm upgrade --install myapp-${{ matrix.environment }} ./charts/myapp \\ --namespace $NAMESPACE \\ --create-namespace \\ --values $VALUES_FILE \\ --values secrets/${{ matrix.environment }}.yaml Configuration \u00b6 Environment Variables \u00b6 Variable Purpose Example DIGITALOCEAN_ACCESS_TOKEN DigitalOcean API authentication dop_v1_xxx... KUBECONFIG Kubernetes configuration file path /root/.kube/config SOPS_AGE_KEY_FILE Age key file for SOPS decryption /tmp/age-key SOPS_AGE_KEY Age key content for SOPS AGE-SECRET-KEY-1XXX... HELM_CACHE_HOME Helm cache directory /tmp/.helm Volume Mounts \u00b6 1 2 3 4 5 6 7 # Essential volume mounts for deployment docker run --rm \\ -v $( pwd ) :/workspace \\ # Project files -v ~/.kube:/root/.kube \\ # Kubernetes config -v ~/.gnupg:/root/.gnupg \\ # GPG keys for SOPS -v helm-cache:/tmp/.helm \\ # Helm cache webgrip/helm-deploy:latest Advanced Usage \u00b6 Custom Helm Chart Development \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Create and test new Helm charts docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Create new chart helm create myapp # Validate chart helm lint myapp/ # Test template rendering helm template myapp myapp/ --values myapp/values.yaml # Package chart helm package myapp/ \" Blue-Green Deployments \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Blue-green deployment strategy docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Deploy green version helm upgrade --install myapp-green ./charts/myapp \\ --set color=green \\ --set image.tag= $NEW_VERSION \\ --namespace production # Wait for green to be ready kubectl rollout status deployment/myapp-green -n production # Switch traffic (update service selector) yq eval '.spec.selector.color = \\\"green\\\"' service.yaml | kubectl apply -f - # Remove blue version after verification helm uninstall myapp-blue --namespace production \" Disaster Recovery \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Backup current deployment docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Get current values helm get values myapp -n production > backup/current-values.yaml # Get current manifests helm get manifest myapp -n production > backup/current-manifest.yaml # Backup persistent volumes kubectl get pv -o yaml > backup/persistent-volumes.yaml \" Security Best Practices \u00b6 Secrets Management \u00b6 Use SOPS for encryption : 1 2 3 4 5 # Encrypt secrets file sops -e secrets/production.yaml > secrets/production.enc.yaml # Never commit unencrypted secrets echo \"secrets/*.yaml\" >> .gitignore Age keys for SOPS : 1 2 3 4 5 # Generate age key pair age-keygen -o age-key.txt # Use in CI/CD export SOPS_AGE_KEY_FILE = /tmp/age-key Kubernetes RBAC : 1 2 3 4 5 6 7 8 9 # Limit deployment permissions apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : helm-deployer rules : - apiGroups : [ \"apps\" , \"\" ] resources : [ \"deployments\" , \"services\" , \"configmaps\" ] verbs : [ \"get\" , \"list\" , \"create\" , \"update\" , \"patch\" ] Network Security \u00b6 1 2 3 4 5 6 # Use private registries docker run --rm \\ -v ~/.docker:/root/.docker \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp \\ --set image.repository = private-registry.com/myapp Troubleshooting \u00b6 Common Issues \u00b6 \"Unable to connect to the server\" 1 2 3 4 5 6 # Verify Kubernetes configuration docker run --rm -v ~/.kube:/root/.kube webgrip/helm-deploy:latest kubectl cluster-info # Check kubeconfig kubectl config view kubectl config current-context \"Helm chart not found\" 1 2 3 4 5 6 7 8 # Update Helm repositories helm repo update # Search for charts helm search repo myapp # Verify chart path ls -la charts/myapp/Chart.yaml SOPS decryption failures 1 2 3 4 5 # Verify age key echo \" $SOPS_AGE_KEY \" | age-keygen -y # Test decryption sops -d secrets/production.enc.yaml DigitalOcean authentication issues 1 2 3 4 5 6 # Verify token doctl auth list doctl account get # Test cluster access doctl kubernetes cluster list Performance Issues \u00b6 Slow Helm operations 1 2 3 4 5 6 7 8 # Use Helm cache export HELM_CACHE_HOME = /tmp/.helm helm repo update # Parallel operations helm upgrade --install app1 ./charts/app1 & helm upgrade --install app2 ./charts/app2 & wait Large chart deployments 1 2 3 4 5 # Increase timeout helm upgrade --install myapp ./charts/myapp --timeout 10m # Use atomic deployments helm upgrade --install myapp ./charts/myapp --atomic Customization \u00b6 Adding Cloud Providers \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Dockerfile.custom FROM webgrip/helm-deploy:latest # Add AWS CLI RUN apk add --no-cache python3 py3-pip && \\ pip3 install awscli # Add Azure CLI RUN apk add --no-cache py3-pip && \\ pip3 install azure-cli # Add Google Cloud SDK RUN wget https://dl.google.com/dl/cloudsdk/channels/rapid/google-cloud-sdk.tar.gz && \\ tar -xzf google-cloud-sdk.tar.gz && \\ ./google-cloud-sdk/install.sh --quiet Custom Helm Plugins \u00b6 1 2 3 4 5 # Install Helm plugins in derived image FROM webgrip/helm-deploy:latest RUN helm plugin install https://github.com/databus23/helm-diff RUN helm plugin install https://github.com/jkroepke/helm-secrets Related Documentation \u00b6 Architecture Overview - Kubernetes deployment architecture CI/CD Pipeline - Automated image building GitHub Runner - Self-hosted runner that uses this image Operations Guide - Contributing improvements Maintenance \u00b6 Update Schedule \u00b6 Tool versions : Updated quarterly or when security issues discovered Alpine base : Updated when new Alpine releases available Kubernetes compatibility : Tested against latest K8s versions Version Matrix \u00b6 Image Version kubectl Helm Alpine Status latest v1.32.2 3.17.1 3.21.3 Active v1.32 v1.32.x 3.17.x 3.21.x Supported v1.31 v1.31.x 3.16.x 3.20.x Deprecated Assumption : Deployments primarily target DigitalOcean Kubernetes clusters. Support for other cloud providers (AWS EKS, GCP GKE, Azure AKS) may require additional CLI tools. Validation needed: Confirm cloud provider requirements with infrastructure team. Maintainer : WebGrip Ops Team Source : ops/docker/helm-deploy/Dockerfile Registry : webgrip/helm-deploy","title":"Helm Deploy"},{"location":"docker-images/helm-deploy/#helm-deploy","text":"A lightweight, Alpine-based container optimized for Kubernetes deployments using Helm, kubectl, and additional DevOps tooling.","title":"Helm Deploy"},{"location":"docker-images/helm-deploy/#purpose","text":"The Helm Deploy image serves as a specialized deployment environment for Kubernetes infrastructure, providing: \u2705 Kubernetes deployment via Helm charts and kubectl \u2705 Multi-cloud support with DigitalOcean CLI integration \u2705 Secrets management using SOPS for encrypted configurations \u2705 YAML processing capabilities for configuration manipulation \u2705 Minimal footprint based on Alpine Linux for fast execution","title":"Purpose"},{"location":"docker-images/helm-deploy/#image-details","text":"Property Value Base Image alpine:3.21.3 Size ~150MB (minimal Alpine + tools) Architecture AMD64 Registry webgrip/helm-deploy Dockerfile ops/docker/helm-deploy/Dockerfile","title":"Image Details"},{"location":"docker-images/helm-deploy/#installed-tools-versions","text":"","title":"Installed Tools &amp; Versions"},{"location":"docker-images/helm-deploy/#core-deployment-tools","text":"Tool Version Purpose kubectl v1.32.2 Kubernetes command-line tool Helm 3.17.1 Kubernetes package manager doctl 1.123.0 DigitalOcean CLI SOPS 3.7.3 Secrets encryption/decryption yq 4.45.1 YAML processing tool","title":"Core Deployment Tools"},{"location":"docker-images/helm-deploy/#system-utilities","text":"git - Version control for chart repositories curl/wget - HTTP clients for API interactions bash - Shell scripting environment tar - Archive handling gnupg - GPG encryption for SOPS openssl - SSL/TLS utilities ca-certificates - Certificate authority bundle","title":"System Utilities"},{"location":"docker-images/helm-deploy/#architecture","text":"","title":"Architecture"},{"location":"docker-images/helm-deploy/#deployment-workflow","text":"flowchart TD START[Deployment Start] --> FETCH[Fetch Helm Charts] FETCH --> DECRYPT[Decrypt Secrets with SOPS] DECRYPT --> TEMPLATE[Template with yq/Helm] TEMPLATE --> VALIDATE[Validate with kubectl] VALIDATE --> DEPLOY[Deploy with Helm] DEPLOY --> VERIFY[Verify Deployment] VERIFY --> END[Deployment Complete] subgraph \"Tools Used\" GIT[git] --> FETCH SOPS[sops] --> DECRYPT YQ[yq] --> TEMPLATE HELM[helm] --> TEMPLATE KUBECTL[kubectl] --> VALIDATE HELM --> DEPLOY KUBECTL --> VERIFY end","title":"Deployment Workflow"},{"location":"docker-images/helm-deploy/#multi-cloud-architecture","text":"flowchart LR subgraph \"Deployment Container\" HELM_DEPLOY[Helm Deploy Image] KUBECTL[kubectl] HELM[helm] DOCTL[doctl] SOPS[sops] end subgraph \"Target Environments\" DO_K8S[DigitalOcean Kubernetes] OTHER_K8S[Other K8s Clusters] end subgraph \"Configuration Sources\" CHARTS[Helm Charts Repository] SECRETS[Encrypted Secrets] CONFIGS[Configuration Files] end HELM_DEPLOY --> DO_K8S HELM_DEPLOY --> OTHER_K8S CHARTS --> HELM_DEPLOY SECRETS --> HELM_DEPLOY CONFIGS --> HELM_DEPLOY","title":"Multi-Cloud Architecture"},{"location":"docker-images/helm-deploy/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/helm-deploy/#basic-helm-deployment","text":"1 2 3 4 5 6 7 # Deploy a Helm chart to Kubernetes docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp","title":"Basic Helm Deployment"},{"location":"docker-images/helm-deploy/#digitalocean-kubernetes-deployment","text":"1 2 3 4 5 6 7 8 9 10 # Deploy to DigitalOcean managed Kubernetes docker run --rm \\ -v $( pwd ) :/workspace \\ -e DIGITALOCEAN_ACCESS_TOKEN = $DO_TOKEN \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" doctl kubernetes cluster kubeconfig save my-cluster helm upgrade --install myapp ./charts/myapp --namespace production \"","title":"DigitalOcean Kubernetes Deployment"},{"location":"docker-images/helm-deploy/#secrets-management-with-sops","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Decrypt secrets and deploy docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -v ~/.gnupg:/root/.gnupg \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Decrypt secrets sops -d secrets/production.enc.yaml > secrets/production.yaml # Deploy with decrypted secrets helm upgrade --install myapp ./charts/myapp \\ --values secrets/production.yaml \\ --namespace production \"","title":"Secrets Management with SOPS"},{"location":"docker-images/helm-deploy/#configuration-processing-with-yq","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Process YAML configurations before deployment docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Modify configuration using yq yq eval '.image.tag = \\\"v1.2.3\\\"' values.yaml > values-updated.yaml # Deploy with updated values helm upgrade --install myapp ./charts/myapp \\ --values values-updated.yaml \"","title":"Configuration Processing with yq"},{"location":"docker-images/helm-deploy/#cicd-integration","text":"","title":"CI/CD Integration"},{"location":"docker-images/helm-deploy/#github-actions-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # .github/workflows/deploy.yml name : Deploy to Kubernetes on : push : branches : [ main ] jobs : deploy : runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - uses : actions/checkout@v4 - name : Setup DigitalOcean CLI env : DIGITALOCEAN_ACCESS_TOKEN : ${{ secrets.DO_TOKEN }} run : | doctl kubernetes cluster kubeconfig save ${{ vars.CLUSTER_NAME }} - name : Decrypt secrets env : SOPS_AGE_KEY : ${{ secrets.SOPS_AGE_KEY }} run : | echo \"$SOPS_AGE_KEY\" > /tmp/age-key export SOPS_AGE_KEY_FILE=/tmp/age-key sops -d secrets/production.enc.yaml > secrets/production.yaml - name : Deploy application run : | helm dependency update ./charts/myapp helm upgrade --install myapp ./charts/myapp \\ --namespace production \\ --create-namespace \\ --values secrets/production.yaml \\ --set image.tag=${{ github.sha }} - name : Verify deployment run : | kubectl rollout status deployment/myapp -n production kubectl get pods -n production","title":"GitHub Actions Workflow"},{"location":"docker-images/helm-deploy/#multi-environment-deployment","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Deploy to multiple environments strategy : matrix : environment : [ staging , production ] steps : - name : Deploy to ${{ matrix.environment }} run : | # Setup environment-specific configuration export NAMESPACE=${{ matrix.environment }} export VALUES_FILE=values-${{ matrix.environment }}.yaml # Decrypt environment-specific secrets sops -d secrets/${{ matrix.environment }}.enc.yaml > secrets/${{ matrix.environment }}.yaml # Deploy with environment-specific settings helm upgrade --install myapp-${{ matrix.environment }} ./charts/myapp \\ --namespace $NAMESPACE \\ --create-namespace \\ --values $VALUES_FILE \\ --values secrets/${{ matrix.environment }}.yaml","title":"Multi-Environment Deployment"},{"location":"docker-images/helm-deploy/#configuration","text":"","title":"Configuration"},{"location":"docker-images/helm-deploy/#environment-variables","text":"Variable Purpose Example DIGITALOCEAN_ACCESS_TOKEN DigitalOcean API authentication dop_v1_xxx... KUBECONFIG Kubernetes configuration file path /root/.kube/config SOPS_AGE_KEY_FILE Age key file for SOPS decryption /tmp/age-key SOPS_AGE_KEY Age key content for SOPS AGE-SECRET-KEY-1XXX... HELM_CACHE_HOME Helm cache directory /tmp/.helm","title":"Environment Variables"},{"location":"docker-images/helm-deploy/#volume-mounts","text":"1 2 3 4 5 6 7 # Essential volume mounts for deployment docker run --rm \\ -v $( pwd ) :/workspace \\ # Project files -v ~/.kube:/root/.kube \\ # Kubernetes config -v ~/.gnupg:/root/.gnupg \\ # GPG keys for SOPS -v helm-cache:/tmp/.helm \\ # Helm cache webgrip/helm-deploy:latest","title":"Volume Mounts"},{"location":"docker-images/helm-deploy/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"docker-images/helm-deploy/#custom-helm-chart-development","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Create and test new Helm charts docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Create new chart helm create myapp # Validate chart helm lint myapp/ # Test template rendering helm template myapp myapp/ --values myapp/values.yaml # Package chart helm package myapp/ \"","title":"Custom Helm Chart Development"},{"location":"docker-images/helm-deploy/#blue-green-deployments","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Blue-green deployment strategy docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Deploy green version helm upgrade --install myapp-green ./charts/myapp \\ --set color=green \\ --set image.tag= $NEW_VERSION \\ --namespace production # Wait for green to be ready kubectl rollout status deployment/myapp-green -n production # Switch traffic (update service selector) yq eval '.spec.selector.color = \\\"green\\\"' service.yaml | kubectl apply -f - # Remove blue version after verification helm uninstall myapp-blue --namespace production \"","title":"Blue-Green Deployments"},{"location":"docker-images/helm-deploy/#disaster-recovery","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Backup current deployment docker run --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ bash -c \" # Get current values helm get values myapp -n production > backup/current-values.yaml # Get current manifests helm get manifest myapp -n production > backup/current-manifest.yaml # Backup persistent volumes kubectl get pv -o yaml > backup/persistent-volumes.yaml \"","title":"Disaster Recovery"},{"location":"docker-images/helm-deploy/#security-best-practices","text":"","title":"Security Best Practices"},{"location":"docker-images/helm-deploy/#secrets-management","text":"Use SOPS for encryption : 1 2 3 4 5 # Encrypt secrets file sops -e secrets/production.yaml > secrets/production.enc.yaml # Never commit unencrypted secrets echo \"secrets/*.yaml\" >> .gitignore Age keys for SOPS : 1 2 3 4 5 # Generate age key pair age-keygen -o age-key.txt # Use in CI/CD export SOPS_AGE_KEY_FILE = /tmp/age-key Kubernetes RBAC : 1 2 3 4 5 6 7 8 9 # Limit deployment permissions apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : helm-deployer rules : - apiGroups : [ \"apps\" , \"\" ] resources : [ \"deployments\" , \"services\" , \"configmaps\" ] verbs : [ \"get\" , \"list\" , \"create\" , \"update\" , \"patch\" ]","title":"Secrets Management"},{"location":"docker-images/helm-deploy/#network-security","text":"1 2 3 4 5 6 # Use private registries docker run --rm \\ -v ~/.docker:/root/.docker \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp \\ --set image.repository = private-registry.com/myapp","title":"Network Security"},{"location":"docker-images/helm-deploy/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/helm-deploy/#common-issues","text":"\"Unable to connect to the server\" 1 2 3 4 5 6 # Verify Kubernetes configuration docker run --rm -v ~/.kube:/root/.kube webgrip/helm-deploy:latest kubectl cluster-info # Check kubeconfig kubectl config view kubectl config current-context \"Helm chart not found\" 1 2 3 4 5 6 7 8 # Update Helm repositories helm repo update # Search for charts helm search repo myapp # Verify chart path ls -la charts/myapp/Chart.yaml SOPS decryption failures 1 2 3 4 5 # Verify age key echo \" $SOPS_AGE_KEY \" | age-keygen -y # Test decryption sops -d secrets/production.enc.yaml DigitalOcean authentication issues 1 2 3 4 5 6 # Verify token doctl auth list doctl account get # Test cluster access doctl kubernetes cluster list","title":"Common Issues"},{"location":"docker-images/helm-deploy/#performance-issues","text":"Slow Helm operations 1 2 3 4 5 6 7 8 # Use Helm cache export HELM_CACHE_HOME = /tmp/.helm helm repo update # Parallel operations helm upgrade --install app1 ./charts/app1 & helm upgrade --install app2 ./charts/app2 & wait Large chart deployments 1 2 3 4 5 # Increase timeout helm upgrade --install myapp ./charts/myapp --timeout 10m # Use atomic deployments helm upgrade --install myapp ./charts/myapp --atomic","title":"Performance Issues"},{"location":"docker-images/helm-deploy/#customization","text":"","title":"Customization"},{"location":"docker-images/helm-deploy/#adding-cloud-providers","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Dockerfile.custom FROM webgrip/helm-deploy:latest # Add AWS CLI RUN apk add --no-cache python3 py3-pip && \\ pip3 install awscli # Add Azure CLI RUN apk add --no-cache py3-pip && \\ pip3 install azure-cli # Add Google Cloud SDK RUN wget https://dl.google.com/dl/cloudsdk/channels/rapid/google-cloud-sdk.tar.gz && \\ tar -xzf google-cloud-sdk.tar.gz && \\ ./google-cloud-sdk/install.sh --quiet","title":"Adding Cloud Providers"},{"location":"docker-images/helm-deploy/#custom-helm-plugins","text":"1 2 3 4 5 # Install Helm plugins in derived image FROM webgrip/helm-deploy:latest RUN helm plugin install https://github.com/databus23/helm-diff RUN helm plugin install https://github.com/jkroepke/helm-secrets","title":"Custom Helm Plugins"},{"location":"docker-images/helm-deploy/#related-documentation","text":"Architecture Overview - Kubernetes deployment architecture CI/CD Pipeline - Automated image building GitHub Runner - Self-hosted runner that uses this image Operations Guide - Contributing improvements","title":"Related Documentation"},{"location":"docker-images/helm-deploy/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/helm-deploy/#update-schedule","text":"Tool versions : Updated quarterly or when security issues discovered Alpine base : Updated when new Alpine releases available Kubernetes compatibility : Tested against latest K8s versions","title":"Update Schedule"},{"location":"docker-images/helm-deploy/#version-matrix","text":"Image Version kubectl Helm Alpine Status latest v1.32.2 3.17.1 3.21.3 Active v1.32 v1.32.x 3.17.x 3.21.x Supported v1.31 v1.31.x 3.16.x 3.20.x Deprecated Assumption : Deployments primarily target DigitalOcean Kubernetes clusters. Support for other cloud providers (AWS EKS, GCP GKE, Azure AKS) may require additional CLI tools. Validation needed: Confirm cloud provider requirements with infrastructure team. Maintainer : WebGrip Ops Team Source : ops/docker/helm-deploy/Dockerfile Registry : webgrip/helm-deploy","title":"Version Matrix"},{"location":"docker-images/php-ci-runner/","text":"PHP CI Runner \u00b6 The PHP CI Runner provides a lightweight, reproducible container environment for running PHP CI tasks (Composer installs, unit tests, static analysis, etc.). Image Details \u00b6 Property Value Base Image ubuntu:noble PHP Version 8.3 (configurable via build arg) Registry webgrip/php-ci-runner Dockerfile ops/docker/php-ci-runner/Dockerfile Included Tooling \u00b6 PHP CLI + common extensions ( bcmath , curl , gd , intl , mbstring , mysql , soap , sockets , xml , zip ) Composer (installed to /usr/local/bin/composer ) Common CI utilities: git , curl , jq , patch , rsync , zip , unzip Usage Examples \u00b6 Run Composer + PHPUnit \u00b6 1 2 3 4 5 docker run --rm -it \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/php-ci-runner:latest \\ bash -lc \"composer install && vendor/bin/phpunit\" Use in GitHub Actions (container job) \u00b6 1 2 3 4 5 6 7 8 jobs : test : runs-on : ubuntu-latest container : webgrip/php-ci-runner:latest steps : - uses : actions/checkout@v4 - run : composer install - run : vendor/bin/phpunit Configuration \u00b6 Build Arguments \u00b6 1 ARG PHP_VERSION = 8 .3 Build with a different PHP version: 1 2 3 4 docker build \\ --build-arg PHP_VERSION = 8 .2 \\ -t webgrip/php-ci-runner:local \\ ops/docker/php-ci-runner/","title":"PHP CI Runner"},{"location":"docker-images/php-ci-runner/#php-ci-runner","text":"The PHP CI Runner provides a lightweight, reproducible container environment for running PHP CI tasks (Composer installs, unit tests, static analysis, etc.).","title":"PHP CI Runner"},{"location":"docker-images/php-ci-runner/#image-details","text":"Property Value Base Image ubuntu:noble PHP Version 8.3 (configurable via build arg) Registry webgrip/php-ci-runner Dockerfile ops/docker/php-ci-runner/Dockerfile","title":"Image Details"},{"location":"docker-images/php-ci-runner/#included-tooling","text":"PHP CLI + common extensions ( bcmath , curl , gd , intl , mbstring , mysql , soap , sockets , xml , zip ) Composer (installed to /usr/local/bin/composer ) Common CI utilities: git , curl , jq , patch , rsync , zip , unzip","title":"Included Tooling"},{"location":"docker-images/php-ci-runner/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/php-ci-runner/#run-composer-phpunit","text":"1 2 3 4 5 docker run --rm -it \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/php-ci-runner:latest \\ bash -lc \"composer install && vendor/bin/phpunit\"","title":"Run Composer + PHPUnit"},{"location":"docker-images/php-ci-runner/#use-in-github-actions-container-job","text":"1 2 3 4 5 6 7 8 jobs : test : runs-on : ubuntu-latest container : webgrip/php-ci-runner:latest steps : - uses : actions/checkout@v4 - run : composer install - run : vendor/bin/phpunit","title":"Use in GitHub Actions (container job)"},{"location":"docker-images/php-ci-runner/#configuration","text":"","title":"Configuration"},{"location":"docker-images/php-ci-runner/#build-arguments","text":"1 ARG PHP_VERSION = 8 .3 Build with a different PHP version: 1 2 3 4 docker build \\ --build-arg PHP_VERSION = 8 .2 \\ -t webgrip/php-ci-runner:local \\ ops/docker/php-ci-runner/","title":"Build Arguments"},{"location":"docker-images/playwright-runner/","text":"Playwright Runner \u00b6 A comprehensive end-to-end testing environment built on Microsoft's official Playwright image, enhanced with PHP tooling for full-stack web application testing. Purpose \u00b6 The Playwright Runner provides a complete browser testing environment that supports: \u2705 Multi-browser testing with Chromium, Firefox, and WebKit \u2705 PHP application testing with full PHP 8.3 ecosystem \u2705 Modern web testing with Playwright's powerful automation capabilities \u2705 CI/CD integration optimized for automated testing workflows \u2705 Security hardening with custom seccomp profile Image Details \u00b6 Property Value Base Image mcr.microsoft.com/playwright:v1.51.0-noble Node.js Version Latest LTS (from base image) PHP Version 8.3 with common extensions Browsers Chromium, Firefox, WebKit (pre-installed) Registry webgrip/playwright-runner Dockerfile ops/docker/playwright-runner/Dockerfile Installed Tools & Software \u00b6 Browser Testing Stack \u00b6 Tool Version Purpose Playwright v1.51.0 Browser automation framework Chromium Latest stable Chrome-based testing Firefox Latest stable Firefox-based testing WebKit Latest stable Safari-based testing Node.js LTS JavaScript runtime for Playwright PHP Development Stack \u00b6 Complete PHP 8.3 setup matching the GitHub Runner : Tool Version Purpose PHP 8.3 Server-side application runtime Composer Latest PHP dependency management Common Extensions 8.3.x bcmath, curl, gd, mysql, xml, zip, etc. System Utilities \u00b6 curl - HTTP client for API testing bash - Shell scripting environment jq - JSON processing for test data git - Version control integration yq - YAML processing for configuration rsync - File synchronization unzip - Archive handling Architecture \u00b6 Testing Workflow \u00b6 flowchart TD START[Test Execution Start] --> SETUP[Environment Setup] SETUP --> PHP_SETUP[PHP Application Setup] PHP_SETUP --> BROWSER_LAUNCH[Launch Browsers] BROWSER_LAUNCH --> TEST_RUN[Execute Playwright Tests] TEST_RUN --> PHP_API[Test PHP API Endpoints] PHP_API --> E2E[End-to-End Scenarios] E2E --> REPORT[Generate Test Reports] REPORT --> CLEANUP[Cleanup & Teardown] CLEANUP --> END[Test Completion] subgraph \"Runtime Environment\" PHP[PHP 8.3 Runtime] BROWSERS[Chromium + Firefox + WebKit] PLAYWRIGHT[Playwright Framework] COMPOSER[Composer Dependencies] end PHP_SETUP --> PHP BROWSER_LAUNCH --> BROWSERS TEST_RUN --> PLAYWRIGHT PHP_SETUP --> COMPOSER Security Architecture \u00b6 flowchart TB subgraph \"Container Security\" SECCOMP[Custom Seccomp Profile] ENTRYPOINT[Custom Entry Point] USER_NS[User Namespaces] end subgraph \"Browser Security\" SANDBOX[Browser Sandboxing] ISOLATION[Process Isolation] HEADLESS[Headless Mode] end subgraph \"Application Security\" PHP_SECURITY[PHP Security Settings] COMPOSER_AUDIT[Composer Audit] TEST_ISOLATION[Test Data Isolation] end SECCOMP --> SANDBOX USER_NS --> ISOLATION ENTRYPOINT --> PHP_SECURITY Usage Examples \u00b6 Basic Playwright Testing \u00b6 1 2 3 4 5 6 # Run Playwright tests in your project docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test PHP + Playwright Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Full-stack testing with PHP backend docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash -c \" # Setup PHP application composer install php artisan migrate --env=testing php artisan serve --port=8000 & # Wait for PHP server to start sleep 5 # Run end-to-end tests npx playwright test --config=playwright-e2e.config.js \" Headless vs. Headed Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Headless testing (default) docker run --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --headed = false # Headed testing with X11 forwarding (Linux) docker run --rm \\ -v $( pwd ) :/app \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e DISPLAY = $DISPLAY \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --headed = true Test Report Generation \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Generate HTML reports docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash -c \" npx playwright test --reporter=html # Copy reports to host cp -r playwright-report/ /app/reports/ \" CI/CD Integration \u00b6 GitHub Actions Workflow \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # .github/workflows/e2e-tests.yml name : End-to-End Tests on : [ push , pull_request ] jobs : e2e-tests : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest services : postgres : image : postgres:15 env : POSTGRES_PASSWORD : postgres POSTGRES_DB : testing options : >- --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5 steps : - uses : actions/checkout@v4 - name : Install PHP dependencies run : composer install --prefer-dist --no-progress - name : Setup application env : DB_CONNECTION : pgsql DB_HOST : postgres DB_DATABASE : testing DB_USERNAME : postgres DB_PASSWORD : postgres run : | php artisan key:generate php artisan migrate --force php artisan db:seed --force - name : Start PHP server run : php artisan serve --port=8000 & - name : Wait for server run : | timeout 30 bash -c 'until curl -f http://localhost:8000/health; do sleep 1; done' - name : Run Playwright tests run : | npx playwright test --config=playwright.config.js - name : Upload test reports uses : actions/upload-artifact@v3 if : always() with : name : playwright-report path : playwright-report/ Multi-Browser Testing \u00b6 1 2 3 4 5 6 7 8 9 10 # Test matrix for different browsers strategy : matrix : browser : [ chromium , firefox , webkit ] steps : - name : Run ${{ matrix.browser }} tests run : | npx playwright test --project=${{ matrix.browser }} \\ --reporter=json --output-dir=results-${{ matrix.browser }} Parallel Test Execution \u00b6 1 2 3 4 5 6 7 8 9 10 # Parallel execution with sharding strategy : matrix : shard : [ 1 , 2 , 3 , 4 ] steps : - name : Run tests (Shard ${{ matrix.shard }}) run : | npx playwright test --shard=${{ matrix.shard }}/4 \\ --reporter=json --output-dir=results-shard-${{ matrix.shard }} Configuration \u00b6 Environment Variables \u00b6 Variable Default Purpose TZ Europe/Amsterdam Container timezone NODE_ENV test Node.js environment PLAYWRIGHT_BROWSERS_PATH System default Browser installation path PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD 1 Skip browser download (pre-installed) Playwright Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // playwright.config.js module . exports = { testDir : './tests/e2e' , timeout : 30000 , retries : process . env . CI ? 2 : 0 , workers : process . env . CI ? 1 : undefined , use : { baseURL : 'http://localhost:8000' , trace : 'on-first-retry' , screenshot : 'only-on-failure' , video : 'retain-on-failure' , }, projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, ], webServer : { command : 'php artisan serve' , port : 8000 , reuseExistingServer : ! process . env . CI , }, }; Security Configuration \u00b6 The image includes a custom seccomp profile ( seccomp_profile.json ) that allows user namespaces required for browser sandboxing: 1 2 3 4 5 { \"comment\" : \"Allow create user namespaces\" , \"names\" : [ \"clone\" , \"setns\" , \"unshare\" ], \"action\" : \"SCMP_ACT_ALLOW\" } Advanced Testing Patterns \u00b6 API Testing Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/api-integration.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'API Integration' , () => { test ( 'should test PHP API endpoints' , async ({ request }) => { // Test PHP API directly const response = await request . get ( '/api/users' ); expect ( response . status ()). toBe ( 200 ); const users = await response . json (); expect ( users ). toHaveLength ( 3 ); }); test ( 'should test UI with API data' , async ({ page }) => { // Navigate to UI that consumes API await page . goto ( '/users' ); // Verify UI displays API data correctly await expect ( page . locator ( '[data-testid=\"user-list\"]' )). toContainText ( 'John Doe' ); }); }); Database Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/database-e2e.spec.js import { test , expect } from '@playwright/test' ; import { execSync } from 'child_process' ; test . describe ( 'Database E2E' , () => { test . beforeEach ( async () => { // Reset database state execSync ( 'php artisan migrate:fresh --seed' , { stdio : 'inherit' }); }); test ( 'should create user through UI and verify in database' , async ({ page }) => { await page . goto ( '/users/create' ); await page . fill ( '[name=\"name\"]' , 'Test User' ); await page . fill ( '[name=\"email\"]' , 'test@example.com' ); await page . click ( 'button[type=\"submit\"]' ); // Verify user was created const result = execSync ( 'php artisan tinker --execute=\"User::where(\\'email\\', \\'test@example.com\\')->count()\"' ). toString (); expect ( parseInt ( result . trim ())). toBe ( 1 ); }); }); Visual Regression Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // tests/visual-regression.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'Visual Regression' , () => { test ( 'should match homepage screenshot' , async ({ page }) => { await page . goto ( '/' ); // Take screenshot and compare with baseline await expect ( page ). toHaveScreenshot ( 'homepage.png' ); }); test ( 'should match mobile view' , async ({ page }) => { await page . setViewportSize ({ width : 375 , height : 667 }); await page . goto ( '/' ); await expect ( page ). toHaveScreenshot ( 'homepage-mobile.png' ); }); }); Performance Testing \u00b6 Load Testing Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // tests/performance.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'Performance' , () => { test ( 'should load homepage within performance budget' , async ({ page }) => { await page . goto ( '/' ); // Wait for network idle await page . waitForLoadState ( 'networkidle' ); // Check performance metrics const performanceEntries = await page . evaluate (() => { return JSON . stringify ( performance . getEntriesByType ( 'navigation' )); }); const navigation = JSON . parse ( performanceEntries )[ 0 ]; expect ( navigation . loadEventEnd - navigation . fetchStart ). toBeLessThan ( 3000 ); }); }); Troubleshooting \u00b6 Common Issues \u00b6 Browser launch failures 1 2 3 4 5 6 # Check browser installation docker run --rm webgrip/playwright-runner:latest \\ npx playwright --version # Verify browser binaries ls -la /ms-playwright/ Permission errors with seccomp 1 2 3 4 5 6 # Run with custom seccomp profile docker run --rm \\ --security-opt seccomp = /etc/seccomp_profile.json \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test PHP server connection issues 1 2 3 4 5 6 7 # Debug PHP server docker run -it --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest bash # Inside container php artisan serve --host = 0 .0.0.0 --port = 8000 & curl http://localhost:8000/health Test timeout issues 1 2 # Increase timeouts npx playwright test --timeout = 60000 --global-timeout = 300000 Debug Mode \u00b6 1 2 3 4 5 6 # Run with debug output docker run --rm \\ -e DEBUG = pw:* \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --debug Performance Issues \u00b6 1 2 3 4 5 6 7 8 # Run with reduced parallelism docker run --rm \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --workers = 1 # Use faster test runner npx playwright test --reporter = dot Customization \u00b6 Adding Custom Browsers \u00b6 1 2 3 4 5 6 # Dockerfile.custom FROM webgrip/playwright-runner:latest # Install additional browsers or versions RUN npx playwright install chrome@beta RUN npx playwright install firefox@beta Custom PHP Extensions \u00b6 1 2 3 4 5 6 7 8 9 10 11 FROM webgrip/playwright-runner:latest USER root # Add additional PHP extensions RUN apt-get update && apt-get install -y \\ php8.3-redis \\ php8.3-mongodb \\ && apt-get clean USER playwright Related Documentation \u00b6 Architecture Overview - E2E testing in our infrastructure GitHub Runner - Complementary CI runner with PHP support Testing Guide - Detailed Playwright configuration CI/CD Pipeline - Automated image building Maintenance \u00b6 Update Schedule \u00b6 Playwright version : Updated monthly following Playwright releases Browser versions : Updated automatically with Playwright updates PHP version : Synchronized with GitHub Runner updates Security patches : Applied immediately when available Version Compatibility \u00b6 Image Version Playwright Node.js PHP Status latest v1.51.0 20 LTS 8.3 Active v1.51 v1.51.x 20 LTS 8.3 Supported v1.50 v1.50.x 18 LTS 8.3 Deprecated Assumption : Tests primarily target web applications with PHP backends. Support for other backend technologies (Python, Ruby, etc.) may require additional runtime dependencies. Validation needed: Confirm backend technology requirements with development teams. Maintainer : WebGrip Ops Team Source : ops/docker/playwright-runner/Dockerfile Registry : webgrip/playwright-runner","title":"Playwright Runner"},{"location":"docker-images/playwright-runner/#playwright-runner","text":"A comprehensive end-to-end testing environment built on Microsoft's official Playwright image, enhanced with PHP tooling for full-stack web application testing.","title":"Playwright Runner"},{"location":"docker-images/playwright-runner/#purpose","text":"The Playwright Runner provides a complete browser testing environment that supports: \u2705 Multi-browser testing with Chromium, Firefox, and WebKit \u2705 PHP application testing with full PHP 8.3 ecosystem \u2705 Modern web testing with Playwright's powerful automation capabilities \u2705 CI/CD integration optimized for automated testing workflows \u2705 Security hardening with custom seccomp profile","title":"Purpose"},{"location":"docker-images/playwright-runner/#image-details","text":"Property Value Base Image mcr.microsoft.com/playwright:v1.51.0-noble Node.js Version Latest LTS (from base image) PHP Version 8.3 with common extensions Browsers Chromium, Firefox, WebKit (pre-installed) Registry webgrip/playwright-runner Dockerfile ops/docker/playwright-runner/Dockerfile","title":"Image Details"},{"location":"docker-images/playwright-runner/#installed-tools-software","text":"","title":"Installed Tools &amp; Software"},{"location":"docker-images/playwright-runner/#browser-testing-stack","text":"Tool Version Purpose Playwright v1.51.0 Browser automation framework Chromium Latest stable Chrome-based testing Firefox Latest stable Firefox-based testing WebKit Latest stable Safari-based testing Node.js LTS JavaScript runtime for Playwright","title":"Browser Testing Stack"},{"location":"docker-images/playwright-runner/#php-development-stack","text":"Complete PHP 8.3 setup matching the GitHub Runner : Tool Version Purpose PHP 8.3 Server-side application runtime Composer Latest PHP dependency management Common Extensions 8.3.x bcmath, curl, gd, mysql, xml, zip, etc.","title":"PHP Development Stack"},{"location":"docker-images/playwright-runner/#system-utilities","text":"curl - HTTP client for API testing bash - Shell scripting environment jq - JSON processing for test data git - Version control integration yq - YAML processing for configuration rsync - File synchronization unzip - Archive handling","title":"System Utilities"},{"location":"docker-images/playwright-runner/#architecture","text":"","title":"Architecture"},{"location":"docker-images/playwright-runner/#testing-workflow","text":"flowchart TD START[Test Execution Start] --> SETUP[Environment Setup] SETUP --> PHP_SETUP[PHP Application Setup] PHP_SETUP --> BROWSER_LAUNCH[Launch Browsers] BROWSER_LAUNCH --> TEST_RUN[Execute Playwright Tests] TEST_RUN --> PHP_API[Test PHP API Endpoints] PHP_API --> E2E[End-to-End Scenarios] E2E --> REPORT[Generate Test Reports] REPORT --> CLEANUP[Cleanup & Teardown] CLEANUP --> END[Test Completion] subgraph \"Runtime Environment\" PHP[PHP 8.3 Runtime] BROWSERS[Chromium + Firefox + WebKit] PLAYWRIGHT[Playwright Framework] COMPOSER[Composer Dependencies] end PHP_SETUP --> PHP BROWSER_LAUNCH --> BROWSERS TEST_RUN --> PLAYWRIGHT PHP_SETUP --> COMPOSER","title":"Testing Workflow"},{"location":"docker-images/playwright-runner/#security-architecture","text":"flowchart TB subgraph \"Container Security\" SECCOMP[Custom Seccomp Profile] ENTRYPOINT[Custom Entry Point] USER_NS[User Namespaces] end subgraph \"Browser Security\" SANDBOX[Browser Sandboxing] ISOLATION[Process Isolation] HEADLESS[Headless Mode] end subgraph \"Application Security\" PHP_SECURITY[PHP Security Settings] COMPOSER_AUDIT[Composer Audit] TEST_ISOLATION[Test Data Isolation] end SECCOMP --> SANDBOX USER_NS --> ISOLATION ENTRYPOINT --> PHP_SECURITY","title":"Security Architecture"},{"location":"docker-images/playwright-runner/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/playwright-runner/#basic-playwright-testing","text":"1 2 3 4 5 6 # Run Playwright tests in your project docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test","title":"Basic Playwright Testing"},{"location":"docker-images/playwright-runner/#php-playwright-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Full-stack testing with PHP backend docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash -c \" # Setup PHP application composer install php artisan migrate --env=testing php artisan serve --port=8000 & # Wait for PHP server to start sleep 5 # Run end-to-end tests npx playwright test --config=playwright-e2e.config.js \"","title":"PHP + Playwright Integration"},{"location":"docker-images/playwright-runner/#headless-vs-headed-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Headless testing (default) docker run --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --headed = false # Headed testing with X11 forwarding (Linux) docker run --rm \\ -v $( pwd ) :/app \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e DISPLAY = $DISPLAY \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --headed = true","title":"Headless vs. Headed Testing"},{"location":"docker-images/playwright-runner/#test-report-generation","text":"1 2 3 4 5 6 7 8 9 10 11 # Generate HTML reports docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash -c \" npx playwright test --reporter=html # Copy reports to host cp -r playwright-report/ /app/reports/ \"","title":"Test Report Generation"},{"location":"docker-images/playwright-runner/#cicd-integration","text":"","title":"CI/CD Integration"},{"location":"docker-images/playwright-runner/#github-actions-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # .github/workflows/e2e-tests.yml name : End-to-End Tests on : [ push , pull_request ] jobs : e2e-tests : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest services : postgres : image : postgres:15 env : POSTGRES_PASSWORD : postgres POSTGRES_DB : testing options : >- --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5 steps : - uses : actions/checkout@v4 - name : Install PHP dependencies run : composer install --prefer-dist --no-progress - name : Setup application env : DB_CONNECTION : pgsql DB_HOST : postgres DB_DATABASE : testing DB_USERNAME : postgres DB_PASSWORD : postgres run : | php artisan key:generate php artisan migrate --force php artisan db:seed --force - name : Start PHP server run : php artisan serve --port=8000 & - name : Wait for server run : | timeout 30 bash -c 'until curl -f http://localhost:8000/health; do sleep 1; done' - name : Run Playwright tests run : | npx playwright test --config=playwright.config.js - name : Upload test reports uses : actions/upload-artifact@v3 if : always() with : name : playwright-report path : playwright-report/","title":"GitHub Actions Workflow"},{"location":"docker-images/playwright-runner/#multi-browser-testing","text":"1 2 3 4 5 6 7 8 9 10 # Test matrix for different browsers strategy : matrix : browser : [ chromium , firefox , webkit ] steps : - name : Run ${{ matrix.browser }} tests run : | npx playwright test --project=${{ matrix.browser }} \\ --reporter=json --output-dir=results-${{ matrix.browser }}","title":"Multi-Browser Testing"},{"location":"docker-images/playwright-runner/#parallel-test-execution","text":"1 2 3 4 5 6 7 8 9 10 # Parallel execution with sharding strategy : matrix : shard : [ 1 , 2 , 3 , 4 ] steps : - name : Run tests (Shard ${{ matrix.shard }}) run : | npx playwright test --shard=${{ matrix.shard }}/4 \\ --reporter=json --output-dir=results-shard-${{ matrix.shard }}","title":"Parallel Test Execution"},{"location":"docker-images/playwright-runner/#configuration","text":"","title":"Configuration"},{"location":"docker-images/playwright-runner/#environment-variables","text":"Variable Default Purpose TZ Europe/Amsterdam Container timezone NODE_ENV test Node.js environment PLAYWRIGHT_BROWSERS_PATH System default Browser installation path PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD 1 Skip browser download (pre-installed)","title":"Environment Variables"},{"location":"docker-images/playwright-runner/#playwright-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // playwright.config.js module . exports = { testDir : './tests/e2e' , timeout : 30000 , retries : process . env . CI ? 2 : 0 , workers : process . env . CI ? 1 : undefined , use : { baseURL : 'http://localhost:8000' , trace : 'on-first-retry' , screenshot : 'only-on-failure' , video : 'retain-on-failure' , }, projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, ], webServer : { command : 'php artisan serve' , port : 8000 , reuseExistingServer : ! process . env . CI , }, };","title":"Playwright Configuration"},{"location":"docker-images/playwright-runner/#security-configuration","text":"The image includes a custom seccomp profile ( seccomp_profile.json ) that allows user namespaces required for browser sandboxing: 1 2 3 4 5 { \"comment\" : \"Allow create user namespaces\" , \"names\" : [ \"clone\" , \"setns\" , \"unshare\" ], \"action\" : \"SCMP_ACT_ALLOW\" }","title":"Security Configuration"},{"location":"docker-images/playwright-runner/#advanced-testing-patterns","text":"","title":"Advanced Testing Patterns"},{"location":"docker-images/playwright-runner/#api-testing-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/api-integration.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'API Integration' , () => { test ( 'should test PHP API endpoints' , async ({ request }) => { // Test PHP API directly const response = await request . get ( '/api/users' ); expect ( response . status ()). toBe ( 200 ); const users = await response . json (); expect ( users ). toHaveLength ( 3 ); }); test ( 'should test UI with API data' , async ({ page }) => { // Navigate to UI that consumes API await page . goto ( '/users' ); // Verify UI displays API data correctly await expect ( page . locator ( '[data-testid=\"user-list\"]' )). toContainText ( 'John Doe' ); }); });","title":"API Testing Integration"},{"location":"docker-images/playwright-runner/#database-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/database-e2e.spec.js import { test , expect } from '@playwright/test' ; import { execSync } from 'child_process' ; test . describe ( 'Database E2E' , () => { test . beforeEach ( async () => { // Reset database state execSync ( 'php artisan migrate:fresh --seed' , { stdio : 'inherit' }); }); test ( 'should create user through UI and verify in database' , async ({ page }) => { await page . goto ( '/users/create' ); await page . fill ( '[name=\"name\"]' , 'Test User' ); await page . fill ( '[name=\"email\"]' , 'test@example.com' ); await page . click ( 'button[type=\"submit\"]' ); // Verify user was created const result = execSync ( 'php artisan tinker --execute=\"User::where(\\'email\\', \\'test@example.com\\')->count()\"' ). toString (); expect ( parseInt ( result . trim ())). toBe ( 1 ); }); });","title":"Database Testing"},{"location":"docker-images/playwright-runner/#visual-regression-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // tests/visual-regression.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'Visual Regression' , () => { test ( 'should match homepage screenshot' , async ({ page }) => { await page . goto ( '/' ); // Take screenshot and compare with baseline await expect ( page ). toHaveScreenshot ( 'homepage.png' ); }); test ( 'should match mobile view' , async ({ page }) => { await page . setViewportSize ({ width : 375 , height : 667 }); await page . goto ( '/' ); await expect ( page ). toHaveScreenshot ( 'homepage-mobile.png' ); }); });","title":"Visual Regression Testing"},{"location":"docker-images/playwright-runner/#performance-testing","text":"","title":"Performance Testing"},{"location":"docker-images/playwright-runner/#load-testing-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // tests/performance.spec.js import { test , expect } from '@playwright/test' ; test . describe ( 'Performance' , () => { test ( 'should load homepage within performance budget' , async ({ page }) => { await page . goto ( '/' ); // Wait for network idle await page . waitForLoadState ( 'networkidle' ); // Check performance metrics const performanceEntries = await page . evaluate (() => { return JSON . stringify ( performance . getEntriesByType ( 'navigation' )); }); const navigation = JSON . parse ( performanceEntries )[ 0 ]; expect ( navigation . loadEventEnd - navigation . fetchStart ). toBeLessThan ( 3000 ); }); });","title":"Load Testing Integration"},{"location":"docker-images/playwright-runner/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/playwright-runner/#common-issues","text":"Browser launch failures 1 2 3 4 5 6 # Check browser installation docker run --rm webgrip/playwright-runner:latest \\ npx playwright --version # Verify browser binaries ls -la /ms-playwright/ Permission errors with seccomp 1 2 3 4 5 6 # Run with custom seccomp profile docker run --rm \\ --security-opt seccomp = /etc/seccomp_profile.json \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test PHP server connection issues 1 2 3 4 5 6 7 # Debug PHP server docker run -it --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest bash # Inside container php artisan serve --host = 0 .0.0.0 --port = 8000 & curl http://localhost:8000/health Test timeout issues 1 2 # Increase timeouts npx playwright test --timeout = 60000 --global-timeout = 300000","title":"Common Issues"},{"location":"docker-images/playwright-runner/#debug-mode","text":"1 2 3 4 5 6 # Run with debug output docker run --rm \\ -e DEBUG = pw:* \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --debug","title":"Debug Mode"},{"location":"docker-images/playwright-runner/#performance-issues","text":"1 2 3 4 5 6 7 8 # Run with reduced parallelism docker run --rm \\ -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test --workers = 1 # Use faster test runner npx playwright test --reporter = dot","title":"Performance Issues"},{"location":"docker-images/playwright-runner/#customization","text":"","title":"Customization"},{"location":"docker-images/playwright-runner/#adding-custom-browsers","text":"1 2 3 4 5 6 # Dockerfile.custom FROM webgrip/playwright-runner:latest # Install additional browsers or versions RUN npx playwright install chrome@beta RUN npx playwright install firefox@beta","title":"Adding Custom Browsers"},{"location":"docker-images/playwright-runner/#custom-php-extensions","text":"1 2 3 4 5 6 7 8 9 10 11 FROM webgrip/playwright-runner:latest USER root # Add additional PHP extensions RUN apt-get update && apt-get install -y \\ php8.3-redis \\ php8.3-mongodb \\ && apt-get clean USER playwright","title":"Custom PHP Extensions"},{"location":"docker-images/playwright-runner/#related-documentation","text":"Architecture Overview - E2E testing in our infrastructure GitHub Runner - Complementary CI runner with PHP support Testing Guide - Detailed Playwright configuration CI/CD Pipeline - Automated image building","title":"Related Documentation"},{"location":"docker-images/playwright-runner/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/playwright-runner/#update-schedule","text":"Playwright version : Updated monthly following Playwright releases Browser versions : Updated automatically with Playwright updates PHP version : Synchronized with GitHub Runner updates Security patches : Applied immediately when available","title":"Update Schedule"},{"location":"docker-images/playwright-runner/#version-compatibility","text":"Image Version Playwright Node.js PHP Status latest v1.51.0 20 LTS 8.3 Active v1.51 v1.51.x 20 LTS 8.3 Supported v1.50 v1.50.x 18 LTS 8.3 Deprecated Assumption : Tests primarily target web applications with PHP backends. Support for other backend technologies (Python, Ruby, etc.) may require additional runtime dependencies. Validation needed: Confirm backend technology requirements with development teams. Maintainer : WebGrip Ops Team Source : ops/docker/playwright-runner/Dockerfile Registry : webgrip/playwright-runner","title":"Version Compatibility"},{"location":"docker-images/rust-ci-runner/","text":"Rust CI Runner \u00b6 The Rust CI Runner provides a complete, optimized environment for Rust development, testing, and continuous integration workflows. Purpose \u00b6 This image serves as the primary development and CI environment for Rust projects at WebGrip, providing: \u2705 Complete Rust toolchain with stable and nightly versions \u2705 Essential Rust CLI tools for quality assurance and testing \u2705 Optimized build environment with caching and minimal overhead \u2705 Security-focused tooling for dependency auditing Image Details \u00b6 Property Value Base Image rust:1.87.0-slim-bookworm \u2192 debian:bookworm-slim Architecture Multi-platform (AMD64, ARM64) Size ~800MB (optimized via multi-stage build) Registry webgrip/rust-ci-runner Dockerfile ops/docker/rust-ci-runner/Dockerfile Installed Tools \u00b6 Core Rust Toolchain \u00b6 Rust Stable : Version 1.87.0 (configurable via build arg) Rust Nightly : Latest nightly toolchain Cargo : Package manager and build tool Rustfmt : Code formatting tool Clippy : Linting and static analysis Quality Assurance Tools \u00b6 Tool Purpose Installation Method cargo-audit Security vulnerability scanning cargo-binstall cargo-deny Dependency validation and licensing cargo-binstall cargo-outdated Dependency update checking cargo-binstall cargo-udeps Unused dependency detection cargo-binstall cargo-msrv Minimum Supported Rust Version checking cargo-binstall cargo-nextest Next-generation test runner cargo-binstall cargo-tarpaulin Code coverage analysis cargo-binstall cargo-sort Cargo.toml dependency sorting Source build System Dependencies \u00b6 Build tools : gcc , make , pkg-config SSL/TLS : libssl-dev , libssl3 Networking : ca-certificates , curl Architecture \u00b6 Multi-Stage Build Process \u00b6 flowchart TD subgraph \"Build Stage\" BUILD[rust:1.87.0-slim-bookworm] BUILD --> INSTALL[Install cargo-binstall] INSTALL --> TOOLS[Install Rust CLI tools] TOOLS --> SORT[Build cargo-sort from source] SORT --> NIGHTLY[Install nightly toolchain] NIGHTLY --> COMPONENTS[Add rustfmt + clippy] end subgraph \"Runtime Stage\" RUNTIME[debian:bookworm-slim] RUNTIME --> DEPS[Install runtime dependencies] DEPS --> COPY[Copy toolchains from build stage] COPY --> ENV[Set environment variables] end BUILD -.->|Multi-stage copy| RUNTIME Benefits of this approach : - Smaller final image : Build dependencies not included in runtime - Layer caching : Rust tools cached independently of project code - Security : Minimal attack surface with only runtime dependencies Usage Examples \u00b6 Basic Development \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Start interactive development environment docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash # Inside container - full Rust development workflow cargo new my-project cd my-project cargo build cargo test cargo clippy cargo fmt --check CI/CD Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # .github/workflows/rust-ci.yml name : Rust CI on : [ push , pull_request ] jobs : test : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - uses : actions/checkout@v4 - name : Run tests run : | cargo test --all-features cargo nextest run --all-features - name : Check code quality run : | cargo clippy -- -D warnings cargo fmt --check cargo audit cargo deny check - name : Generate coverage run : cargo tarpaulin --out xml Quality Assurance Workflow \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Complete quality check pipeline docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash -c \" echo '\ud83d\udd0d Checking code format...' cargo fmt --check echo '\ud83d\udcce Running clippy...' cargo clippy -- -D warnings echo '\ud83d\udd12 Auditing dependencies...' cargo audit echo '\ud83d\udce6 Checking for unused deps...' cargo +nightly udeps echo '\ud83d\udcca Generating coverage...' cargo tarpaulin --out html \" Configuration \u00b6 Environment Variables \u00b6 Variable Default Purpose CARGO_HOME /usr/local/cargo Cargo installation directory RUSTUP_HOME /usr/local/rustup Rustup installation directory PATH Includes cargo bin Tool discovery Build Arguments \u00b6 1 2 # Customize Rust version during build ARG RUST_VERSION = 1 .87.0 Build with custom Rust version: 1 2 docker build --build-arg RUST_VERSION = 1 .86.0 \\ -t my-rust-ci ops/docker/rust-ci-runner/ Best Practices \u00b6 Performance Optimization \u00b6 Use cargo workspaces for monorepos: 1 2 3 # Mount workspace root docker run -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner cargo build --workspace Cache dependencies between runs: 1 2 3 4 5 # Create named volume for cargo cache docker volume create cargo-cache docker run -v cargo-cache:/usr/local/cargo/registry \\ -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner cargo build Parallel testing with nextest: 1 2 3 docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner \\ cargo nextest run --jobs $( nproc ) Security Considerations \u00b6 Regular dependency audits : 1 2 3 # Include in CI pipeline cargo audit --deny warnings cargo deny check MSRV compliance : 1 2 # Verify minimum supported Rust version cargo msrv Dependency management : 1 2 3 4 # Check for outdated dependencies cargo outdated # Remove unused dependencies cargo +nightly udeps Troubleshooting \u00b6 Common Issues \u00b6 Build failures due to missing system dependencies 1 2 # Check if additional system packages needed apt list --installed | grep -E 'ssl|pkg-config|build' Permission errors with mounted volumes 1 2 3 4 # Fix ownership after container operations docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ chown -R $( id -u ) : $( id -g ) target/ Tool not found errors 1 2 3 # Verify tools are in PATH docker run --rm webgrip/rust-ci-runner:latest which cargo-audit docker run --rm webgrip/rust-ci-runner:latest cargo --list Performance Issues \u00b6 Slow builds - Use cargo cache volumes - Enable incremental compilation: CARGO_INCREMENTAL=1 - Use faster linker: Install lld in derived images Large image size - Image is already optimized via multi-stage build - For smaller images, consider cargo-chef pattern for layer caching Customization \u00b6 Extending the Image \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/rust-ci-runner:latest # Add project-specific tools RUN cargo binstall --no-confirm cargo-watch cargo-expand # Add system dependencies USER root RUN apt-get update && apt-get install -y postgresql-client USER rust # Set project-specific environment ENV DATABASE_URL = postgresql://test:test@localhost/test Adding Custom Tools \u00b6 1 2 3 4 5 6 7 8 9 10 # Run container and install additional tools docker run -it --name rust-dev webgrip/rust-ci-runner:latest bash # Inside container cargo install cargo-watch cargo binstall --no-confirm cargo-expand # Commit changes to new image docker commit rust-dev my-custom-rust-ci docker rm rust-dev Related Documentation \u00b6 Architecture Overview - How this fits into our infrastructure CI/CD Pipeline - Automated building of this image Contributing Images - How to improve this image Quick Start Guide - Get started quickly Maintenance \u00b6 Update Schedule \u00b6 Rust versions : Updated monthly following Rust release schedule CLI tools : Updated quarterly or when security issues discovered Base image : Updated when new Debian security releases available Version Policy \u00b6 latest : Latest stable Rust version <rust-version> : Specific Rust version (e.g., 1.87.0 ) <git-sha> : Specific build commit for reproducibility Assumption : Teams primarily use stable Rust toolchain. Nightly toolchain available but not default. Validation needed: Confirm if any projects require nightly-specific features. Maintainer : WebGrip Ops Team Source : ops/docker/rust-ci-runner/Dockerfile Registry : webgrip/rust-ci-runner","title":"Rust CI Runner"},{"location":"docker-images/rust-ci-runner/#rust-ci-runner","text":"The Rust CI Runner provides a complete, optimized environment for Rust development, testing, and continuous integration workflows.","title":"Rust CI Runner"},{"location":"docker-images/rust-ci-runner/#purpose","text":"This image serves as the primary development and CI environment for Rust projects at WebGrip, providing: \u2705 Complete Rust toolchain with stable and nightly versions \u2705 Essential Rust CLI tools for quality assurance and testing \u2705 Optimized build environment with caching and minimal overhead \u2705 Security-focused tooling for dependency auditing","title":"Purpose"},{"location":"docker-images/rust-ci-runner/#image-details","text":"Property Value Base Image rust:1.87.0-slim-bookworm \u2192 debian:bookworm-slim Architecture Multi-platform (AMD64, ARM64) Size ~800MB (optimized via multi-stage build) Registry webgrip/rust-ci-runner Dockerfile ops/docker/rust-ci-runner/Dockerfile","title":"Image Details"},{"location":"docker-images/rust-ci-runner/#installed-tools","text":"","title":"Installed Tools"},{"location":"docker-images/rust-ci-runner/#core-rust-toolchain","text":"Rust Stable : Version 1.87.0 (configurable via build arg) Rust Nightly : Latest nightly toolchain Cargo : Package manager and build tool Rustfmt : Code formatting tool Clippy : Linting and static analysis","title":"Core Rust Toolchain"},{"location":"docker-images/rust-ci-runner/#quality-assurance-tools","text":"Tool Purpose Installation Method cargo-audit Security vulnerability scanning cargo-binstall cargo-deny Dependency validation and licensing cargo-binstall cargo-outdated Dependency update checking cargo-binstall cargo-udeps Unused dependency detection cargo-binstall cargo-msrv Minimum Supported Rust Version checking cargo-binstall cargo-nextest Next-generation test runner cargo-binstall cargo-tarpaulin Code coverage analysis cargo-binstall cargo-sort Cargo.toml dependency sorting Source build","title":"Quality Assurance Tools"},{"location":"docker-images/rust-ci-runner/#system-dependencies","text":"Build tools : gcc , make , pkg-config SSL/TLS : libssl-dev , libssl3 Networking : ca-certificates , curl","title":"System Dependencies"},{"location":"docker-images/rust-ci-runner/#architecture","text":"","title":"Architecture"},{"location":"docker-images/rust-ci-runner/#multi-stage-build-process","text":"flowchart TD subgraph \"Build Stage\" BUILD[rust:1.87.0-slim-bookworm] BUILD --> INSTALL[Install cargo-binstall] INSTALL --> TOOLS[Install Rust CLI tools] TOOLS --> SORT[Build cargo-sort from source] SORT --> NIGHTLY[Install nightly toolchain] NIGHTLY --> COMPONENTS[Add rustfmt + clippy] end subgraph \"Runtime Stage\" RUNTIME[debian:bookworm-slim] RUNTIME --> DEPS[Install runtime dependencies] DEPS --> COPY[Copy toolchains from build stage] COPY --> ENV[Set environment variables] end BUILD -.->|Multi-stage copy| RUNTIME Benefits of this approach : - Smaller final image : Build dependencies not included in runtime - Layer caching : Rust tools cached independently of project code - Security : Minimal attack surface with only runtime dependencies","title":"Multi-Stage Build Process"},{"location":"docker-images/rust-ci-runner/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/rust-ci-runner/#basic-development","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Start interactive development environment docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash # Inside container - full Rust development workflow cargo new my-project cd my-project cargo build cargo test cargo clippy cargo fmt --check","title":"Basic Development"},{"location":"docker-images/rust-ci-runner/#cicd-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # .github/workflows/rust-ci.yml name : Rust CI on : [ push , pull_request ] jobs : test : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - uses : actions/checkout@v4 - name : Run tests run : | cargo test --all-features cargo nextest run --all-features - name : Check code quality run : | cargo clippy -- -D warnings cargo fmt --check cargo audit cargo deny check - name : Generate coverage run : cargo tarpaulin --out xml","title":"CI/CD Integration"},{"location":"docker-images/rust-ci-runner/#quality-assurance-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Complete quality check pipeline docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash -c \" echo '\ud83d\udd0d Checking code format...' cargo fmt --check echo '\ud83d\udcce Running clippy...' cargo clippy -- -D warnings echo '\ud83d\udd12 Auditing dependencies...' cargo audit echo '\ud83d\udce6 Checking for unused deps...' cargo +nightly udeps echo '\ud83d\udcca Generating coverage...' cargo tarpaulin --out html \"","title":"Quality Assurance Workflow"},{"location":"docker-images/rust-ci-runner/#configuration","text":"","title":"Configuration"},{"location":"docker-images/rust-ci-runner/#environment-variables","text":"Variable Default Purpose CARGO_HOME /usr/local/cargo Cargo installation directory RUSTUP_HOME /usr/local/rustup Rustup installation directory PATH Includes cargo bin Tool discovery","title":"Environment Variables"},{"location":"docker-images/rust-ci-runner/#build-arguments","text":"1 2 # Customize Rust version during build ARG RUST_VERSION = 1 .87.0 Build with custom Rust version: 1 2 docker build --build-arg RUST_VERSION = 1 .86.0 \\ -t my-rust-ci ops/docker/rust-ci-runner/","title":"Build Arguments"},{"location":"docker-images/rust-ci-runner/#best-practices","text":"","title":"Best Practices"},{"location":"docker-images/rust-ci-runner/#performance-optimization","text":"Use cargo workspaces for monorepos: 1 2 3 # Mount workspace root docker run -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner cargo build --workspace Cache dependencies between runs: 1 2 3 4 5 # Create named volume for cargo cache docker volume create cargo-cache docker run -v cargo-cache:/usr/local/cargo/registry \\ -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner cargo build Parallel testing with nextest: 1 2 3 docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner \\ cargo nextest run --jobs $( nproc )","title":"Performance Optimization"},{"location":"docker-images/rust-ci-runner/#security-considerations","text":"Regular dependency audits : 1 2 3 # Include in CI pipeline cargo audit --deny warnings cargo deny check MSRV compliance : 1 2 # Verify minimum supported Rust version cargo msrv Dependency management : 1 2 3 4 # Check for outdated dependencies cargo outdated # Remove unused dependencies cargo +nightly udeps","title":"Security Considerations"},{"location":"docker-images/rust-ci-runner/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/rust-ci-runner/#common-issues","text":"Build failures due to missing system dependencies 1 2 # Check if additional system packages needed apt list --installed | grep -E 'ssl|pkg-config|build' Permission errors with mounted volumes 1 2 3 4 # Fix ownership after container operations docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ chown -R $( id -u ) : $( id -g ) target/ Tool not found errors 1 2 3 # Verify tools are in PATH docker run --rm webgrip/rust-ci-runner:latest which cargo-audit docker run --rm webgrip/rust-ci-runner:latest cargo --list","title":"Common Issues"},{"location":"docker-images/rust-ci-runner/#performance-issues","text":"Slow builds - Use cargo cache volumes - Enable incremental compilation: CARGO_INCREMENTAL=1 - Use faster linker: Install lld in derived images Large image size - Image is already optimized via multi-stage build - For smaller images, consider cargo-chef pattern for layer caching","title":"Performance Issues"},{"location":"docker-images/rust-ci-runner/#customization","text":"","title":"Customization"},{"location":"docker-images/rust-ci-runner/#extending-the-image","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/rust-ci-runner:latest # Add project-specific tools RUN cargo binstall --no-confirm cargo-watch cargo-expand # Add system dependencies USER root RUN apt-get update && apt-get install -y postgresql-client USER rust # Set project-specific environment ENV DATABASE_URL = postgresql://test:test@localhost/test","title":"Extending the Image"},{"location":"docker-images/rust-ci-runner/#adding-custom-tools","text":"1 2 3 4 5 6 7 8 9 10 # Run container and install additional tools docker run -it --name rust-dev webgrip/rust-ci-runner:latest bash # Inside container cargo install cargo-watch cargo binstall --no-confirm cargo-expand # Commit changes to new image docker commit rust-dev my-custom-rust-ci docker rm rust-dev","title":"Adding Custom Tools"},{"location":"docker-images/rust-ci-runner/#related-documentation","text":"Architecture Overview - How this fits into our infrastructure CI/CD Pipeline - Automated building of this image Contributing Images - How to improve this image Quick Start Guide - Get started quickly","title":"Related Documentation"},{"location":"docker-images/rust-ci-runner/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/rust-ci-runner/#update-schedule","text":"Rust versions : Updated monthly following Rust release schedule CLI tools : Updated quarterly or when security issues discovered Base image : Updated when new Debian security releases available","title":"Update Schedule"},{"location":"docker-images/rust-ci-runner/#version-policy","text":"latest : Latest stable Rust version <rust-version> : Specific Rust version (e.g., 1.87.0 ) <git-sha> : Specific build commit for reproducibility Assumption : Teams primarily use stable Rust toolchain. Nightly toolchain available but not default. Validation needed: Confirm if any projects require nightly-specific features. Maintainer : WebGrip Ops Team Source : ops/docker/rust-ci-runner/Dockerfile Registry : webgrip/rust-ci-runner","title":"Version Policy"},{"location":"docker-images/rust-releaser/","text":"Rust Releaser \u00b6 A comprehensive release automation environment combining Node.js semantic-release tooling with Rust cross-compilation capabilities for automated software releases. Purpose \u00b6 The Rust Releaser provides automated release management for Rust projects by combining: \u2705 Semantic Release automation with conventional commits \u2705 Rust cross-compilation for multiple target platforms \u2705 Multi-format releases supporting crates, binaries, and container images \u2705 WASM support for WebAssembly compilation targets \u2705 Changelog generation with automated versioning \u2705 GitHub integration for releases and asset publishing Image Details \u00b6 Property Value Base Image node:22-bookworm-slim Size ~2GB (includes Rust toolchains + cross-compilation targets) Architecture AMD64 (with cross-compilation support) Registry webgrip/rust-releaser Dockerfile ops/docker/rust-releaser/Dockerfile Installed Tools & Software \u00b6 Release Automation Stack \u00b6 Tool Version Purpose Node.js 22 LTS Runtime for semantic-release semantic-release Latest Automated release management git-cliff Latest Changelog generation cargo-release Latest Rust-specific release tooling Rust Compilation Environment \u00b6 Component Purpose Rust Stable Primary compilation toolchain cross Cross-compilation tool cargo-binstall Fast binary installation wasm-bindgen-cli WebAssembly binding generation wasm32-unknown-unknown WebAssembly compilation target System Build Tools \u00b6 build-essential - GCC, make, and related build tools pkg-config - Library configuration libssl-dev - SSL/TLS development headers Docker CLI - Container image building QEMU - Cross-platform emulation for builds Semantic Release Plugins \u00b6 Plugin Purpose @semantic-release/changelog Generate changelog files @semantic-release/commit-analyzer Analyze commits for release type @semantic-release/exec Execute custom release commands @semantic-release/git Commit and tag releases @semantic-release/github GitHub release integration @semantic-release/release-notes-generator Generate release notes semantic-release-cargo Rust/Cargo integration semantic-release-github-actions-tags GitHub Actions tag management semantic-release-helm3 Helm chart releases Architecture \u00b6 Release Pipeline Architecture \u00b6 flowchart TD COMMIT[Conventional Commits] --> ANALYZE[Commit Analysis] ANALYZE --> VERSION[Version Calculation] VERSION --> CHANGELOG[Changelog Generation] CHANGELOG --> RUST_BUILD[Rust Compilation] RUST_BUILD --> CROSS_COMPILE[Cross Compilation] CROSS_COMPILE --> WASM_BUILD[WASM Compilation] WASM_BUILD --> PACKAGE[Package Assets] PACKAGE --> GITHUB_RELEASE[GitHub Release] GITHUB_RELEASE --> CRATES_IO[Crates.io Publish] CRATES_IO --> DOCKER_BUILD[Docker Image Build] DOCKER_BUILD --> NOTIFY[Notifications] subgraph \"Tools Used\" SEMANTIC[semantic-release] CARGO[cargo-release] CROSS[cross] WASM[wasm-bindgen] CLIFF[git-cliff] end ANALYZE --> SEMANTIC RUST_BUILD --> CARGO CROSS_COMPILE --> CROSS WASM_BUILD --> WASM CHANGELOG --> CLIFF Cross-Compilation Targets \u00b6 flowchart LR subgraph \"Source\" RUST_CODE[Rust Source Code] end subgraph \"Compilation Targets\" X86_64_LINUX[x86_64-unknown-linux-gnu] X86_64_WINDOWS[x86_64-pc-windows-gnu] X86_64_MACOS[x86_64-apple-darwin] ARM64_LINUX[aarch64-unknown-linux-gnu] WASM[wasm32-unknown-unknown] end subgraph \"Output Artifacts\" LINUX_BIN[Linux Binary] WINDOWS_EXE[Windows Executable] MACOS_BIN[macOS Binary] ARM_BIN[ARM64 Binary] WASM_PKG[WASM Package] end RUST_CODE --> X86_64_LINUX --> LINUX_BIN RUST_CODE --> X86_64_WINDOWS --> WINDOWS_EXE RUST_CODE --> X86_64_MACOS --> MACOS_BIN RUST_CODE --> ARM64_LINUX --> ARM_BIN RUST_CODE --> WASM --> WASM_PKG Usage Examples \u00b6 Basic Semantic Release \u00b6 1 2 3 4 5 6 7 8 # Run semantic release for Rust project docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e CARGO_REGISTRY_TOKEN = $CARGO_TOKEN \\ webgrip/rust-releaser:latest \\ npx semantic-release Cross-Platform Binary Release \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Build and release for multiple platforms docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build for multiple targets cross build --release --target x86_64-unknown-linux-gnu cross build --release --target x86_64-pc-windows-gnu cross build --release --target aarch64-unknown-linux-gnu # Create release with binaries npx semantic-release \" WASM Package Release \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Build and release WebAssembly package docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e NPM_TOKEN = $NPM_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build WASM package wasm-pack build --target web --out-dir pkg # Run semantic release npx semantic-release \" Docker Image Release \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Build and release Docker images docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e DOCKER_TOKEN = $DOCKER_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build Docker image docker build -t myapp:latest . # Run semantic release with Docker publishing npx semantic-release \" Configuration \u00b6 Semantic Release Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // .releaserc.json { \"branches\" : [ \"main\" ], \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , \"@semantic-release/changelog\" , [ \"semantic-release-cargo\" , { \"cargoWorkspace\" : true , \"publishToCargoRegistry\" : true } ], [ \"@semantic-release/exec\" , { \"prepareCmd\" : \"cross build --release --target x86_64-unknown-linux-gnu && cross build --release --target x86_64-pc-windows-gnu\" , \"publishCmd\" : \"echo 'Custom publish steps'\" } ], [ \"@semantic-release/github\" , { \"assets\" : [ { \"path\" : \"target/x86_64-unknown-linux-gnu/release/myapp\" , \"name\" : \"myapp-linux-amd64\" , \"label\" : \"Linux AMD64 Binary\" }, { \"path\" : \"target/x86_64-pc-windows-gnu/release/myapp.exe\" , \"name\" : \"myapp-windows-amd64.exe\" , \"label\" : \"Windows AMD64 Executable\" } ] } ], [ \"@semantic-release/git\" , { \"assets\" : [ \"CHANGELOG.md\" , \"Cargo.toml\" , \"Cargo.lock\" ], \"message\" : \"chore(release): ${nextRelease.version} [skip ci]\\n\\n${nextRelease.notes}\" } ] ] } Cross-Compilation Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Cross.toml [build] pre-build = [ \"dpkg --add-architecture $CROSS_DEB_ARCH\" , \"apt-get update && apt-get --assume-yes install libssl-dev:$CROSS_DEB_ARCH\" ] [target.x86_64-pc-windows-gnu] pre-build = [ \"apt-get update && apt-get install -y mingw-w64\" ] [target.aarch64-unknown-linux-gnu] pre-build = [ \"dpkg --add-architecture arm64\" , \"apt-get update && apt-get install -y libssl-dev:arm64\" ] Environment Variables \u00b6 Variable Required Purpose Example GITHUB_TOKEN Yes GitHub API authentication ghp_xxxxxxxxxxxx CARGO_REGISTRY_TOKEN Optional Crates.io publishing cio_xxxxxxxx NPM_TOKEN Optional npm package publishing npm_xxxxxxxx DOCKER_TOKEN Optional Docker Hub publishing dckr_pat_xxxxx CI/CD Integration \u00b6 GitHub Actions Workflow \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # .github/workflows/release.yml name : Release on : push : branches : [ main ] jobs : release : runs-on : ubuntu-latest container : webgrip/rust-releaser:latest steps : - uses : actions/checkout@v4 with : fetch-depth : 0 token : ${{ secrets.GITHUB_TOKEN }} - name : Configure Git run : | git config --global user.name \"github-actions[bot]\" git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\" - name : Cache Rust dependencies uses : actions/cache@v3 with : path : | ~/.cargo/registry ~/.cargo/git target/ key : ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }} - name : Build cross-platform binaries run : | cross build --release --target x86_64-unknown-linux-gnu cross build --release --target x86_64-pc-windows-gnu cross build --release --target aarch64-unknown-linux-gnu - name : Build WASM package run : | wasm-pack build --target web --out-dir pkg - name : Run semantic release env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} CARGO_REGISTRY_TOKEN : ${{ secrets.CARGO_REGISTRY_TOKEN }} NPM_TOKEN : ${{ secrets.NPM_TOKEN }} run : npx semantic-release Multi-Package Workspace Release \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Release multiple packages in workspace name : Workspace Release on : push : branches : [ main ] jobs : release : runs-on : ubuntu-latest container : webgrip/rust-releaser:latest strategy : matrix : package : [ core , cli , web ] steps : - uses : actions/checkout@v4 with : fetch-depth : 0 - name : Release ${{ matrix.package }} env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} CARGO_REGISTRY_TOKEN : ${{ secrets.CARGO_REGISTRY_TOKEN }} run : | cd packages/${{ matrix.package }} npx semantic-release Advanced Release Patterns \u00b6 Helm Chart Release \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // .releaserc.json for Helm chart { \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , [ \"semantic-release-helm3\" , { \"chartPath\" : \"./charts/myapp\" , \"registry\" : \"oci://registry-1.docker.io/webgrip\" } ], \"@semantic-release/github\" ] } Container Image with Binaries \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Multi-stage release with container images docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build optimized release binary cross build --release --target x86_64-unknown-linux-musl # Build minimal container image docker build -f Dockerfile.release -t myapp:latest . # Tag with semantic version NEXT_VERSION=\\$(npx semantic-release --dry-run | grep 'Published release' | awk '{print \\$3}') docker tag myapp:latest myapp:\\$NEXT_VERSION # Run full release npx semantic-release \" Beta/Pre-release Workflow \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // .releaserc.json with pre-release { \"branches\" : [ \"main\" , { \"name\" : \"beta\" , \"prerelease\" : true }, { \"name\" : \"alpha\" , \"prerelease\" : true } ], \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , [ \"semantic-release-cargo\" , { \"publishToCargoRegistry\" : false // Skip publishing pre-releases } ], \"@semantic-release/github\" ] } Performance Optimization \u00b6 Build Caching \u00b6 1 2 3 4 5 6 7 8 # Use build cache for faster releases docker run --rm \\ -v $( pwd ) :/workspace \\ -v rust-cache:/usr/local/cargo/registry \\ -v target-cache:/workspace/target \\ -w /workspace \\ webgrip/rust-releaser:latest \\ npx semantic-release Parallel Compilation \u00b6 1 2 3 4 5 6 7 # Enable parallel builds docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e CARGO_BUILD_JOBS = 4 \\ webgrip/rust-releaser:latest \\ cross build --release --target x86_64-unknown-linux-gnu Troubleshooting \u00b6 Common Issues \u00b6 Cross-compilation failures 1 2 3 4 5 6 7 8 # Debug cross-compilation docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-releaser:latest bash # Inside container cross build --target x86_64-pc-windows-gnu --verbose Semantic release authentication 1 2 3 # Verify tokens echo $GITHUB_TOKEN | cut -c1-10 curl -H \"Authorization: token $GITHUB_TOKEN \" https://api.github.com/user WASM build issues 1 2 3 4 5 6 # Check WASM tools wasm-pack --version rustup target list | grep wasm # Install missing targets rustup target add wasm32-unknown-unknown Docker socket access 1 2 3 4 5 # Verify Docker access docker run --rm \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/rust-releaser:latest \\ docker version Performance Issues \u00b6 Slow builds 1 2 3 4 5 6 # Use cached layers docker run --rm \\ -v $( pwd ) :/workspace \\ -v /usr/local/cargo/registry:/usr/local/cargo/registry \\ webgrip/rust-releaser:latest \\ cargo build --release Large artifacts 1 2 3 # Strip debug symbols cross build --release --target x86_64-unknown-linux-gnu strip target/x86_64-unknown-linux-gnu/release/myapp Security Considerations \u00b6 Token Management \u00b6 1 2 3 4 5 6 # Use short-lived tokens export GITHUB_TOKEN = $( gh auth token --expire 1h ) # Rotate registry tokens regularly cargo logout cargo login $NEW_CARGO_TOKEN Binary Verification \u00b6 1 2 # Generate checksums for releases sha256sum target/release/myapp > myapp.sha256 Container Security \u00b6 1 2 3 4 5 # Scan container images docker run --rm \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/rust-releaser:latest \\ docker scan myapp:latest Customization \u00b6 Project-specific Releaser \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/rust-releaser:latest # Add project-specific tools RUN cargo install cargo-audit cargo-deny # Custom release configuration COPY .releaserc.json /workspace/ COPY Cross.toml /workspace/ # Custom entry point COPY release-script.sh /usr/local/bin/ ENTRYPOINT [ \"/usr/local/bin/release-script.sh\" ] Extended Target Support \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM webgrip/rust-releaser:latest # Add additional cross-compilation targets RUN rustup target add \\ armv7-unknown-linux-gnueabihf \\ mips64-unknown-linux-gnuabi64 \\ powerpc64-unknown-linux-gnu # Install additional cross-compilation tools RUN apt-get update && apt-get install -y \\ gcc-arm-linux-gnueabihf \\ gcc-mips64-linux-gnuabi64 \\ gcc-powerpc64-linux-gnu Related Documentation \u00b6 Architecture Overview - Release automation in our infrastructure Rust CI Runner - Development and testing environment CI/CD Pipeline - Automated building and releasing GitHub Runner - Self-hosted runner for releases Maintenance \u00b6 Update Schedule \u00b6 semantic-release : Updated monthly for new features and security Rust toolchain : Updated quarterly following Rust release schedule Node.js : Updated when new LTS versions available Cross-compilation tools : Updated as needed for platform support Version Compatibility \u00b6 Image Version semantic-release Rust Node.js Status latest Latest Stable 22 LTS Active v2.x v2.x Stable 22 LTS Supported v1.x v1.x Stable 20 LTS Deprecated Assumption : Release workflows primarily target GitHub and crates.io. Support for additional registries (private registries, alternative Git providers) may require additional configuration. Validation needed: Confirm release target requirements with development teams. Maintainer : WebGrip Ops Team Source : ops/docker/rust-releaser/Dockerfile Registry : webgrip/rust-releaser","title":"Rust Releaser"},{"location":"docker-images/rust-releaser/#rust-releaser","text":"A comprehensive release automation environment combining Node.js semantic-release tooling with Rust cross-compilation capabilities for automated software releases.","title":"Rust Releaser"},{"location":"docker-images/rust-releaser/#purpose","text":"The Rust Releaser provides automated release management for Rust projects by combining: \u2705 Semantic Release automation with conventional commits \u2705 Rust cross-compilation for multiple target platforms \u2705 Multi-format releases supporting crates, binaries, and container images \u2705 WASM support for WebAssembly compilation targets \u2705 Changelog generation with automated versioning \u2705 GitHub integration for releases and asset publishing","title":"Purpose"},{"location":"docker-images/rust-releaser/#image-details","text":"Property Value Base Image node:22-bookworm-slim Size ~2GB (includes Rust toolchains + cross-compilation targets) Architecture AMD64 (with cross-compilation support) Registry webgrip/rust-releaser Dockerfile ops/docker/rust-releaser/Dockerfile","title":"Image Details"},{"location":"docker-images/rust-releaser/#installed-tools-software","text":"","title":"Installed Tools &amp; Software"},{"location":"docker-images/rust-releaser/#release-automation-stack","text":"Tool Version Purpose Node.js 22 LTS Runtime for semantic-release semantic-release Latest Automated release management git-cliff Latest Changelog generation cargo-release Latest Rust-specific release tooling","title":"Release Automation Stack"},{"location":"docker-images/rust-releaser/#rust-compilation-environment","text":"Component Purpose Rust Stable Primary compilation toolchain cross Cross-compilation tool cargo-binstall Fast binary installation wasm-bindgen-cli WebAssembly binding generation wasm32-unknown-unknown WebAssembly compilation target","title":"Rust Compilation Environment"},{"location":"docker-images/rust-releaser/#system-build-tools","text":"build-essential - GCC, make, and related build tools pkg-config - Library configuration libssl-dev - SSL/TLS development headers Docker CLI - Container image building QEMU - Cross-platform emulation for builds","title":"System Build Tools"},{"location":"docker-images/rust-releaser/#semantic-release-plugins","text":"Plugin Purpose @semantic-release/changelog Generate changelog files @semantic-release/commit-analyzer Analyze commits for release type @semantic-release/exec Execute custom release commands @semantic-release/git Commit and tag releases @semantic-release/github GitHub release integration @semantic-release/release-notes-generator Generate release notes semantic-release-cargo Rust/Cargo integration semantic-release-github-actions-tags GitHub Actions tag management semantic-release-helm3 Helm chart releases","title":"Semantic Release Plugins"},{"location":"docker-images/rust-releaser/#architecture","text":"","title":"Architecture"},{"location":"docker-images/rust-releaser/#release-pipeline-architecture","text":"flowchart TD COMMIT[Conventional Commits] --> ANALYZE[Commit Analysis] ANALYZE --> VERSION[Version Calculation] VERSION --> CHANGELOG[Changelog Generation] CHANGELOG --> RUST_BUILD[Rust Compilation] RUST_BUILD --> CROSS_COMPILE[Cross Compilation] CROSS_COMPILE --> WASM_BUILD[WASM Compilation] WASM_BUILD --> PACKAGE[Package Assets] PACKAGE --> GITHUB_RELEASE[GitHub Release] GITHUB_RELEASE --> CRATES_IO[Crates.io Publish] CRATES_IO --> DOCKER_BUILD[Docker Image Build] DOCKER_BUILD --> NOTIFY[Notifications] subgraph \"Tools Used\" SEMANTIC[semantic-release] CARGO[cargo-release] CROSS[cross] WASM[wasm-bindgen] CLIFF[git-cliff] end ANALYZE --> SEMANTIC RUST_BUILD --> CARGO CROSS_COMPILE --> CROSS WASM_BUILD --> WASM CHANGELOG --> CLIFF","title":"Release Pipeline Architecture"},{"location":"docker-images/rust-releaser/#cross-compilation-targets","text":"flowchart LR subgraph \"Source\" RUST_CODE[Rust Source Code] end subgraph \"Compilation Targets\" X86_64_LINUX[x86_64-unknown-linux-gnu] X86_64_WINDOWS[x86_64-pc-windows-gnu] X86_64_MACOS[x86_64-apple-darwin] ARM64_LINUX[aarch64-unknown-linux-gnu] WASM[wasm32-unknown-unknown] end subgraph \"Output Artifacts\" LINUX_BIN[Linux Binary] WINDOWS_EXE[Windows Executable] MACOS_BIN[macOS Binary] ARM_BIN[ARM64 Binary] WASM_PKG[WASM Package] end RUST_CODE --> X86_64_LINUX --> LINUX_BIN RUST_CODE --> X86_64_WINDOWS --> WINDOWS_EXE RUST_CODE --> X86_64_MACOS --> MACOS_BIN RUST_CODE --> ARM64_LINUX --> ARM_BIN RUST_CODE --> WASM --> WASM_PKG","title":"Cross-Compilation Targets"},{"location":"docker-images/rust-releaser/#usage-examples","text":"","title":"Usage Examples"},{"location":"docker-images/rust-releaser/#basic-semantic-release","text":"1 2 3 4 5 6 7 8 # Run semantic release for Rust project docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e CARGO_REGISTRY_TOKEN = $CARGO_TOKEN \\ webgrip/rust-releaser:latest \\ npx semantic-release","title":"Basic Semantic Release"},{"location":"docker-images/rust-releaser/#cross-platform-binary-release","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Build and release for multiple platforms docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build for multiple targets cross build --release --target x86_64-unknown-linux-gnu cross build --release --target x86_64-pc-windows-gnu cross build --release --target aarch64-unknown-linux-gnu # Create release with binaries npx semantic-release \"","title":"Cross-Platform Binary Release"},{"location":"docker-images/rust-releaser/#wasm-package-release","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Build and release WebAssembly package docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e NPM_TOKEN = $NPM_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build WASM package wasm-pack build --target web --out-dir pkg # Run semantic release npx semantic-release \"","title":"WASM Package Release"},{"location":"docker-images/rust-releaser/#docker-image-release","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Build and release Docker images docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ -e DOCKER_TOKEN = $DOCKER_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build Docker image docker build -t myapp:latest . # Run semantic release with Docker publishing npx semantic-release \"","title":"Docker Image Release"},{"location":"docker-images/rust-releaser/#configuration","text":"","title":"Configuration"},{"location":"docker-images/rust-releaser/#semantic-release-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // .releaserc.json { \"branches\" : [ \"main\" ], \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , \"@semantic-release/changelog\" , [ \"semantic-release-cargo\" , { \"cargoWorkspace\" : true , \"publishToCargoRegistry\" : true } ], [ \"@semantic-release/exec\" , { \"prepareCmd\" : \"cross build --release --target x86_64-unknown-linux-gnu && cross build --release --target x86_64-pc-windows-gnu\" , \"publishCmd\" : \"echo 'Custom publish steps'\" } ], [ \"@semantic-release/github\" , { \"assets\" : [ { \"path\" : \"target/x86_64-unknown-linux-gnu/release/myapp\" , \"name\" : \"myapp-linux-amd64\" , \"label\" : \"Linux AMD64 Binary\" }, { \"path\" : \"target/x86_64-pc-windows-gnu/release/myapp.exe\" , \"name\" : \"myapp-windows-amd64.exe\" , \"label\" : \"Windows AMD64 Executable\" } ] } ], [ \"@semantic-release/git\" , { \"assets\" : [ \"CHANGELOG.md\" , \"Cargo.toml\" , \"Cargo.lock\" ], \"message\" : \"chore(release): ${nextRelease.version} [skip ci]\\n\\n${nextRelease.notes}\" } ] ] }","title":"Semantic Release Configuration"},{"location":"docker-images/rust-releaser/#cross-compilation-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Cross.toml [build] pre-build = [ \"dpkg --add-architecture $CROSS_DEB_ARCH\" , \"apt-get update && apt-get --assume-yes install libssl-dev:$CROSS_DEB_ARCH\" ] [target.x86_64-pc-windows-gnu] pre-build = [ \"apt-get update && apt-get install -y mingw-w64\" ] [target.aarch64-unknown-linux-gnu] pre-build = [ \"dpkg --add-architecture arm64\" , \"apt-get update && apt-get install -y libssl-dev:arm64\" ]","title":"Cross-Compilation Configuration"},{"location":"docker-images/rust-releaser/#environment-variables","text":"Variable Required Purpose Example GITHUB_TOKEN Yes GitHub API authentication ghp_xxxxxxxxxxxx CARGO_REGISTRY_TOKEN Optional Crates.io publishing cio_xxxxxxxx NPM_TOKEN Optional npm package publishing npm_xxxxxxxx DOCKER_TOKEN Optional Docker Hub publishing dckr_pat_xxxxx","title":"Environment Variables"},{"location":"docker-images/rust-releaser/#cicd-integration","text":"","title":"CI/CD Integration"},{"location":"docker-images/rust-releaser/#github-actions-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # .github/workflows/release.yml name : Release on : push : branches : [ main ] jobs : release : runs-on : ubuntu-latest container : webgrip/rust-releaser:latest steps : - uses : actions/checkout@v4 with : fetch-depth : 0 token : ${{ secrets.GITHUB_TOKEN }} - name : Configure Git run : | git config --global user.name \"github-actions[bot]\" git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\" - name : Cache Rust dependencies uses : actions/cache@v3 with : path : | ~/.cargo/registry ~/.cargo/git target/ key : ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }} - name : Build cross-platform binaries run : | cross build --release --target x86_64-unknown-linux-gnu cross build --release --target x86_64-pc-windows-gnu cross build --release --target aarch64-unknown-linux-gnu - name : Build WASM package run : | wasm-pack build --target web --out-dir pkg - name : Run semantic release env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} CARGO_REGISTRY_TOKEN : ${{ secrets.CARGO_REGISTRY_TOKEN }} NPM_TOKEN : ${{ secrets.NPM_TOKEN }} run : npx semantic-release","title":"GitHub Actions Workflow"},{"location":"docker-images/rust-releaser/#multi-package-workspace-release","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Release multiple packages in workspace name : Workspace Release on : push : branches : [ main ] jobs : release : runs-on : ubuntu-latest container : webgrip/rust-releaser:latest strategy : matrix : package : [ core , cli , web ] steps : - uses : actions/checkout@v4 with : fetch-depth : 0 - name : Release ${{ matrix.package }} env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} CARGO_REGISTRY_TOKEN : ${{ secrets.CARGO_REGISTRY_TOKEN }} run : | cd packages/${{ matrix.package }} npx semantic-release","title":"Multi-Package Workspace Release"},{"location":"docker-images/rust-releaser/#advanced-release-patterns","text":"","title":"Advanced Release Patterns"},{"location":"docker-images/rust-releaser/#helm-chart-release","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // .releaserc.json for Helm chart { \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , [ \"semantic-release-helm3\" , { \"chartPath\" : \"./charts/myapp\" , \"registry\" : \"oci://registry-1.docker.io/webgrip\" } ], \"@semantic-release/github\" ] }","title":"Helm Chart Release"},{"location":"docker-images/rust-releaser/#container-image-with-binaries","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Multi-stage release with container images docker run --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ bash -c \" # Build optimized release binary cross build --release --target x86_64-unknown-linux-musl # Build minimal container image docker build -f Dockerfile.release -t myapp:latest . # Tag with semantic version NEXT_VERSION=\\$(npx semantic-release --dry-run | grep 'Published release' | awk '{print \\$3}') docker tag myapp:latest myapp:\\$NEXT_VERSION # Run full release npx semantic-release \"","title":"Container Image with Binaries"},{"location":"docker-images/rust-releaser/#betapre-release-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // .releaserc.json with pre-release { \"branches\" : [ \"main\" , { \"name\" : \"beta\" , \"prerelease\" : true }, { \"name\" : \"alpha\" , \"prerelease\" : true } ], \"plugins\" : [ \"@semantic-release/commit-analyzer\" , \"@semantic-release/release-notes-generator\" , [ \"semantic-release-cargo\" , { \"publishToCargoRegistry\" : false // Skip publishing pre-releases } ], \"@semantic-release/github\" ] }","title":"Beta/Pre-release Workflow"},{"location":"docker-images/rust-releaser/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"docker-images/rust-releaser/#build-caching","text":"1 2 3 4 5 6 7 8 # Use build cache for faster releases docker run --rm \\ -v $( pwd ) :/workspace \\ -v rust-cache:/usr/local/cargo/registry \\ -v target-cache:/workspace/target \\ -w /workspace \\ webgrip/rust-releaser:latest \\ npx semantic-release","title":"Build Caching"},{"location":"docker-images/rust-releaser/#parallel-compilation","text":"1 2 3 4 5 6 7 # Enable parallel builds docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e CARGO_BUILD_JOBS = 4 \\ webgrip/rust-releaser:latest \\ cross build --release --target x86_64-unknown-linux-gnu","title":"Parallel Compilation"},{"location":"docker-images/rust-releaser/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docker-images/rust-releaser/#common-issues","text":"Cross-compilation failures 1 2 3 4 5 6 7 8 # Debug cross-compilation docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-releaser:latest bash # Inside container cross build --target x86_64-pc-windows-gnu --verbose Semantic release authentication 1 2 3 # Verify tokens echo $GITHUB_TOKEN | cut -c1-10 curl -H \"Authorization: token $GITHUB_TOKEN \" https://api.github.com/user WASM build issues 1 2 3 4 5 6 # Check WASM tools wasm-pack --version rustup target list | grep wasm # Install missing targets rustup target add wasm32-unknown-unknown Docker socket access 1 2 3 4 5 # Verify Docker access docker run --rm \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/rust-releaser:latest \\ docker version","title":"Common Issues"},{"location":"docker-images/rust-releaser/#performance-issues","text":"Slow builds 1 2 3 4 5 6 # Use cached layers docker run --rm \\ -v $( pwd ) :/workspace \\ -v /usr/local/cargo/registry:/usr/local/cargo/registry \\ webgrip/rust-releaser:latest \\ cargo build --release Large artifacts 1 2 3 # Strip debug symbols cross build --release --target x86_64-unknown-linux-gnu strip target/x86_64-unknown-linux-gnu/release/myapp","title":"Performance Issues"},{"location":"docker-images/rust-releaser/#security-considerations","text":"","title":"Security Considerations"},{"location":"docker-images/rust-releaser/#token-management","text":"1 2 3 4 5 6 # Use short-lived tokens export GITHUB_TOKEN = $( gh auth token --expire 1h ) # Rotate registry tokens regularly cargo logout cargo login $NEW_CARGO_TOKEN","title":"Token Management"},{"location":"docker-images/rust-releaser/#binary-verification","text":"1 2 # Generate checksums for releases sha256sum target/release/myapp > myapp.sha256","title":"Binary Verification"},{"location":"docker-images/rust-releaser/#container-security","text":"1 2 3 4 5 # Scan container images docker run --rm \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/rust-releaser:latest \\ docker scan myapp:latest","title":"Container Security"},{"location":"docker-images/rust-releaser/#customization","text":"","title":"Customization"},{"location":"docker-images/rust-releaser/#project-specific-releaser","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Dockerfile.custom FROM webgrip/rust-releaser:latest # Add project-specific tools RUN cargo install cargo-audit cargo-deny # Custom release configuration COPY .releaserc.json /workspace/ COPY Cross.toml /workspace/ # Custom entry point COPY release-script.sh /usr/local/bin/ ENTRYPOINT [ \"/usr/local/bin/release-script.sh\" ]","title":"Project-specific Releaser"},{"location":"docker-images/rust-releaser/#extended-target-support","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 FROM webgrip/rust-releaser:latest # Add additional cross-compilation targets RUN rustup target add \\ armv7-unknown-linux-gnueabihf \\ mips64-unknown-linux-gnuabi64 \\ powerpc64-unknown-linux-gnu # Install additional cross-compilation tools RUN apt-get update && apt-get install -y \\ gcc-arm-linux-gnueabihf \\ gcc-mips64-linux-gnuabi64 \\ gcc-powerpc64-linux-gnu","title":"Extended Target Support"},{"location":"docker-images/rust-releaser/#related-documentation","text":"Architecture Overview - Release automation in our infrastructure Rust CI Runner - Development and testing environment CI/CD Pipeline - Automated building and releasing GitHub Runner - Self-hosted runner for releases","title":"Related Documentation"},{"location":"docker-images/rust-releaser/#maintenance","text":"","title":"Maintenance"},{"location":"docker-images/rust-releaser/#update-schedule","text":"semantic-release : Updated monthly for new features and security Rust toolchain : Updated quarterly following Rust release schedule Node.js : Updated when new LTS versions available Cross-compilation tools : Updated as needed for platform support","title":"Update Schedule"},{"location":"docker-images/rust-releaser/#version-compatibility","text":"Image Version semantic-release Rust Node.js Status latest Latest Stable 22 LTS Active v2.x v2.x Stable 22 LTS Supported v1.x v1.x Stable 20 LTS Deprecated Assumption : Release workflows primarily target GitHub and crates.io. Support for additional registries (private registries, alternative Git providers) may require additional configuration. Validation needed: Confirm release target requirements with development teams. Maintainer : WebGrip Ops Team Source : ops/docker/rust-releaser/Dockerfile Registry : webgrip/rust-releaser","title":"Version Compatibility"},{"location":"operations/building-locally/","text":"Building Locally \u00b6 Guide for building and testing Docker images locally during development and maintenance. Overview \u00b6 Local building capabilities enable: \u2705 Development iteration without pushing to GitHub \u2705 Testing changes before committing to version control \u2705 Debugging build issues with full access to build context \u2705 Custom image variants for specific use cases \u2705 Offline development when internet connectivity is limited Prerequisites \u00b6 Required Tools \u00b6 Tool Purpose Installation Docker Container building and runtime Install Docker Docker Compose Multi-container orchestration Included with Docker Desktop Git Source code management Install Git Make (optional) Build automation sudo apt install make (Linux) System Requirements \u00b6 CPU : 2+ cores recommended for parallel builds RAM : 4GB minimum, 8GB recommended Storage : 20GB free space for Docker images and build cache Network : Reliable internet for base image downloads Repository Setup \u00b6 Clone Repository \u00b6 1 2 3 4 5 6 # Clone the infrastructure repository git clone https://github.com/webgrip/infrastructure.git cd infrastructure # Verify directory structure ls -la ops/docker/ Environment Setup \u00b6 1 2 3 4 5 6 7 8 9 # Create local environment file (optional) cat > .env.local << EOF DOCKER_REGISTRY=localhost:5000 BUILD_ARGS=\"--no-cache\" PARALLEL_BUILDS=4 EOF # Source environment source .env.local Basic Building \u00b6 Single Image Build \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Build specific image docker build -t webgrip/rust-ci-runner:local ops/docker/rust-ci-runner/ # Build with specific tag docker build -t my-rust-ci:test ops/docker/rust-ci-runner/ # Build with build arguments docker build \\ --build-arg RUST_VERSION = 1 .86.0 \\ -t webgrip/rust-ci-runner:1.86 \\ ops/docker/rust-ci-runner/ Using Docker Compose \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Build all images defined in docker-compose.yml docker-compose build # Build specific service docker-compose build rust-ci-runner # Build with no cache docker-compose build --no-cache # Build in parallel docker-compose build --parallel Build Context Verification \u00b6 1 2 3 4 5 6 7 8 # Check build context size du -sh ops/docker/rust-ci-runner/ # List files in build context find ops/docker/rust-ci-runner/ -type f # Verify Dockerfile syntax docker build --dry-run ops/docker/rust-ci-runner/ Advanced Building \u00b6 Multi-stage Build Optimization \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Example optimization for development FROM rust:1.87.0-slim-bookworm AS development # Add development-specific tools RUN apt-get update && apt-get install -y \\ gdb lldb strace valgrind FROM rust:1.87.0-slim-bookworm AS production # Production optimizations RUN apt-get update && apt-get install -y --no-install-recommends \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* 1 2 3 # Build specific stage docker build --target development -t rust-ci:dev ops/docker/rust-ci-runner/ docker build --target production -t rust-ci:prod ops/docker/rust-ci-runner/ Build Arguments and Customization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Common build arguments docker build \\ --build-arg RUST_VERSION = 1 .87.0 \\ --build-arg NODE_VERSION = 20 \\ --build-arg DEBIAN_FRONTEND = noninteractive \\ -t webgrip/rust-ci-runner:custom \\ ops/docker/rust-ci-runner/ # Development build with debug symbols docker build \\ --build-arg BUILD_TYPE = debug \\ --build-arg OPTIMIZATION_LEVEL = 0 \\ -t webgrip/rust-ci-runner:debug \\ ops/docker/rust-ci-runner/ Build Cache Management \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Build with cache from registry docker build \\ --cache-from webgrip/rust-ci-runner:latest \\ -t webgrip/rust-ci-runner:local \\ ops/docker/rust-ci-runner/ # Use BuildKit for advanced caching export DOCKER_BUILDKIT = 1 docker build \\ --build-arg BUILDKIT_INLINE_CACHE = 1 \\ -t webgrip/rust-ci-runner:cached \\ ops/docker/rust-ci-runner/ # Clean build cache docker builder prune docker system prune -a Build Automation \u00b6 Makefile for Build Automation \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Makefile for local building IMAGES := rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser REGISTRY := webgrip TAG := local .PHONY : all build -% clean test -% push -% help # Build all images all : $( addprefix build- , $( IMAGES )) # Build specific image build-% : @echo \"Building $* image...\" docker build -t $( REGISTRY ) / $* : $( TAG ) ops/docker/ $* / @echo \"\u2705 Built $( REGISTRY ) / $* : $( TAG ) \" # Test specific image test-% : build -% @echo \"Testing $* image...\" docker run --rm $( REGISTRY ) / $* : $( TAG ) --version || echo \"\u2705 $* image works\" # Push to local registry push-% : build -% docker push $( REGISTRY ) / $* : $( TAG ) # Clean up local images clean : docker images | grep \" $( REGISTRY ) \" | grep \" $( TAG ) \" | awk '{print $$3}' | xargs -r docker rmi # Build with custom tag tag : $( eval TAG : = $( shell git rev-parse --short HEAD )) @echo \"Building with tag: $( TAG ) \" # Help target help : @echo \"Available targets:\" @echo \" all - Build all images\" @echo \" build-<image> - Build specific image\" @echo \" test-<image> - Test specific image\" @echo \" push-<image> - Push to registry\" @echo \" clean - Clean up local images\" @echo \" tag - Build with git SHA tag\" @echo \"\" @echo \"Available images: $( IMAGES ) \" @echo \"\" @echo \"Examples:\" @echo \" make build-rust-ci-runner\" @echo \" make test-playwright-runner\" @echo \" make TAG=dev build-helm-deploy\" # Usage examples build-dev : TAG = dev build-dev : all build-test : TAG = test build-test : all Usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Build all images make all # Build specific image make build-rust-ci-runner # Build and test make test-playwright-runner # Build with custom tag make TAG = dev build-helm-deploy # Clean up make clean Build Script Automation \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 #!/bin/bash # scripts/build-local.sh - Automated local building set -euo pipefail # Configuration REGISTRY = \" ${ DOCKER_REGISTRY :- webgrip } \" TAG = \" ${ BUILD_TAG :- local } \" PARALLEL = \" ${ PARALLEL_BUILDS :- 2 } \" BUILD_ARGS = \" ${ BUILD_ARGS :- } \" # Colors for output RED = '\\033[0;31m' GREEN = '\\033[0;32m' YELLOW = '\\033[1;33m' NC = '\\033[0m' # No Color # Logging functions log_info () { echo -e \" ${ GREEN } [INFO] ${ NC } $1 \" ; } log_warn () { echo -e \" ${ YELLOW } [WARN] ${ NC } $1 \" ; } log_error () { echo -e \" ${ RED } [ERROR] ${ NC } $1 \" ; } # Image definitions declare -A IMAGES =( [ \"rust-ci-runner\" ]= \"ops/docker/rust-ci-runner\" [ \"github-runner\" ]= \"ops/docker/github-runner\" [ \"helm-deploy\" ]= \"ops/docker/helm-deploy\" [ \"playwright-runner\" ]= \"ops/docker/playwright-runner\" [ \"act-runner\" ]= \"ops/docker/act-runner\" [ \"rust-releaser\" ]= \"ops/docker/rust-releaser\" ) # Build single image build_image () { local name = $1 local path = $2 local full_tag = \" ${ REGISTRY } / ${ name } : ${ TAG } \" log_info \"Building $name -> $full_tag \" if docker build $BUILD_ARGS -t \" $full_tag \" \" $path \" ; then log_info \"\u2705 Successfully built $full_tag \" return 0 else log_error \"\u274c Failed to build $full_tag \" return 1 fi } # Test image test_image () { local name = $1 local full_tag = \" ${ REGISTRY } / ${ name } : ${ TAG } \" log_info \"Testing $full_tag \" case $name in \"rust-ci-runner\" ) docker run --rm \" $full_tag \" rustc --version >/dev/null ;; \"github-runner\" ) docker run --rm \" $full_tag \" php --version >/dev/null ;; \"helm-deploy\" ) docker run --rm \" $full_tag \" helm version >/dev/null ;; \"playwright-runner\" ) docker run --rm \" $full_tag \" npx playwright --version >/dev/null ;; \"act-runner\" ) docker run --rm \" $full_tag \" act --version >/dev/null ;; \"rust-releaser\" ) docker run --rm \" $full_tag \" node --version >/dev/null ;; esac if [ $? -eq 0 ] ; then log_info \"\u2705 $full_tag passed basic test\" return 0 else log_error \"\u274c $full_tag failed basic test\" return 1 fi } # Main function main () { local target_images =() local test_after_build = false local clean_before_build = false # Parse arguments while [[ $# -gt 0 ]] ; do case $1 in --test ) test_after_build = true shift ;; --clean ) clean_before_build = true shift ;; --parallel ) PARALLEL = \" $2 \" shift 2 ;; --tag ) TAG = \" $2 \" shift 2 ;; --all ) target_images =( ${ !IMAGES[@] } ) shift ;; * ) if [[ -n \" ${ IMAGES [ $1 ] :- } \" ]] ; then target_images +=( \" $1 \" ) else log_error \"Unknown image: $1 \" log_info \"Available images: ${ !IMAGES[*] } \" exit 1 fi shift ;; esac done # Default to all images if none specified if [[ ${# target_images [@] } -eq 0 ]] ; then target_images =( ${ !IMAGES[@] } ) fi log_info \"Building images: ${ target_images [*] } \" log_info \"Registry: $REGISTRY \" log_info \"Tag: $TAG \" # Clean if requested if [[ \" $clean_before_build \" == \"true\" ]] ; then log_info \"Cleaning Docker cache...\" docker system prune -f fi # Build images local failed_builds =() for image in \" ${ target_images [@] } \" ; do if ! build_image \" $image \" \" ${ IMAGES [ $image ] } \" ; then failed_builds +=( \" $image \" ) fi # Test if requested if [[ \" $test_after_build \" == \"true\" ]] ; then test_image \" $image \" || failed_builds +=( \" $image -test\" ) fi done # Report results if [[ ${# failed_builds [@] } -eq 0 ]] ; then log_info \"\ud83c\udf89 All builds completed successfully!\" else log_error \"\u274c Failed builds: ${ failed_builds [*] } \" exit 1 fi } # Usage function usage () { cat << EOF Usage: $0 [OPTIONS] [IMAGES...] Build Docker images locally. OPTIONS: --test Test images after building --clean Clean Docker cache before building --parallel N Number of parallel builds (default: $PARALLEL) --tag TAG Tag for built images (default: $TAG) --all Build all images IMAGES: ${!IMAGES[*]} EXAMPLES: $0 --all --test # Build and test all images $0 rust-ci-runner playwright-runner # Build specific images $0 --tag dev --clean helm-deploy # Build with custom tag and clean cache ENVIRONMENT VARIABLES: DOCKER_REGISTRY Docker registry (default: webgrip) BUILD_TAG Default tag (default: local) PARALLEL_BUILDS Parallel builds (default: 2) BUILD_ARGS Additional docker build args EOF } # Handle help if [[ \" ${ 1 :- } \" == \"--help\" ]] || [[ \" ${ 1 :- } \" == \"-h\" ]] ; then usage exit 0 fi # Run main function main \" $@ \" Usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Make script executable chmod +x scripts/build-local.sh # Build all images ./scripts/build-local.sh --all # Build and test specific images ./scripts/build-local.sh --test rust-ci-runner playwright-runner # Build with custom tag and clean cache ./scripts/build-local.sh --tag dev --clean helm-deploy # Build all with custom configuration BUILD_TAG = dev PARALLEL_BUILDS = 4 ./scripts/build-local.sh --all --test Testing Built Images \u00b6 Basic Functionality Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Test Rust CI Runner docker run --rm webgrip/rust-ci-runner:local rustc --version docker run --rm webgrip/rust-ci-runner:local cargo --version docker run --rm webgrip/rust-ci-runner:local cargo audit --version # Test Playwright Runner docker run --rm webgrip/playwright-runner:local npx playwright --version docker run --rm webgrip/playwright-runner:local php --version # Test Helm Deploy docker run --rm webgrip/helm-deploy:local helm version docker run --rm webgrip/helm-deploy:local kubectl version --client # Test ACT Runner docker run --rm webgrip/act-runner:local act --version # Test GitHub Runner (requires setup) docker run --rm webgrip/github-runner:local php --version docker run --rm webgrip/github-runner:local composer --version # Test Rust Releaser docker run --rm webgrip/rust-releaser:local node --version docker run --rm webgrip/rust-releaser:local npx semantic-release --version Integration Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Test volume mounting docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:local \\ bash -c \"ls -la && rustc --version\" # Test network connectivity docker run --rm webgrip/rust-ci-runner:local \\ bash -c \"curl -s https://crates.io | head -5\" # Test build functionality mkdir -p /tmp/test-rust-project cd /tmp/test-rust-project cargo init --name test-app docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:local \\ bash -c \"cargo build && cargo test\" Performance Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Measure build time time docker build -t test-build ops/docker/rust-ci-runner/ # Measure image size docker images | grep rust-ci-runner # Test container startup time time docker run --rm webgrip/rust-ci-runner:local echo \"Hello World\" # Memory usage test docker run --rm \\ --memory = 1g \\ webgrip/rust-ci-runner:local \\ bash -c \"echo 'Memory test passed'\" Troubleshooting \u00b6 Build Failures \u00b6 Out of disk space 1 2 3 4 5 6 7 # Check disk usage df -h docker system df # Clean up docker system prune -a --volumes docker builder prune --all Network timeouts 1 2 3 4 5 6 # Use build args for proxy docker build \\ --build-arg HTTP_PROXY = http://proxy:8080 \\ --build-arg HTTPS_PROXY = http://proxy:8080 \\ -t webgrip/rust-ci-runner:local \\ ops/docker/rust-ci-runner/ Permission errors 1 2 3 4 5 6 # Check Docker daemon access docker info # Fix permissions (Linux) sudo usermod -aG docker $USER newgrp docker Base image pull failures 1 2 3 4 5 6 7 # Pre-pull base images docker pull rust:1.87.0-slim-bookworm docker pull alpine:3.22.1 docker pull mcr.microsoft.com/playwright:v1.51.0-noble # Use local registry mirror docker build --pull = false -t local-build ops/docker/rust-ci-runner/ Runtime Issues \u00b6 Container won't start 1 2 3 4 5 6 7 8 # Debug container docker run -it --entrypoint = /bin/bash webgrip/rust-ci-runner:local # Check logs docker logs <container-id> # Inspect image docker inspect webgrip/rust-ci-runner:local Tool not found 1 2 3 4 5 6 7 8 # Verify PATH docker run --rm webgrip/rust-ci-runner:local echo $PATH # Check installed tools docker run --rm webgrip/rust-ci-runner:local which cargo rustc # Debug package installation docker run --rm webgrip/rust-ci-runner:local dpkg -l | grep rust Build Performance Issues \u00b6 Slow builds 1 2 3 4 5 6 7 8 # Use BuildKit export DOCKER_BUILDKIT = 1 # Parallel builds docker-compose build --parallel # Use build cache docker build --cache-from webgrip/rust-ci-runner:latest Layer cache misses 1 2 3 4 5 6 # Optimize Dockerfile layer order # Place frequently changing content at the end # Use .dockerignore echo \"target/\" >> ops/docker/rust-ci-runner/.dockerignore echo \"*.log\" >> ops/docker/rust-ci-runner/.dockerignore Best Practices \u00b6 Development Workflow \u00b6 Small, incremental changes : Test each change incrementally Use development tags : Tag images with descriptive names ( dev , test , feature-x ) Clean up regularly : Remove unused images and containers Use build cache : Leverage Docker's layer caching for faster builds Security Considerations \u00b6 1 2 3 4 5 6 7 # Scan images for vulnerabilities docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ aquasec/trivy image webgrip/rust-ci-runner:local # Check for secrets in images docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ wagoodman/dive webgrip/rust-ci-runner:local Resource Management \u00b6 1 2 3 4 5 6 7 8 # Monitor resource usage docker stats # Set resource limits docker run --memory = 2g --cpus = 1 webgrip/rust-ci-runner:local # Use multi-stage builds to reduce image size # Optimize package installation order Integration with Development Tools \u00b6 VS Code Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // .vscode/tasks.json { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Build Rust CI Runner\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"build\" , \"-t\" , \"webgrip/rust-ci-runner:dev\" , \"ops/docker/rust-ci-runner/\" ], \"group\" : \"build\" , \"presentation\" : { \"reveal\" : \"always\" , \"panel\" : \"new\" } }, { \"label\" : \"Test Built Image\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"run\" , \"--rm\" , \"webgrip/rust-ci-runner:dev\" , \"rustc\" , \"--version\" ], \"dependsOn\" : \"Build Rust CI Runner\" , \"group\" : \"test\" } ] } IDE Docker Plugin \u00b6 Most IDEs support Docker plugins for: - Building images directly from IDE - Running containers with debugging - Viewing container logs - Managing Docker resources Related Documentation \u00b6 Contributing Images - How to contribute new images Maintenance - Ongoing maintenance procedures Docker Images - Individual image documentation CI/CD Pipeline - Automated building process Assumption : Developers have local Docker installations and sufficient system resources for building container images. Network connectivity requirements may vary based on base image sizes and dependencies. Validation needed: Confirm local development environment standards and resource requirements. Maintainer : WebGrip Ops Team Scripts : Available in repository scripts/ directory Support : GitHub Issues","title":"Building Locally"},{"location":"operations/building-locally/#building-locally","text":"Guide for building and testing Docker images locally during development and maintenance.","title":"Building Locally"},{"location":"operations/building-locally/#overview","text":"Local building capabilities enable: \u2705 Development iteration without pushing to GitHub \u2705 Testing changes before committing to version control \u2705 Debugging build issues with full access to build context \u2705 Custom image variants for specific use cases \u2705 Offline development when internet connectivity is limited","title":"Overview"},{"location":"operations/building-locally/#prerequisites","text":"","title":"Prerequisites"},{"location":"operations/building-locally/#required-tools","text":"Tool Purpose Installation Docker Container building and runtime Install Docker Docker Compose Multi-container orchestration Included with Docker Desktop Git Source code management Install Git Make (optional) Build automation sudo apt install make (Linux)","title":"Required Tools"},{"location":"operations/building-locally/#system-requirements","text":"CPU : 2+ cores recommended for parallel builds RAM : 4GB minimum, 8GB recommended Storage : 20GB free space for Docker images and build cache Network : Reliable internet for base image downloads","title":"System Requirements"},{"location":"operations/building-locally/#repository-setup","text":"","title":"Repository Setup"},{"location":"operations/building-locally/#clone-repository","text":"1 2 3 4 5 6 # Clone the infrastructure repository git clone https://github.com/webgrip/infrastructure.git cd infrastructure # Verify directory structure ls -la ops/docker/","title":"Clone Repository"},{"location":"operations/building-locally/#environment-setup","text":"1 2 3 4 5 6 7 8 9 # Create local environment file (optional) cat > .env.local << EOF DOCKER_REGISTRY=localhost:5000 BUILD_ARGS=\"--no-cache\" PARALLEL_BUILDS=4 EOF # Source environment source .env.local","title":"Environment Setup"},{"location":"operations/building-locally/#basic-building","text":"","title":"Basic Building"},{"location":"operations/building-locally/#single-image-build","text":"1 2 3 4 5 6 7 8 9 10 11 # Build specific image docker build -t webgrip/rust-ci-runner:local ops/docker/rust-ci-runner/ # Build with specific tag docker build -t my-rust-ci:test ops/docker/rust-ci-runner/ # Build with build arguments docker build \\ --build-arg RUST_VERSION = 1 .86.0 \\ -t webgrip/rust-ci-runner:1.86 \\ ops/docker/rust-ci-runner/","title":"Single Image Build"},{"location":"operations/building-locally/#using-docker-compose","text":"1 2 3 4 5 6 7 8 9 10 11 # Build all images defined in docker-compose.yml docker-compose build # Build specific service docker-compose build rust-ci-runner # Build with no cache docker-compose build --no-cache # Build in parallel docker-compose build --parallel","title":"Using Docker Compose"},{"location":"operations/building-locally/#build-context-verification","text":"1 2 3 4 5 6 7 8 # Check build context size du -sh ops/docker/rust-ci-runner/ # List files in build context find ops/docker/rust-ci-runner/ -type f # Verify Dockerfile syntax docker build --dry-run ops/docker/rust-ci-runner/","title":"Build Context Verification"},{"location":"operations/building-locally/#advanced-building","text":"","title":"Advanced Building"},{"location":"operations/building-locally/#multi-stage-build-optimization","text":"1 2 3 4 5 6 7 8 9 10 11 # Example optimization for development FROM rust:1.87.0-slim-bookworm AS development # Add development-specific tools RUN apt-get update && apt-get install -y \\ gdb lldb strace valgrind FROM rust:1.87.0-slim-bookworm AS production # Production optimizations RUN apt-get update && apt-get install -y --no-install-recommends \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* 1 2 3 # Build specific stage docker build --target development -t rust-ci:dev ops/docker/rust-ci-runner/ docker build --target production -t rust-ci:prod ops/docker/rust-ci-runner/","title":"Multi-stage Build Optimization"},{"location":"operations/building-locally/#build-arguments-and-customization","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Common build arguments docker build \\ --build-arg RUST_VERSION = 1 .87.0 \\ --build-arg NODE_VERSION = 20 \\ --build-arg DEBIAN_FRONTEND = noninteractive \\ -t webgrip/rust-ci-runner:custom \\ ops/docker/rust-ci-runner/ # Development build with debug symbols docker build \\ --build-arg BUILD_TYPE = debug \\ --build-arg OPTIMIZATION_LEVEL = 0 \\ -t webgrip/rust-ci-runner:debug \\ ops/docker/rust-ci-runner/","title":"Build Arguments and Customization"},{"location":"operations/building-locally/#build-cache-management","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Build with cache from registry docker build \\ --cache-from webgrip/rust-ci-runner:latest \\ -t webgrip/rust-ci-runner:local \\ ops/docker/rust-ci-runner/ # Use BuildKit for advanced caching export DOCKER_BUILDKIT = 1 docker build \\ --build-arg BUILDKIT_INLINE_CACHE = 1 \\ -t webgrip/rust-ci-runner:cached \\ ops/docker/rust-ci-runner/ # Clean build cache docker builder prune docker system prune -a","title":"Build Cache Management"},{"location":"operations/building-locally/#build-automation","text":"","title":"Build Automation"},{"location":"operations/building-locally/#makefile-for-build-automation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Makefile for local building IMAGES := rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser REGISTRY := webgrip TAG := local .PHONY : all build -% clean test -% push -% help # Build all images all : $( addprefix build- , $( IMAGES )) # Build specific image build-% : @echo \"Building $* image...\" docker build -t $( REGISTRY ) / $* : $( TAG ) ops/docker/ $* / @echo \"\u2705 Built $( REGISTRY ) / $* : $( TAG ) \" # Test specific image test-% : build -% @echo \"Testing $* image...\" docker run --rm $( REGISTRY ) / $* : $( TAG ) --version || echo \"\u2705 $* image works\" # Push to local registry push-% : build -% docker push $( REGISTRY ) / $* : $( TAG ) # Clean up local images clean : docker images | grep \" $( REGISTRY ) \" | grep \" $( TAG ) \" | awk '{print $$3}' | xargs -r docker rmi # Build with custom tag tag : $( eval TAG : = $( shell git rev-parse --short HEAD )) @echo \"Building with tag: $( TAG ) \" # Help target help : @echo \"Available targets:\" @echo \" all - Build all images\" @echo \" build-<image> - Build specific image\" @echo \" test-<image> - Test specific image\" @echo \" push-<image> - Push to registry\" @echo \" clean - Clean up local images\" @echo \" tag - Build with git SHA tag\" @echo \"\" @echo \"Available images: $( IMAGES ) \" @echo \"\" @echo \"Examples:\" @echo \" make build-rust-ci-runner\" @echo \" make test-playwright-runner\" @echo \" make TAG=dev build-helm-deploy\" # Usage examples build-dev : TAG = dev build-dev : all build-test : TAG = test build-test : all Usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Build all images make all # Build specific image make build-rust-ci-runner # Build and test make test-playwright-runner # Build with custom tag make TAG = dev build-helm-deploy # Clean up make clean","title":"Makefile for Build Automation"},{"location":"operations/building-locally/#build-script-automation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 #!/bin/bash # scripts/build-local.sh - Automated local building set -euo pipefail # Configuration REGISTRY = \" ${ DOCKER_REGISTRY :- webgrip } \" TAG = \" ${ BUILD_TAG :- local } \" PARALLEL = \" ${ PARALLEL_BUILDS :- 2 } \" BUILD_ARGS = \" ${ BUILD_ARGS :- } \" # Colors for output RED = '\\033[0;31m' GREEN = '\\033[0;32m' YELLOW = '\\033[1;33m' NC = '\\033[0m' # No Color # Logging functions log_info () { echo -e \" ${ GREEN } [INFO] ${ NC } $1 \" ; } log_warn () { echo -e \" ${ YELLOW } [WARN] ${ NC } $1 \" ; } log_error () { echo -e \" ${ RED } [ERROR] ${ NC } $1 \" ; } # Image definitions declare -A IMAGES =( [ \"rust-ci-runner\" ]= \"ops/docker/rust-ci-runner\" [ \"github-runner\" ]= \"ops/docker/github-runner\" [ \"helm-deploy\" ]= \"ops/docker/helm-deploy\" [ \"playwright-runner\" ]= \"ops/docker/playwright-runner\" [ \"act-runner\" ]= \"ops/docker/act-runner\" [ \"rust-releaser\" ]= \"ops/docker/rust-releaser\" ) # Build single image build_image () { local name = $1 local path = $2 local full_tag = \" ${ REGISTRY } / ${ name } : ${ TAG } \" log_info \"Building $name -> $full_tag \" if docker build $BUILD_ARGS -t \" $full_tag \" \" $path \" ; then log_info \"\u2705 Successfully built $full_tag \" return 0 else log_error \"\u274c Failed to build $full_tag \" return 1 fi } # Test image test_image () { local name = $1 local full_tag = \" ${ REGISTRY } / ${ name } : ${ TAG } \" log_info \"Testing $full_tag \" case $name in \"rust-ci-runner\" ) docker run --rm \" $full_tag \" rustc --version >/dev/null ;; \"github-runner\" ) docker run --rm \" $full_tag \" php --version >/dev/null ;; \"helm-deploy\" ) docker run --rm \" $full_tag \" helm version >/dev/null ;; \"playwright-runner\" ) docker run --rm \" $full_tag \" npx playwright --version >/dev/null ;; \"act-runner\" ) docker run --rm \" $full_tag \" act --version >/dev/null ;; \"rust-releaser\" ) docker run --rm \" $full_tag \" node --version >/dev/null ;; esac if [ $? -eq 0 ] ; then log_info \"\u2705 $full_tag passed basic test\" return 0 else log_error \"\u274c $full_tag failed basic test\" return 1 fi } # Main function main () { local target_images =() local test_after_build = false local clean_before_build = false # Parse arguments while [[ $# -gt 0 ]] ; do case $1 in --test ) test_after_build = true shift ;; --clean ) clean_before_build = true shift ;; --parallel ) PARALLEL = \" $2 \" shift 2 ;; --tag ) TAG = \" $2 \" shift 2 ;; --all ) target_images =( ${ !IMAGES[@] } ) shift ;; * ) if [[ -n \" ${ IMAGES [ $1 ] :- } \" ]] ; then target_images +=( \" $1 \" ) else log_error \"Unknown image: $1 \" log_info \"Available images: ${ !IMAGES[*] } \" exit 1 fi shift ;; esac done # Default to all images if none specified if [[ ${# target_images [@] } -eq 0 ]] ; then target_images =( ${ !IMAGES[@] } ) fi log_info \"Building images: ${ target_images [*] } \" log_info \"Registry: $REGISTRY \" log_info \"Tag: $TAG \" # Clean if requested if [[ \" $clean_before_build \" == \"true\" ]] ; then log_info \"Cleaning Docker cache...\" docker system prune -f fi # Build images local failed_builds =() for image in \" ${ target_images [@] } \" ; do if ! build_image \" $image \" \" ${ IMAGES [ $image ] } \" ; then failed_builds +=( \" $image \" ) fi # Test if requested if [[ \" $test_after_build \" == \"true\" ]] ; then test_image \" $image \" || failed_builds +=( \" $image -test\" ) fi done # Report results if [[ ${# failed_builds [@] } -eq 0 ]] ; then log_info \"\ud83c\udf89 All builds completed successfully!\" else log_error \"\u274c Failed builds: ${ failed_builds [*] } \" exit 1 fi } # Usage function usage () { cat << EOF Usage: $0 [OPTIONS] [IMAGES...] Build Docker images locally. OPTIONS: --test Test images after building --clean Clean Docker cache before building --parallel N Number of parallel builds (default: $PARALLEL) --tag TAG Tag for built images (default: $TAG) --all Build all images IMAGES: ${!IMAGES[*]} EXAMPLES: $0 --all --test # Build and test all images $0 rust-ci-runner playwright-runner # Build specific images $0 --tag dev --clean helm-deploy # Build with custom tag and clean cache ENVIRONMENT VARIABLES: DOCKER_REGISTRY Docker registry (default: webgrip) BUILD_TAG Default tag (default: local) PARALLEL_BUILDS Parallel builds (default: 2) BUILD_ARGS Additional docker build args EOF } # Handle help if [[ \" ${ 1 :- } \" == \"--help\" ]] || [[ \" ${ 1 :- } \" == \"-h\" ]] ; then usage exit 0 fi # Run main function main \" $@ \" Usage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Make script executable chmod +x scripts/build-local.sh # Build all images ./scripts/build-local.sh --all # Build and test specific images ./scripts/build-local.sh --test rust-ci-runner playwright-runner # Build with custom tag and clean cache ./scripts/build-local.sh --tag dev --clean helm-deploy # Build all with custom configuration BUILD_TAG = dev PARALLEL_BUILDS = 4 ./scripts/build-local.sh --all --test","title":"Build Script Automation"},{"location":"operations/building-locally/#testing-built-images","text":"","title":"Testing Built Images"},{"location":"operations/building-locally/#basic-functionality-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Test Rust CI Runner docker run --rm webgrip/rust-ci-runner:local rustc --version docker run --rm webgrip/rust-ci-runner:local cargo --version docker run --rm webgrip/rust-ci-runner:local cargo audit --version # Test Playwright Runner docker run --rm webgrip/playwright-runner:local npx playwright --version docker run --rm webgrip/playwright-runner:local php --version # Test Helm Deploy docker run --rm webgrip/helm-deploy:local helm version docker run --rm webgrip/helm-deploy:local kubectl version --client # Test ACT Runner docker run --rm webgrip/act-runner:local act --version # Test GitHub Runner (requires setup) docker run --rm webgrip/github-runner:local php --version docker run --rm webgrip/github-runner:local composer --version # Test Rust Releaser docker run --rm webgrip/rust-releaser:local node --version docker run --rm webgrip/rust-releaser:local npx semantic-release --version","title":"Basic Functionality Testing"},{"location":"operations/building-locally/#integration-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Test volume mounting docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:local \\ bash -c \"ls -la && rustc --version\" # Test network connectivity docker run --rm webgrip/rust-ci-runner:local \\ bash -c \"curl -s https://crates.io | head -5\" # Test build functionality mkdir -p /tmp/test-rust-project cd /tmp/test-rust-project cargo init --name test-app docker run --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:local \\ bash -c \"cargo build && cargo test\"","title":"Integration Testing"},{"location":"operations/building-locally/#performance-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Measure build time time docker build -t test-build ops/docker/rust-ci-runner/ # Measure image size docker images | grep rust-ci-runner # Test container startup time time docker run --rm webgrip/rust-ci-runner:local echo \"Hello World\" # Memory usage test docker run --rm \\ --memory = 1g \\ webgrip/rust-ci-runner:local \\ bash -c \"echo 'Memory test passed'\"","title":"Performance Testing"},{"location":"operations/building-locally/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"operations/building-locally/#build-failures","text":"Out of disk space 1 2 3 4 5 6 7 # Check disk usage df -h docker system df # Clean up docker system prune -a --volumes docker builder prune --all Network timeouts 1 2 3 4 5 6 # Use build args for proxy docker build \\ --build-arg HTTP_PROXY = http://proxy:8080 \\ --build-arg HTTPS_PROXY = http://proxy:8080 \\ -t webgrip/rust-ci-runner:local \\ ops/docker/rust-ci-runner/ Permission errors 1 2 3 4 5 6 # Check Docker daemon access docker info # Fix permissions (Linux) sudo usermod -aG docker $USER newgrp docker Base image pull failures 1 2 3 4 5 6 7 # Pre-pull base images docker pull rust:1.87.0-slim-bookworm docker pull alpine:3.22.1 docker pull mcr.microsoft.com/playwright:v1.51.0-noble # Use local registry mirror docker build --pull = false -t local-build ops/docker/rust-ci-runner/","title":"Build Failures"},{"location":"operations/building-locally/#runtime-issues","text":"Container won't start 1 2 3 4 5 6 7 8 # Debug container docker run -it --entrypoint = /bin/bash webgrip/rust-ci-runner:local # Check logs docker logs <container-id> # Inspect image docker inspect webgrip/rust-ci-runner:local Tool not found 1 2 3 4 5 6 7 8 # Verify PATH docker run --rm webgrip/rust-ci-runner:local echo $PATH # Check installed tools docker run --rm webgrip/rust-ci-runner:local which cargo rustc # Debug package installation docker run --rm webgrip/rust-ci-runner:local dpkg -l | grep rust","title":"Runtime Issues"},{"location":"operations/building-locally/#build-performance-issues","text":"Slow builds 1 2 3 4 5 6 7 8 # Use BuildKit export DOCKER_BUILDKIT = 1 # Parallel builds docker-compose build --parallel # Use build cache docker build --cache-from webgrip/rust-ci-runner:latest Layer cache misses 1 2 3 4 5 6 # Optimize Dockerfile layer order # Place frequently changing content at the end # Use .dockerignore echo \"target/\" >> ops/docker/rust-ci-runner/.dockerignore echo \"*.log\" >> ops/docker/rust-ci-runner/.dockerignore","title":"Build Performance Issues"},{"location":"operations/building-locally/#best-practices","text":"","title":"Best Practices"},{"location":"operations/building-locally/#development-workflow","text":"Small, incremental changes : Test each change incrementally Use development tags : Tag images with descriptive names ( dev , test , feature-x ) Clean up regularly : Remove unused images and containers Use build cache : Leverage Docker's layer caching for faster builds","title":"Development Workflow"},{"location":"operations/building-locally/#security-considerations","text":"1 2 3 4 5 6 7 # Scan images for vulnerabilities docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ aquasec/trivy image webgrip/rust-ci-runner:local # Check for secrets in images docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ wagoodman/dive webgrip/rust-ci-runner:local","title":"Security Considerations"},{"location":"operations/building-locally/#resource-management","text":"1 2 3 4 5 6 7 8 # Monitor resource usage docker stats # Set resource limits docker run --memory = 2g --cpus = 1 webgrip/rust-ci-runner:local # Use multi-stage builds to reduce image size # Optimize package installation order","title":"Resource Management"},{"location":"operations/building-locally/#integration-with-development-tools","text":"","title":"Integration with Development Tools"},{"location":"operations/building-locally/#vs-code-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // .vscode/tasks.json { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Build Rust CI Runner\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"build\" , \"-t\" , \"webgrip/rust-ci-runner:dev\" , \"ops/docker/rust-ci-runner/\" ], \"group\" : \"build\" , \"presentation\" : { \"reveal\" : \"always\" , \"panel\" : \"new\" } }, { \"label\" : \"Test Built Image\" , \"type\" : \"shell\" , \"command\" : \"docker\" , \"args\" : [ \"run\" , \"--rm\" , \"webgrip/rust-ci-runner:dev\" , \"rustc\" , \"--version\" ], \"dependsOn\" : \"Build Rust CI Runner\" , \"group\" : \"test\" } ] }","title":"VS Code Integration"},{"location":"operations/building-locally/#ide-docker-plugin","text":"Most IDEs support Docker plugins for: - Building images directly from IDE - Running containers with debugging - Viewing container logs - Managing Docker resources","title":"IDE Docker Plugin"},{"location":"operations/building-locally/#related-documentation","text":"Contributing Images - How to contribute new images Maintenance - Ongoing maintenance procedures Docker Images - Individual image documentation CI/CD Pipeline - Automated building process Assumption : Developers have local Docker installations and sufficient system resources for building container images. Network connectivity requirements may vary based on base image sizes and dependencies. Validation needed: Confirm local development environment standards and resource requirements. Maintainer : WebGrip Ops Team Scripts : Available in repository scripts/ directory Support : GitHub Issues","title":"Related Documentation"},{"location":"operations/contributing-images/","text":"Contributing Images \u00b6 Guide for contributing new Docker images or improving existing ones in the WebGrip infrastructure repository. Overview \u00b6 Contributing to our infrastructure helps: \u2705 Expand capabilities with new development tools and environments \u2705 Improve existing images with performance optimizations and feature additions \u2705 Share knowledge through documentation and best practices \u2705 Maintain quality through consistent standards and review processes \u2705 Support the community by solving common development challenges Contribution Process \u00b6 1. Planning Phase \u00b6 flowchart TD IDEA[Image Idea] --> RESEARCH[Research Existing Solutions] RESEARCH --> PROPOSAL[Create Proposal Issue] PROPOSAL --> DISCUSSION[Community Discussion] DISCUSSION --> APPROVED{Approved?} APPROVED -->|Yes| DESIGN[Design Phase] APPROVED -->|No| REVISE[Revise Proposal] REVISE --> DISCUSSION Before starting development: Check existing images : Review current images to avoid duplication Create an issue : Use our issue template Discuss approach : Engage with the team on implementation strategy Get approval : Wait for maintainer approval before significant work 2. Development Phase \u00b6 flowchart LR FORK[Fork Repository] --> BRANCH[Create Feature Branch] BRANCH --> DEVELOP[Develop Image] DEVELOP --> TEST[Local Testing] TEST --> DOCUMENT[Documentation] DOCUMENT --> PR[Create Pull Request] PR --> REVIEW[Code Review] REVIEW --> MERGE[Merge to Main] Creating a New Image \u00b6 Directory Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Create new image directory mkdir -p ops/docker/my-new-image # Standard structure ops/docker/my-new-image/ \u251c\u2500\u2500 Dockerfile # Main build file \u251c\u2500\u2500 README.md # Image-specific documentation \u251c\u2500\u2500 .dockerignore # Build context exclusions \u251c\u2500\u2500 entrypoint.sh # Custom entry point (if needed) \u251c\u2500\u2500 config/ # Configuration files \u2502 \u251c\u2500\u2500 tool.conf \u2502 \u2514\u2500\u2500 env.sh \u2514\u2500\u2500 scripts/ # Helper scripts \u251c\u2500\u2500 setup.sh \u2514\u2500\u2500 healthcheck.sh Dockerfile Best Practices \u00b6 Base Image Selection \u00b6 1 2 3 4 5 # Prefer official, minimal base images FROM node:20-alpine3.18 # Good: official + minimal FROM alpine:3.22.1 # Good: minimal FROM ubuntu:22.04 # OK: official but larger FROM my-custom-base:latest # Avoid: non-standard base Multi-stage Build Pattern \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # Build stage - install build dependencies FROM node:20-alpine3.18 AS build WORKDIR /build # Copy package files first (for layer caching) COPY package*.json ./ RUN npm ci --only = production # Copy source code COPY . . RUN npm run build # Runtime stage - minimal runtime dependencies FROM node:20-alpine3.18 AS runtime # Create non-root user RUN addgroup -g 1001 -S appgroup && \\ adduser -S appuser -u 1001 -G appgroup # Install runtime dependencies only RUN apk add --no-cache \\ ca-certificates \\ curl # Copy artifacts from build stage COPY --from = build /build/dist /app COPY --from = build /build/node_modules /app/node_modules # Set ownership and switch to non-root user RUN chown -R appuser:appgroup /app USER appuser WORKDIR /app EXPOSE 3000 # Health check HEALTHCHECK --interval = 30s --timeout = 3s --start-period = 5s --retries = 3 \\ CMD curl -f http://localhost:3000/health || exit 1 ENTRYPOINT [ \"node\" , \"server.js\" ] Layer Optimization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # \u274c BAD: Creates many layers RUN apt-get update RUN apt-get install -y curl RUN apt-get install -y git RUN apt-get install -y build-essential RUN rm -rf /var/lib/apt/lists/* # \u2705 GOOD: Single layer with cleanup RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ curl \\ git \\ build-essential && \\ rm -rf /var/lib/apt/lists/* Build Arguments and Environment \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Build-time configuration ARG NODE_VERSION = 20 ARG BUILD_DATE ARG VERSION # Runtime environment ENV NODE_ENV = production \\ PORT = 3000 \\ LOG_LEVEL = info # Labels for metadata LABEL maintainer = \"WebGrip Ops Team <ops@webgrip.nl>\" \\ org.opencontainers.image.title = \"My Tool\" \\ org.opencontainers.image.description = \"Description of the tool\" \\ org.opencontainers.image.version = \" ${ VERSION } \" \\ org.opencontainers.image.created = \" ${ BUILD_DATE } \" \\ org.opencontainers.image.source = \"https://github.com/webgrip/infrastructure\" Example: Creating a Python Tools Image \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # ops/docker/python-tools/Dockerfile ARG PYTHON_VERSION = 3 .11 # Build stage FROM python:${PYTHON_VERSION}-slim-bookworm AS build # System build dependencies RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ build-essential \\ curl \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* # Python tools installation RUN pip install --no-cache-dir \\ poetry \\ black \\ flake8 \\ mypy \\ pytest \\ jupyter # Runtime stage FROM python:${PYTHON_VERSION}-slim-bookworm AS runtime # Runtime dependencies RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ git \\ curl \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* # Copy Python tools from build stage COPY --from = build /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages COPY --from = build /usr/local/bin /usr/local/bin # Create non-root user RUN groupadd -r python && useradd -r -g python python # Set working directory WORKDIR /workspace # Switch to non-root user USER python # Verify installation RUN python --version && \\ poetry --version && \\ black --version ENTRYPOINT [ \"bash\" ] Configuration Files \u00b6 .dockerignore \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ops/docker/my-new-image/.dockerignore **/.git **/.gitignore **/README.md **/Dockerfile **/docker-compose*.yml **/.dockerignore **/.vscode **/.idea **/node_modules **/target **/*.log **/tmp **/temp .DS_Store Thumbs.db Health Check Script \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # ops/docker/my-new-image/scripts/healthcheck.sh set -e # Check if main service is running if pgrep -f \"my-service\" > /dev/null ; then echo \"Service is running\" exit 0 else echo \"Service is not running\" exit 1 fi Entry Point Script \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # ops/docker/my-new-image/entrypoint.sh set -e # Setup function setup_environment () { echo \"Setting up environment...\" # Create necessary directories mkdir -p /workspace/.cache # Set permissions chown -R $( id -u ) : $( id -g ) /workspace echo \"Environment setup complete\" } # Main execution main () { setup_environment # Execute the main command exec \" $@ \" } # Run main function main \" $@ \" Testing New Images \u00b6 Local Testing Checklist \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 1. Build image docker build -t webgrip/my-new-image:test ops/docker/my-new-image/ # 2. Basic functionality test docker run --rm webgrip/my-new-image:test --version # 3. Interactive test docker run -it --rm webgrip/my-new-image:test bash # 4. Volume mounting test docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/my-new-image:test ls -la # 5. Environment variable test docker run --rm -e TEST_VAR = hello \\ webgrip/my-new-image:test env | grep TEST_VAR # 6. Health check test (if implemented) docker run -d --name test-container webgrip/my-new-image:test sleep 10 docker exec test-container /scripts/healthcheck.sh docker rm -f test-container Automated Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #!/bin/bash # ops/docker/my-new-image/test.sh set -e IMAGE_NAME = \"webgrip/my-new-image:test\" CONTAINER_NAME = \"test-my-new-image\" echo \"\ud83e\uddea Testing $IMAGE_NAME \" # Build image echo \"Building image...\" docker build -t \" $IMAGE_NAME \" . # Test 1: Basic execution echo \"Test 1: Basic execution\" docker run --rm \" $IMAGE_NAME \" --version # Test 2: Tool availability echo \"Test 2: Tool availability\" docker run --rm \" $IMAGE_NAME \" which python3 docker run --rm \" $IMAGE_NAME \" python3 -c \"import sys; print(sys.version)\" # Test 3: Workspace functionality echo \"Test 3: Workspace functionality\" docker run --rm -v \" $( pwd ) :/workspace\" -w /workspace \\ \" $IMAGE_NAME \" ls -la # Test 4: Non-root user echo \"Test 4: Non-root user\" USER_ID = $( docker run --rm \" $IMAGE_NAME \" id -u ) if [ \" $USER_ID \" = \"0\" ] ; then echo \"\u274c Container running as root\" exit 1 else echo \"\u2705 Container running as non-root user ( $USER_ID )\" fi # Test 5: Security scan echo \"Test 5: Security scan\" if command -v trivy >/dev/null 2 > & 1 ; then trivy image \" $IMAGE_NAME \" else echo \"\u26a0\ufe0f Trivy not available, skipping security scan\" fi echo \"\u2705 All tests passed!\" Integration Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # .github/workflows/test-new-image.yml name : Test New Image on : pull_request : paths : - 'ops/docker/my-new-image/**' jobs : test : runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Build image run : | docker build -t test-image ops/docker/my-new-image/ - name : Run tests run : | cd ops/docker/my-new-image chmod +x test.sh ./test.sh - name : Security scan uses : aquasecurity/trivy-action@master with : image-ref : test-image format : sarif output : trivy-results.sarif - name : Upload scan results uses : github/codeql-action/upload-sarif@v2 with : sarif_file : trivy-results.sarif Documentation Requirements \u00b6 Image Documentation Template \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # My New Image Brief description of what this image provides and its purpose. ## Purpose This image serves as... ## Image Details | Property | Value | |----------|-------| | **Base Image** | `python:3.11-slim-bookworm` | | **Size** | ~200MB | | **Architecture** | AMD64 | | **Registry** | `webgrip/my-new-image` | | **Dockerfile** | [ `ops/docker/my-new-image/Dockerfile` ](../../../ops/docker/my-new-image/Dockerfile) | ## Installed Tools | Tool | Version | Purpose | |------|---------|---------| | **Python** | 3.11 | Runtime environment | | **Poetry** | Latest | Dependency management | ## Usage Examples ### Basic Usage ```bash # Run interactive session docker run -it --rm webgrip/my-new-image:latest Project Development \u00b6 1 2 3 4 # Mount project directory docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/my-new-image:latest \\ python main.py Configuration \u00b6 Environment Variables \u00b6 Variable Default Purpose PYTHON_ENV production Python environment Troubleshooting \u00b6 Common Issues \u00b6 Tool not found 1 2 # Verify installation docker run --rm webgrip/my-new-image:latest which python3 Related Documentation \u00b6 Building Locally Architecture Overview 1 2 3 4 5 6 7 8 ### Integration with Main Documentation Update the main index page to include your new image: ```markdown # Add to docs/techdocs/docs/index.md | [My New Image](docker-images/my-new-image.md) | Python development tools | Complete Python toolchain for development | Update the navigation in mkdocs.yml : 1 2 3 4 # Add to docs/techdocs/mkdocs.yml nav : - Docker Images : - My New Image : docker-images/my-new-image.md Code Review Process \u00b6 Pre-Review Checklist \u00b6 Before submitting a pull request: Dockerfile follows best practices (multi-stage, layer optimization, security) Image builds successfully locally Basic functionality tested with manual verification Documentation created following template Tests implemented (automated testing script) Security considerations addressed (non-root user, minimal packages) .dockerignore configured to exclude unnecessary files Build arguments documented and sensible defaults provided Pull Request Template \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ## Description Brief description of the new image or changes. ## Type of Change - [ ] New Docker image - [ ] Enhancement to existing image - [ ] Bug fix - [ ] Documentation update ## Testing - [ ] Local build successful - [ ] Manual functionality testing complete - [ ] Automated tests pass - [ ] Security scan results reviewed ## Documentation - [ ] Image documentation created/updated - [ ] Navigation updated in mkdocs.yml - [ ] Usage examples provided - [ ] Troubleshooting section included ## Checklist - [ ] Dockerfile follows best practices - [ ] Image uses non-root user - [ ] Minimal package installation - [ ] Health check implemented (if applicable) - [ ] Entry point script provided (if needed) - [ ] .dockerignore configured ## Additional Notes Any additional information about the implementation. Review Criteria \u00b6 Reviewers will evaluate: Technical Quality Dockerfile best practices Security considerations Performance optimization Error handling Documentation Quality Completeness and accuracy Usage examples Troubleshooting guidance Integration with existing docs Testing Coverage Automated test coverage Manual testing verification Error condition handling Maintainability Code clarity and organization Update procedures Dependency management Common Patterns \u00b6 Development Tool Images \u00b6 For images containing development tools: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Pattern: Development environment FROM base-runtime AS development # Install development tools RUN package-manager install dev-tools # Configure development environment ENV DEVELOPMENT_MODE = true COPY dev-config/ /etc/dev-config/ # Keep runtime optimized FROM base-runtime AS production COPY --from = development /usr/local/bin /usr/local/bin CI/CD Tool Images \u00b6 For CI/CD pipeline tools: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Pattern: CI/CD tool FROM minimal-base # Install CI tools RUN install-ci-tools # Add pipeline scripts COPY scripts/ /usr/local/bin/ RUN chmod +x /usr/local/bin/* # Configure for automation ENV AUTOMATION_MODE = true ENTRYPOINT [ \"/usr/local/bin/entrypoint.sh\" ] Language Runtime Images \u00b6 For language-specific runtimes: 1 2 3 4 5 6 7 8 9 10 11 # Pattern: Language runtime FROM official-language-image # Add common tools RUN install-language-tools # Configure language environment ENV LANGUAGE_ENV = production # Add helpful utilities COPY utilities/ /usr/local/bin/ Maintenance Responsibilities \u00b6 After Contribution \u00b6 Once your image is accepted: Monitor issues related to your image Respond to bug reports in a timely manner Propose updates for security patches and new features Maintain documentation accuracy Participate in reviews of related changes Long-term Ownership \u00b6 Consider the long-term maintenance: Dependency updates : Regular updates for security and features Base image updates : Following upstream base image changes Documentation maintenance : Keeping docs current with changes Community support : Helping other users with issues Related Documentation \u00b6 Building Locally - Local development and testing Maintenance - Ongoing maintenance procedures Architecture Overview - How images fit into infrastructure CI/CD Pipeline - Automated building process Assumption : Contributors have basic Docker knowledge and can follow standard GitHub contribution workflows. Complex images may require additional review time and documentation. Validation needed: Confirm contribution workflow and review capacity with maintainer team. Maintainer : WebGrip Ops Team Issues : GitHub Issues Discussions : GitHub Discussions","title":"Contributing Images"},{"location":"operations/contributing-images/#contributing-images","text":"Guide for contributing new Docker images or improving existing ones in the WebGrip infrastructure repository.","title":"Contributing Images"},{"location":"operations/contributing-images/#overview","text":"Contributing to our infrastructure helps: \u2705 Expand capabilities with new development tools and environments \u2705 Improve existing images with performance optimizations and feature additions \u2705 Share knowledge through documentation and best practices \u2705 Maintain quality through consistent standards and review processes \u2705 Support the community by solving common development challenges","title":"Overview"},{"location":"operations/contributing-images/#contribution-process","text":"","title":"Contribution Process"},{"location":"operations/contributing-images/#1-planning-phase","text":"flowchart TD IDEA[Image Idea] --> RESEARCH[Research Existing Solutions] RESEARCH --> PROPOSAL[Create Proposal Issue] PROPOSAL --> DISCUSSION[Community Discussion] DISCUSSION --> APPROVED{Approved?} APPROVED -->|Yes| DESIGN[Design Phase] APPROVED -->|No| REVISE[Revise Proposal] REVISE --> DISCUSSION Before starting development: Check existing images : Review current images to avoid duplication Create an issue : Use our issue template Discuss approach : Engage with the team on implementation strategy Get approval : Wait for maintainer approval before significant work","title":"1. Planning Phase"},{"location":"operations/contributing-images/#2-development-phase","text":"flowchart LR FORK[Fork Repository] --> BRANCH[Create Feature Branch] BRANCH --> DEVELOP[Develop Image] DEVELOP --> TEST[Local Testing] TEST --> DOCUMENT[Documentation] DOCUMENT --> PR[Create Pull Request] PR --> REVIEW[Code Review] REVIEW --> MERGE[Merge to Main]","title":"2. Development Phase"},{"location":"operations/contributing-images/#creating-a-new-image","text":"","title":"Creating a New Image"},{"location":"operations/contributing-images/#directory-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Create new image directory mkdir -p ops/docker/my-new-image # Standard structure ops/docker/my-new-image/ \u251c\u2500\u2500 Dockerfile # Main build file \u251c\u2500\u2500 README.md # Image-specific documentation \u251c\u2500\u2500 .dockerignore # Build context exclusions \u251c\u2500\u2500 entrypoint.sh # Custom entry point (if needed) \u251c\u2500\u2500 config/ # Configuration files \u2502 \u251c\u2500\u2500 tool.conf \u2502 \u2514\u2500\u2500 env.sh \u2514\u2500\u2500 scripts/ # Helper scripts \u251c\u2500\u2500 setup.sh \u2514\u2500\u2500 healthcheck.sh","title":"Directory Structure"},{"location":"operations/contributing-images/#dockerfile-best-practices","text":"","title":"Dockerfile Best Practices"},{"location":"operations/contributing-images/#base-image-selection","text":"1 2 3 4 5 # Prefer official, minimal base images FROM node:20-alpine3.18 # Good: official + minimal FROM alpine:3.22.1 # Good: minimal FROM ubuntu:22.04 # OK: official but larger FROM my-custom-base:latest # Avoid: non-standard base","title":"Base Image Selection"},{"location":"operations/contributing-images/#multi-stage-build-pattern","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # Build stage - install build dependencies FROM node:20-alpine3.18 AS build WORKDIR /build # Copy package files first (for layer caching) COPY package*.json ./ RUN npm ci --only = production # Copy source code COPY . . RUN npm run build # Runtime stage - minimal runtime dependencies FROM node:20-alpine3.18 AS runtime # Create non-root user RUN addgroup -g 1001 -S appgroup && \\ adduser -S appuser -u 1001 -G appgroup # Install runtime dependencies only RUN apk add --no-cache \\ ca-certificates \\ curl # Copy artifacts from build stage COPY --from = build /build/dist /app COPY --from = build /build/node_modules /app/node_modules # Set ownership and switch to non-root user RUN chown -R appuser:appgroup /app USER appuser WORKDIR /app EXPOSE 3000 # Health check HEALTHCHECK --interval = 30s --timeout = 3s --start-period = 5s --retries = 3 \\ CMD curl -f http://localhost:3000/health || exit 1 ENTRYPOINT [ \"node\" , \"server.js\" ]","title":"Multi-stage Build Pattern"},{"location":"operations/contributing-images/#layer-optimization","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # \u274c BAD: Creates many layers RUN apt-get update RUN apt-get install -y curl RUN apt-get install -y git RUN apt-get install -y build-essential RUN rm -rf /var/lib/apt/lists/* # \u2705 GOOD: Single layer with cleanup RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ curl \\ git \\ build-essential && \\ rm -rf /var/lib/apt/lists/*","title":"Layer Optimization"},{"location":"operations/contributing-images/#build-arguments-and-environment","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Build-time configuration ARG NODE_VERSION = 20 ARG BUILD_DATE ARG VERSION # Runtime environment ENV NODE_ENV = production \\ PORT = 3000 \\ LOG_LEVEL = info # Labels for metadata LABEL maintainer = \"WebGrip Ops Team <ops@webgrip.nl>\" \\ org.opencontainers.image.title = \"My Tool\" \\ org.opencontainers.image.description = \"Description of the tool\" \\ org.opencontainers.image.version = \" ${ VERSION } \" \\ org.opencontainers.image.created = \" ${ BUILD_DATE } \" \\ org.opencontainers.image.source = \"https://github.com/webgrip/infrastructure\"","title":"Build Arguments and Environment"},{"location":"operations/contributing-images/#example-creating-a-python-tools-image","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # ops/docker/python-tools/Dockerfile ARG PYTHON_VERSION = 3 .11 # Build stage FROM python:${PYTHON_VERSION}-slim-bookworm AS build # System build dependencies RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ build-essential \\ curl \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* # Python tools installation RUN pip install --no-cache-dir \\ poetry \\ black \\ flake8 \\ mypy \\ pytest \\ jupyter # Runtime stage FROM python:${PYTHON_VERSION}-slim-bookworm AS runtime # Runtime dependencies RUN apt-get update && \\ apt-get install -y --no-install-recommends \\ git \\ curl \\ ca-certificates && \\ rm -rf /var/lib/apt/lists/* # Copy Python tools from build stage COPY --from = build /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages COPY --from = build /usr/local/bin /usr/local/bin # Create non-root user RUN groupadd -r python && useradd -r -g python python # Set working directory WORKDIR /workspace # Switch to non-root user USER python # Verify installation RUN python --version && \\ poetry --version && \\ black --version ENTRYPOINT [ \"bash\" ]","title":"Example: Creating a Python Tools Image"},{"location":"operations/contributing-images/#configuration-files","text":"","title":"Configuration Files"},{"location":"operations/contributing-images/#dockerignore","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ops/docker/my-new-image/.dockerignore **/.git **/.gitignore **/README.md **/Dockerfile **/docker-compose*.yml **/.dockerignore **/.vscode **/.idea **/node_modules **/target **/*.log **/tmp **/temp .DS_Store Thumbs.db","title":".dockerignore"},{"location":"operations/contributing-images/#health-check-script","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # ops/docker/my-new-image/scripts/healthcheck.sh set -e # Check if main service is running if pgrep -f \"my-service\" > /dev/null ; then echo \"Service is running\" exit 0 else echo \"Service is not running\" exit 1 fi","title":"Health Check Script"},{"location":"operations/contributing-images/#entry-point-script","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # ops/docker/my-new-image/entrypoint.sh set -e # Setup function setup_environment () { echo \"Setting up environment...\" # Create necessary directories mkdir -p /workspace/.cache # Set permissions chown -R $( id -u ) : $( id -g ) /workspace echo \"Environment setup complete\" } # Main execution main () { setup_environment # Execute the main command exec \" $@ \" } # Run main function main \" $@ \"","title":"Entry Point Script"},{"location":"operations/contributing-images/#testing-new-images","text":"","title":"Testing New Images"},{"location":"operations/contributing-images/#local-testing-checklist","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 1. Build image docker build -t webgrip/my-new-image:test ops/docker/my-new-image/ # 2. Basic functionality test docker run --rm webgrip/my-new-image:test --version # 3. Interactive test docker run -it --rm webgrip/my-new-image:test bash # 4. Volume mounting test docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/my-new-image:test ls -la # 5. Environment variable test docker run --rm -e TEST_VAR = hello \\ webgrip/my-new-image:test env | grep TEST_VAR # 6. Health check test (if implemented) docker run -d --name test-container webgrip/my-new-image:test sleep 10 docker exec test-container /scripts/healthcheck.sh docker rm -f test-container","title":"Local Testing Checklist"},{"location":"operations/contributing-images/#automated-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #!/bin/bash # ops/docker/my-new-image/test.sh set -e IMAGE_NAME = \"webgrip/my-new-image:test\" CONTAINER_NAME = \"test-my-new-image\" echo \"\ud83e\uddea Testing $IMAGE_NAME \" # Build image echo \"Building image...\" docker build -t \" $IMAGE_NAME \" . # Test 1: Basic execution echo \"Test 1: Basic execution\" docker run --rm \" $IMAGE_NAME \" --version # Test 2: Tool availability echo \"Test 2: Tool availability\" docker run --rm \" $IMAGE_NAME \" which python3 docker run --rm \" $IMAGE_NAME \" python3 -c \"import sys; print(sys.version)\" # Test 3: Workspace functionality echo \"Test 3: Workspace functionality\" docker run --rm -v \" $( pwd ) :/workspace\" -w /workspace \\ \" $IMAGE_NAME \" ls -la # Test 4: Non-root user echo \"Test 4: Non-root user\" USER_ID = $( docker run --rm \" $IMAGE_NAME \" id -u ) if [ \" $USER_ID \" = \"0\" ] ; then echo \"\u274c Container running as root\" exit 1 else echo \"\u2705 Container running as non-root user ( $USER_ID )\" fi # Test 5: Security scan echo \"Test 5: Security scan\" if command -v trivy >/dev/null 2 > & 1 ; then trivy image \" $IMAGE_NAME \" else echo \"\u26a0\ufe0f Trivy not available, skipping security scan\" fi echo \"\u2705 All tests passed!\"","title":"Automated Testing"},{"location":"operations/contributing-images/#integration-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # .github/workflows/test-new-image.yml name : Test New Image on : pull_request : paths : - 'ops/docker/my-new-image/**' jobs : test : runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Build image run : | docker build -t test-image ops/docker/my-new-image/ - name : Run tests run : | cd ops/docker/my-new-image chmod +x test.sh ./test.sh - name : Security scan uses : aquasecurity/trivy-action@master with : image-ref : test-image format : sarif output : trivy-results.sarif - name : Upload scan results uses : github/codeql-action/upload-sarif@v2 with : sarif_file : trivy-results.sarif","title":"Integration Testing"},{"location":"operations/contributing-images/#documentation-requirements","text":"","title":"Documentation Requirements"},{"location":"operations/contributing-images/#image-documentation-template","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # My New Image Brief description of what this image provides and its purpose. ## Purpose This image serves as... ## Image Details | Property | Value | |----------|-------| | **Base Image** | `python:3.11-slim-bookworm` | | **Size** | ~200MB | | **Architecture** | AMD64 | | **Registry** | `webgrip/my-new-image` | | **Dockerfile** | [ `ops/docker/my-new-image/Dockerfile` ](../../../ops/docker/my-new-image/Dockerfile) | ## Installed Tools | Tool | Version | Purpose | |------|---------|---------| | **Python** | 3.11 | Runtime environment | | **Poetry** | Latest | Dependency management | ## Usage Examples ### Basic Usage ```bash # Run interactive session docker run -it --rm webgrip/my-new-image:latest","title":"Image Documentation Template"},{"location":"operations/contributing-images/#project-development","text":"1 2 3 4 # Mount project directory docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/my-new-image:latest \\ python main.py","title":"Project Development"},{"location":"operations/contributing-images/#configuration","text":"","title":"Configuration"},{"location":"operations/contributing-images/#environment-variables","text":"Variable Default Purpose PYTHON_ENV production Python environment","title":"Environment Variables"},{"location":"operations/contributing-images/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"operations/contributing-images/#common-issues","text":"Tool not found 1 2 # Verify installation docker run --rm webgrip/my-new-image:latest which python3","title":"Common Issues"},{"location":"operations/contributing-images/#related-documentation","text":"Building Locally Architecture Overview 1 2 3 4 5 6 7 8 ### Integration with Main Documentation Update the main index page to include your new image: ```markdown # Add to docs/techdocs/docs/index.md | [My New Image](docker-images/my-new-image.md) | Python development tools | Complete Python toolchain for development | Update the navigation in mkdocs.yml : 1 2 3 4 # Add to docs/techdocs/mkdocs.yml nav : - Docker Images : - My New Image : docker-images/my-new-image.md","title":"Related Documentation"},{"location":"operations/contributing-images/#code-review-process","text":"","title":"Code Review Process"},{"location":"operations/contributing-images/#pre-review-checklist","text":"Before submitting a pull request: Dockerfile follows best practices (multi-stage, layer optimization, security) Image builds successfully locally Basic functionality tested with manual verification Documentation created following template Tests implemented (automated testing script) Security considerations addressed (non-root user, minimal packages) .dockerignore configured to exclude unnecessary files Build arguments documented and sensible defaults provided","title":"Pre-Review Checklist"},{"location":"operations/contributing-images/#pull-request-template","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ## Description Brief description of the new image or changes. ## Type of Change - [ ] New Docker image - [ ] Enhancement to existing image - [ ] Bug fix - [ ] Documentation update ## Testing - [ ] Local build successful - [ ] Manual functionality testing complete - [ ] Automated tests pass - [ ] Security scan results reviewed ## Documentation - [ ] Image documentation created/updated - [ ] Navigation updated in mkdocs.yml - [ ] Usage examples provided - [ ] Troubleshooting section included ## Checklist - [ ] Dockerfile follows best practices - [ ] Image uses non-root user - [ ] Minimal package installation - [ ] Health check implemented (if applicable) - [ ] Entry point script provided (if needed) - [ ] .dockerignore configured ## Additional Notes Any additional information about the implementation.","title":"Pull Request Template"},{"location":"operations/contributing-images/#review-criteria","text":"Reviewers will evaluate: Technical Quality Dockerfile best practices Security considerations Performance optimization Error handling Documentation Quality Completeness and accuracy Usage examples Troubleshooting guidance Integration with existing docs Testing Coverage Automated test coverage Manual testing verification Error condition handling Maintainability Code clarity and organization Update procedures Dependency management","title":"Review Criteria"},{"location":"operations/contributing-images/#common-patterns","text":"","title":"Common Patterns"},{"location":"operations/contributing-images/#development-tool-images","text":"For images containing development tools: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Pattern: Development environment FROM base-runtime AS development # Install development tools RUN package-manager install dev-tools # Configure development environment ENV DEVELOPMENT_MODE = true COPY dev-config/ /etc/dev-config/ # Keep runtime optimized FROM base-runtime AS production COPY --from = development /usr/local/bin /usr/local/bin","title":"Development Tool Images"},{"location":"operations/contributing-images/#cicd-tool-images","text":"For CI/CD pipeline tools: 1 2 3 4 5 6 7 8 9 10 11 12 13 # Pattern: CI/CD tool FROM minimal-base # Install CI tools RUN install-ci-tools # Add pipeline scripts COPY scripts/ /usr/local/bin/ RUN chmod +x /usr/local/bin/* # Configure for automation ENV AUTOMATION_MODE = true ENTRYPOINT [ \"/usr/local/bin/entrypoint.sh\" ]","title":"CI/CD Tool Images"},{"location":"operations/contributing-images/#language-runtime-images","text":"For language-specific runtimes: 1 2 3 4 5 6 7 8 9 10 11 # Pattern: Language runtime FROM official-language-image # Add common tools RUN install-language-tools # Configure language environment ENV LANGUAGE_ENV = production # Add helpful utilities COPY utilities/ /usr/local/bin/","title":"Language Runtime Images"},{"location":"operations/contributing-images/#maintenance-responsibilities","text":"","title":"Maintenance Responsibilities"},{"location":"operations/contributing-images/#after-contribution","text":"Once your image is accepted: Monitor issues related to your image Respond to bug reports in a timely manner Propose updates for security patches and new features Maintain documentation accuracy Participate in reviews of related changes","title":"After Contribution"},{"location":"operations/contributing-images/#long-term-ownership","text":"Consider the long-term maintenance: Dependency updates : Regular updates for security and features Base image updates : Following upstream base image changes Documentation maintenance : Keeping docs current with changes Community support : Helping other users with issues","title":"Long-term Ownership"},{"location":"operations/contributing-images/#related-documentation_1","text":"Building Locally - Local development and testing Maintenance - Ongoing maintenance procedures Architecture Overview - How images fit into infrastructure CI/CD Pipeline - Automated building process Assumption : Contributors have basic Docker knowledge and can follow standard GitHub contribution workflows. Complex images may require additional review time and documentation. Validation needed: Confirm contribution workflow and review capacity with maintainer team. Maintainer : WebGrip Ops Team Issues : GitHub Issues Discussions : GitHub Discussions","title":"Related Documentation"},{"location":"operations/maintaining-techdocs/","text":"Maintaining TechDocs \u00b6 Guide for maintaining and updating the WebGrip Infrastructure TechDocs documentation. Overview \u00b6 This guide helps contributors and maintainers keep the TechDocs documentation accurate, current, and valuable for all users of the WebGrip infrastructure. Documentation Architecture \u00b6 Information Architecture Mapping \u00b6 The TechDocs structure directly maps to the repository organization: 1 2 3 4 5 6 7 8 9 Repository Structure \u2192 Documentation Structure \u251c\u2500\u2500 ops/docker/ \u2192 \u251c\u2500\u2500 docker-images/ \u2502 \u251c\u2500\u2500 rust-ci-runner/ \u2192 \u2502 \u251c\u2500\u2500 rust-ci-runner.md \u2502 \u251c\u2500\u2500 github-runner/ \u2192 \u2502 \u251c\u2500\u2500 github-runner.md \u2502 \u2514\u2500\u2500 ... \u2192 \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 .github/workflows/ \u2192 \u251c\u2500\u2500 cicd/ \u251c\u2500\u2500 tests/playwright-runner/ \u2192 \u251c\u2500\u2500 testing/ \u251c\u2500\u2500 docs/adrs/ \u2192 \u251c\u2500\u2500 adrs/ \u2514\u2500\u2500 docs/techdocs/ \u2192 \u2514\u2500\u2500 (this documentation) Content Organization Principles \u00b6 Service-First Structure : Documentation organized around Docker images as primary services Audience-Specific Sections : Content tailored for developers, DevOps engineers, and QA teams Cross-Linking : Extensive internal links for discoverability Source Citations : All claims link back to source code or configuration Assumption Tracking : Clear marking of inferences with validation suggestions Adding New Content \u00b6 New Docker Image Documentation \u00b6 When adding a new Docker image: Create image documentation file : 1 2 # Create new file following naming convention touch docs/techdocs/docs/docker-images/my-new-image.md Update navigation : 1 2 3 4 # Add to docs/techdocs/mkdocs.yml nav : - Docker Images : - My New Image : docker-images/my-new-image.md Follow documentation template : Purpose and scope Image details table Installed tools and versions Usage examples Configuration options Troubleshooting section Related documentation links Update overview pages : Add to main index page table Update architecture diagrams if needed Add cross-references from related pages New Feature Documentation \u00b6 For new features or significant changes: Identify affected sections : Determine which existing pages need updates Create new pages if needed : For substantial new functionality Update cross-references : Ensure new content is discoverable Add to quick start : Include in relevant quick start workflows Update troubleshooting : Add common issues and solutions Updating Existing Content \u00b6 Regular Content Maintenance \u00b6 Version Information : - Update tool versions in image documentation - Sync version matrices and compatibility tables - Update \"latest\" version references Links and References : - Validate internal links quarterly - Update external links when they change - Fix broken references to source code Examples and Code Snippets : - Test code examples for accuracy - Update deprecated command syntax - Refresh environment variables and configuration Systematic Updates \u00b6 Quarterly Review Process : Link Validation : 1 2 3 # Run link checker on all documentation cd docs/techdocs/docs find . -name \"*.md\" -exec markdown-link-check {} \\; Content Audit : 1 2 3 4 5 # Find outdated content markers grep -r \"TODO\\|FIXME\\|XXX\" docs/techdocs/docs --include = \"*.md\" # Find assumption blocks for validation grep -r \"> Assumption:\" docs/techdocs/docs --include = \"*.md\" Version Synchronization : 1 2 # Update version information across all pages # This should be automated as part of maintenance scripts Content Standards \u00b6 Writing Guidelines \u00b6 Voice and Tone : - Use active voice and clear, direct language - Write for multiple skill levels with appropriate context - Include practical examples and real-world usage patterns Structure : - Use consistent heading hierarchy (H1 \u2192 H2 \u2192 H3) - Include purpose statement at the beginning of each page - Provide table of contents for long pages via MkDocs Technical Content : - Include complete, runnable examples - Provide troubleshooting for common issues - Link to source code and configuration files - Mark assumptions and inferences clearly Documentation Patterns \u00b6 Image Documentation Pattern : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Image Name Brief description and purpose. ## Image Details [Standard table with base image, size, registry, etc.] ## Installed Tools [Table of tools, versions, and purposes] ## Usage Examples [Practical, copy-paste examples] ## Configuration [Environment variables, build args, etc.] ## Troubleshooting [Common issues and solutions] ## Related Documentation [Cross-links to related content] Process Documentation Pattern : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Process Name Overview and purpose. ## Architecture [Mermaid diagram showing process flow] ## Implementation [Detailed steps and configuration] ## Examples [Real-world usage scenarios] ## Troubleshooting [Common issues and debugging] Mermaid Diagram Standards \u00b6 Use consistent Mermaid diagram patterns: flowchart TD START[Start Node] --> PROCESS[Process Step] PROCESS --> DECISION{Decision Point} DECISION -->|Yes| SUCCESS[Success Path] DECISION -->|No| ERROR[Error Path] ERROR --> RETRY[Retry Logic] RETRY --> PROCESS SUCCESS --> END[End Node] Diagram Guidelines : - Use descriptive node labels - Include decision points and error paths - Group related components in subgraphs - Use consistent color coding for different types of nodes - Keep diagrams focused and not overly complex Building and Testing \u00b6 Local Development \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Install MkDocs and dependencies pip install mkdocs mkdocs-material # Navigate to TechDocs directory cd docs/techdocs # Serve locally for development mkdocs serve # Build static site mkdocs build Content Validation \u00b6 1 2 3 4 5 6 7 8 # Validate Markdown syntax markdownlint docs/techdocs/docs/**/*.md # Check for broken links markdown-link-check docs/techdocs/docs/**/*.md # Validate MkDocs configuration mkdocs build --strict Integration Testing \u00b6 The documentation builds automatically when: - Changes are pushed to the main branch - Pull requests modify documentation files - Backstage TechDocs refreshes content PR Review Guidelines \u00b6 Documentation Review Checklist \u00b6 Content Quality : - [ ] Information is accurate and up-to-date - [ ] Examples are complete and runnable - [ ] Assumptions are clearly marked - [ ] Cross-references are appropriate and working Structure and Navigation : - [ ] Content follows established patterns - [ ] Navigation updates are included - [ ] New content is discoverable - [ ] Headings use proper hierarchy Technical Accuracy : - [ ] Code examples have been tested - [ ] Version information is current - [ ] Links to source code are correct - [ ] Configuration examples are valid Style and Consistency : - [ ] Writing follows voice and tone guidelines - [ ] Formatting is consistent with existing content - [ ] Mermaid diagrams follow established patterns - [ ] Table formatting is consistent Review Process \u00b6 Automated Checks : GitHub Actions validate links and build documentation Content Review : Reviewers check accuracy and completeness Style Review : Ensure consistency with existing documentation Technical Review : Validate examples and technical accuracy Integration Test : Verify documentation builds and deploys correctly Troubleshooting \u00b6 Common Issues \u00b6 MkDocs Build Failures : 1 2 3 4 5 # Check configuration syntax mkdocs build --strict # Validate nav structure python -c \"import yaml; yaml.safe_load(open('mkdocs.yml'))\" Link Validation Failures : 1 2 3 4 5 # Check specific file markdown-link-check docs/docker-images/rust-ci-runner.md # Fix common patterns sed -i 's/\\.\\.\\/\\.\\.\\/\\.\\.\\//..\\/..\\//' docs/**/*.md Mermaid Diagram Issues : - Verify syntax using Mermaid Live Editor - Check for proper escaping in YAML configuration - Ensure diagram complexity doesn't exceed rendering limits Getting Help \u00b6 Documentation Issues : - Create GitHub issue with documentation label - Include specific pages and sections affected - Provide suggestions for improvement when possible Technical Questions : - Use GitHub Discussions for questions about content - Tag relevant maintainers for urgent issues - Check existing issues before creating new ones Automation and Tools \u00b6 Maintenance Scripts \u00b6 The repository includes several scripts for documentation maintenance: 1 2 3 4 5 6 7 8 # Validate all documentation scripts/validate-documentation.sh # Update version information scripts/sync-versions.sh # Check for broken links scripts/check-documentation-links.sh GitHub Actions \u00b6 Automated workflows handle: - Link validation on PRs - Documentation building and deployment - Content validation and formatting checks Related Documentation \u00b6 Contributing Images - How to document new images Maintenance - Overall repository maintenance procedures ADRs - Architectural decisions affecting documentation Maintenance Schedule : Documentation should be reviewed quarterly and updated whenever infrastructure changes. Use this guide to ensure consistency and quality across all TechDocs content. Maintainer : WebGrip Ops Team Source : docs/techdocs/ Support : GitHub Issues with documentation label","title":"Maintaining TechDocs"},{"location":"operations/maintaining-techdocs/#maintaining-techdocs","text":"Guide for maintaining and updating the WebGrip Infrastructure TechDocs documentation.","title":"Maintaining TechDocs"},{"location":"operations/maintaining-techdocs/#overview","text":"This guide helps contributors and maintainers keep the TechDocs documentation accurate, current, and valuable for all users of the WebGrip infrastructure.","title":"Overview"},{"location":"operations/maintaining-techdocs/#documentation-architecture","text":"","title":"Documentation Architecture"},{"location":"operations/maintaining-techdocs/#information-architecture-mapping","text":"The TechDocs structure directly maps to the repository organization: 1 2 3 4 5 6 7 8 9 Repository Structure \u2192 Documentation Structure \u251c\u2500\u2500 ops/docker/ \u2192 \u251c\u2500\u2500 docker-images/ \u2502 \u251c\u2500\u2500 rust-ci-runner/ \u2192 \u2502 \u251c\u2500\u2500 rust-ci-runner.md \u2502 \u251c\u2500\u2500 github-runner/ \u2192 \u2502 \u251c\u2500\u2500 github-runner.md \u2502 \u2514\u2500\u2500 ... \u2192 \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 .github/workflows/ \u2192 \u251c\u2500\u2500 cicd/ \u251c\u2500\u2500 tests/playwright-runner/ \u2192 \u251c\u2500\u2500 testing/ \u251c\u2500\u2500 docs/adrs/ \u2192 \u251c\u2500\u2500 adrs/ \u2514\u2500\u2500 docs/techdocs/ \u2192 \u2514\u2500\u2500 (this documentation)","title":"Information Architecture Mapping"},{"location":"operations/maintaining-techdocs/#content-organization-principles","text":"Service-First Structure : Documentation organized around Docker images as primary services Audience-Specific Sections : Content tailored for developers, DevOps engineers, and QA teams Cross-Linking : Extensive internal links for discoverability Source Citations : All claims link back to source code or configuration Assumption Tracking : Clear marking of inferences with validation suggestions","title":"Content Organization Principles"},{"location":"operations/maintaining-techdocs/#adding-new-content","text":"","title":"Adding New Content"},{"location":"operations/maintaining-techdocs/#new-docker-image-documentation","text":"When adding a new Docker image: Create image documentation file : 1 2 # Create new file following naming convention touch docs/techdocs/docs/docker-images/my-new-image.md Update navigation : 1 2 3 4 # Add to docs/techdocs/mkdocs.yml nav : - Docker Images : - My New Image : docker-images/my-new-image.md Follow documentation template : Purpose and scope Image details table Installed tools and versions Usage examples Configuration options Troubleshooting section Related documentation links Update overview pages : Add to main index page table Update architecture diagrams if needed Add cross-references from related pages","title":"New Docker Image Documentation"},{"location":"operations/maintaining-techdocs/#new-feature-documentation","text":"For new features or significant changes: Identify affected sections : Determine which existing pages need updates Create new pages if needed : For substantial new functionality Update cross-references : Ensure new content is discoverable Add to quick start : Include in relevant quick start workflows Update troubleshooting : Add common issues and solutions","title":"New Feature Documentation"},{"location":"operations/maintaining-techdocs/#updating-existing-content","text":"","title":"Updating Existing Content"},{"location":"operations/maintaining-techdocs/#regular-content-maintenance","text":"Version Information : - Update tool versions in image documentation - Sync version matrices and compatibility tables - Update \"latest\" version references Links and References : - Validate internal links quarterly - Update external links when they change - Fix broken references to source code Examples and Code Snippets : - Test code examples for accuracy - Update deprecated command syntax - Refresh environment variables and configuration","title":"Regular Content Maintenance"},{"location":"operations/maintaining-techdocs/#systematic-updates","text":"Quarterly Review Process : Link Validation : 1 2 3 # Run link checker on all documentation cd docs/techdocs/docs find . -name \"*.md\" -exec markdown-link-check {} \\; Content Audit : 1 2 3 4 5 # Find outdated content markers grep -r \"TODO\\|FIXME\\|XXX\" docs/techdocs/docs --include = \"*.md\" # Find assumption blocks for validation grep -r \"> Assumption:\" docs/techdocs/docs --include = \"*.md\" Version Synchronization : 1 2 # Update version information across all pages # This should be automated as part of maintenance scripts","title":"Systematic Updates"},{"location":"operations/maintaining-techdocs/#content-standards","text":"","title":"Content Standards"},{"location":"operations/maintaining-techdocs/#writing-guidelines","text":"Voice and Tone : - Use active voice and clear, direct language - Write for multiple skill levels with appropriate context - Include practical examples and real-world usage patterns Structure : - Use consistent heading hierarchy (H1 \u2192 H2 \u2192 H3) - Include purpose statement at the beginning of each page - Provide table of contents for long pages via MkDocs Technical Content : - Include complete, runnable examples - Provide troubleshooting for common issues - Link to source code and configuration files - Mark assumptions and inferences clearly","title":"Writing Guidelines"},{"location":"operations/maintaining-techdocs/#documentation-patterns","text":"Image Documentation Pattern : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Image Name Brief description and purpose. ## Image Details [Standard table with base image, size, registry, etc.] ## Installed Tools [Table of tools, versions, and purposes] ## Usage Examples [Practical, copy-paste examples] ## Configuration [Environment variables, build args, etc.] ## Troubleshooting [Common issues and solutions] ## Related Documentation [Cross-links to related content] Process Documentation Pattern : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Process Name Overview and purpose. ## Architecture [Mermaid diagram showing process flow] ## Implementation [Detailed steps and configuration] ## Examples [Real-world usage scenarios] ## Troubleshooting [Common issues and debugging]","title":"Documentation Patterns"},{"location":"operations/maintaining-techdocs/#mermaid-diagram-standards","text":"Use consistent Mermaid diagram patterns: flowchart TD START[Start Node] --> PROCESS[Process Step] PROCESS --> DECISION{Decision Point} DECISION -->|Yes| SUCCESS[Success Path] DECISION -->|No| ERROR[Error Path] ERROR --> RETRY[Retry Logic] RETRY --> PROCESS SUCCESS --> END[End Node] Diagram Guidelines : - Use descriptive node labels - Include decision points and error paths - Group related components in subgraphs - Use consistent color coding for different types of nodes - Keep diagrams focused and not overly complex","title":"Mermaid Diagram Standards"},{"location":"operations/maintaining-techdocs/#building-and-testing","text":"","title":"Building and Testing"},{"location":"operations/maintaining-techdocs/#local-development","text":"1 2 3 4 5 6 7 8 9 10 11 # Install MkDocs and dependencies pip install mkdocs mkdocs-material # Navigate to TechDocs directory cd docs/techdocs # Serve locally for development mkdocs serve # Build static site mkdocs build","title":"Local Development"},{"location":"operations/maintaining-techdocs/#content-validation","text":"1 2 3 4 5 6 7 8 # Validate Markdown syntax markdownlint docs/techdocs/docs/**/*.md # Check for broken links markdown-link-check docs/techdocs/docs/**/*.md # Validate MkDocs configuration mkdocs build --strict","title":"Content Validation"},{"location":"operations/maintaining-techdocs/#integration-testing","text":"The documentation builds automatically when: - Changes are pushed to the main branch - Pull requests modify documentation files - Backstage TechDocs refreshes content","title":"Integration Testing"},{"location":"operations/maintaining-techdocs/#pr-review-guidelines","text":"","title":"PR Review Guidelines"},{"location":"operations/maintaining-techdocs/#documentation-review-checklist","text":"Content Quality : - [ ] Information is accurate and up-to-date - [ ] Examples are complete and runnable - [ ] Assumptions are clearly marked - [ ] Cross-references are appropriate and working Structure and Navigation : - [ ] Content follows established patterns - [ ] Navigation updates are included - [ ] New content is discoverable - [ ] Headings use proper hierarchy Technical Accuracy : - [ ] Code examples have been tested - [ ] Version information is current - [ ] Links to source code are correct - [ ] Configuration examples are valid Style and Consistency : - [ ] Writing follows voice and tone guidelines - [ ] Formatting is consistent with existing content - [ ] Mermaid diagrams follow established patterns - [ ] Table formatting is consistent","title":"Documentation Review Checklist"},{"location":"operations/maintaining-techdocs/#review-process","text":"Automated Checks : GitHub Actions validate links and build documentation Content Review : Reviewers check accuracy and completeness Style Review : Ensure consistency with existing documentation Technical Review : Validate examples and technical accuracy Integration Test : Verify documentation builds and deploys correctly","title":"Review Process"},{"location":"operations/maintaining-techdocs/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"operations/maintaining-techdocs/#common-issues","text":"MkDocs Build Failures : 1 2 3 4 5 # Check configuration syntax mkdocs build --strict # Validate nav structure python -c \"import yaml; yaml.safe_load(open('mkdocs.yml'))\" Link Validation Failures : 1 2 3 4 5 # Check specific file markdown-link-check docs/docker-images/rust-ci-runner.md # Fix common patterns sed -i 's/\\.\\.\\/\\.\\.\\/\\.\\.\\//..\\/..\\//' docs/**/*.md Mermaid Diagram Issues : - Verify syntax using Mermaid Live Editor - Check for proper escaping in YAML configuration - Ensure diagram complexity doesn't exceed rendering limits","title":"Common Issues"},{"location":"operations/maintaining-techdocs/#getting-help","text":"Documentation Issues : - Create GitHub issue with documentation label - Include specific pages and sections affected - Provide suggestions for improvement when possible Technical Questions : - Use GitHub Discussions for questions about content - Tag relevant maintainers for urgent issues - Check existing issues before creating new ones","title":"Getting Help"},{"location":"operations/maintaining-techdocs/#automation-and-tools","text":"","title":"Automation and Tools"},{"location":"operations/maintaining-techdocs/#maintenance-scripts","text":"The repository includes several scripts for documentation maintenance: 1 2 3 4 5 6 7 8 # Validate all documentation scripts/validate-documentation.sh # Update version information scripts/sync-versions.sh # Check for broken links scripts/check-documentation-links.sh","title":"Maintenance Scripts"},{"location":"operations/maintaining-techdocs/#github-actions","text":"Automated workflows handle: - Link validation on PRs - Documentation building and deployment - Content validation and formatting checks","title":"GitHub Actions"},{"location":"operations/maintaining-techdocs/#related-documentation","text":"Contributing Images - How to document new images Maintenance - Overall repository maintenance procedures ADRs - Architectural decisions affecting documentation Maintenance Schedule : Documentation should be reviewed quarterly and updated whenever infrastructure changes. Use this guide to ensure consistency and quality across all TechDocs content. Maintainer : WebGrip Ops Team Source : docs/techdocs/ Support : GitHub Issues with documentation label","title":"Related Documentation"},{"location":"operations/maintenance/","text":"Maintenance \u00b6 Comprehensive guide for maintaining and updating the WebGrip infrastructure Docker images and documentation. Overview \u00b6 Maintenance encompasses: \u2705 Regular updates to base images and dependencies \u2705 Security patch management and vulnerability remediation \u2705 Performance monitoring and optimization \u2705 Documentation maintenance to ensure accuracy and relevance \u2705 Quality assurance through automated testing and validation Maintenance Schedule \u00b6 Weekly Tasks \u00b6 gantt title Weekly Maintenance Schedule dateFormat YYYY-MM-DD section Security Security Scans :2024-01-01, 1d Vulnerability Review :2024-01-02, 1d section Performance Build Time Analysis :2024-01-03, 1d section Quality Documentation Review :2024-01-04, 1d Link Validation :2024-01-05, 1d Every Monday : Security and vulnerability scanning 1 2 3 4 5 6 # Automated security scan script #!/bin/bash for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Scanning webgrip/ $image :latest\" trivy image \"webgrip/ $image :latest\" --severity HIGH,CRITICAL done Every Wednesday : Performance and build time monitoring 1 2 3 4 5 6 7 # Performance monitoring script #!/bin/bash for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Testing $image performance...\" time docker pull \"webgrip/ $image :latest\" time docker run --rm \"webgrip/ $image :latest\" echo \"Performance test\" done Every Friday : Documentation review and link validation 1 2 3 # Documentation validation cd docs/techdocs/docs find . -name \"*.md\" -exec markdown-link-check {} \\; Monthly Tasks \u00b6 First Monday of Month : Base image updates - Review base image security advisories - Test updated base images - Update Dockerfiles with new base image versions - Rebuild and test all images Second Monday : Dependency updates - Update language runtimes (Rust, Node.js, PHP, Python) - Update CLI tools and utilities - Test compatibility with existing workflows Third Monday : Performance optimization - Analyze image sizes and build times - Optimize Dockerfile layer caching - Review and update build arguments Fourth Monday : Documentation review - Review and update all image documentation - Validate links and references - Update version information and compatibility matrices Quarterly Tasks \u00b6 Security Review : - Comprehensive security audit of all images - Review and update security practices - Update base images to latest stable versions - Implement new security features Architecture Review : - Evaluate image architecture and dependencies - Consider consolidation or splitting of images - Review integration patterns and usage - Plan for new image requirements Community Feedback : - Review GitHub issues and discussions - Analyze usage patterns from logs - Gather feedback from development teams - Plan improvements based on feedback Image Maintenance \u00b6 Base Image Updates \u00b6 flowchart TD MONITOR[Monitor Base Images] --> CHECK[Check for Updates] CHECK --> SECURITY[Security Advisory Review] SECURITY --> TEST[Test Updated Images] TEST --> COMPATIBLE{Compatible?} COMPATIBLE -->|Yes| UPDATE[Update Dockerfiles] COMPATIBLE -->|No| INVESTIGATE[Investigate Issues] INVESTIGATE --> FIX[Apply Fixes] FIX --> TEST UPDATE --> BUILD[Rebuild Images] BUILD --> DEPLOY[Deploy to Registry] DEPLOY --> VERIFY[Verify Deployment] Monitoring Base Images \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # scripts/monitor-base-images.sh declare -A BASE_IMAGES =( [ \"rust-ci-runner\" ]= \"rust:1.87.0-slim-bookworm\" [ \"github-runner\" ]= \"ghcr.io/actions/actions-runner:2.328.0\" [ \"helm-deploy\" ]= \"alpine:3.21.3\" [ \"playwright-runner\" ]= \"mcr.microsoft.com/playwright:v1.51.0-noble\" [ \"act-runner\" ]= \"alpine:3.22.1\" [ \"rust-releaser\" ]= \"node:22-bookworm-slim\" ) echo \"Checking base image updates...\" for image in \" ${ !BASE_IMAGES[@] } \" ; do base = \" ${ BASE_IMAGES [ $image ] } \" echo \"Checking $image (base: $base )\" # Check for newer versions if docker pull \" $base \" ; then echo \"\u2705 $base is current\" else echo \"\u274c Failed to pull $base \" fi # Check for security vulnerabilities trivy image \" $base \" --severity HIGH,CRITICAL --quiet done Update Process \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #!/bin/bash # scripts/update-base-image.sh IMAGE_NAME = $1 NEW_BASE_VERSION = $2 if [[ -z \" $IMAGE_NAME \" || -z \" $NEW_BASE_VERSION \" ]] ; then echo \"Usage: $0 <image-name> <new-base-version>\" exit 1 fi echo \"Updating $IMAGE_NAME to use base image $NEW_BASE_VERSION \" # Update Dockerfile sed -i \"s/FROM .*/FROM $NEW_BASE_VERSION /\" \"ops/docker/ $IMAGE_NAME /Dockerfile\" # Build and test docker build -t \"webgrip/ $IMAGE_NAME :test-update\" \"ops/docker/ $IMAGE_NAME /\" # Run basic tests echo \"Running basic tests...\" case $IMAGE_NAME in \"rust-ci-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" rustc --version ;; \"github-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" php --version ;; \"helm-deploy\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" helm version ;; \"playwright-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" npx playwright --version ;; \"act-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" act --version ;; \"rust-releaser\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" node --version ;; esac if [[ $? -eq 0 ]] ; then echo \"\u2705 Update successful for $IMAGE_NAME \" echo \"Ready to commit and push changes\" else echo \"\u274c Update failed for $IMAGE_NAME \" exit 1 fi Dependency Management \u00b6 Language Runtime Updates \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash # scripts/update-runtimes.sh # Rust updates echo \"Checking Rust versions...\" LATEST_RUST = $( curl -s https://forge.rust-lang.org/infra/channel-releases.html | grep -o \"1\\.[0-9]\\+\\.[0-9]\\+\" | head -1 ) echo \"Latest Rust: $LATEST_RUST \" # Node.js updates echo \"Checking Node.js versions...\" LATEST_NODE = $( curl -s https://nodejs.org/dist/index.json | jq -r '.[0].version' | sed 's/v//' ) echo \"Latest Node.js: $LATEST_NODE \" # PHP updates echo \"Checking PHP versions...\" LATEST_PHP = $( curl -s https://www.php.net/releases/index.php | grep -o \"8\\.[0-9]\\+\\.[0-9]\\+\" | head -1 ) echo \"Latest PHP: $LATEST_PHP \" # Update Dockerfiles with new versions # This would typically involve careful testing and validation Tool Updates \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash # scripts/update-tools.sh declare -A TOOLS =( [ \"helm\" ]= \"https://api.github.com/repos/helm/helm/releases/latest\" [ \"kubectl\" ]= \"https://storage.googleapis.com/kubernetes-release/release/stable.txt\" [ \"act\" ]= \"https://api.github.com/repos/nektos/act/releases/latest\" [ \"sops\" ]= \"https://api.github.com/repos/mozilla/sops/releases/latest\" ) for tool in \" ${ !TOOLS[@] } \" ; do echo \"Checking $tool updates...\" case $tool in \"kubectl\" ) latest = $( curl -s \" ${ TOOLS [ $tool ] } \" ) ;; * ) latest = $( curl -s \" ${ TOOLS [ $tool ] } \" | jq -r '.tag_name' ) ;; esac echo \" $tool latest version: $latest \" done Security Maintenance \u00b6 Vulnerability Scanning \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/bash # scripts/security-scan.sh IMAGES =( \"webgrip/rust-ci-runner:latest\" \"webgrip/github-runner:latest\" \"webgrip/helm-deploy:latest\" \"webgrip/playwright-runner:latest\" \"webgrip/act-runner:latest\" \"webgrip/rust-releaser:latest\" ) REPORT_DIR = \"security-reports/ $( date +%Y-%m-%d ) \" mkdir -p \" $REPORT_DIR \" for image in \" ${ IMAGES [@] } \" ; do echo \"Scanning $image ...\" # Trivy scan trivy image \" $image \" \\ --format json \\ --output \" $REPORT_DIR / $( basename $image ) -trivy.json\" # Summary report trivy image \" $image \" \\ --severity HIGH,CRITICAL \\ --format table \\ > \" $REPORT_DIR / $( basename $image ) -summary.txt\" done # Generate overall report echo \"# Security Scan Report - $( date ) \" > \" $REPORT_DIR /README.md\" echo \"\" >> \" $REPORT_DIR /README.md\" for image in \" ${ IMAGES [@] } \" ; do echo \"## $( basename $image ) \" >> \" $REPORT_DIR /README.md\" echo '```' >> \" $REPORT_DIR /README.md\" cat \" $REPORT_DIR / $( basename $image ) -summary.txt\" >> \" $REPORT_DIR /README.md\" echo '```' >> \" $REPORT_DIR /README.md\" echo \"\" >> \" $REPORT_DIR /README.md\" done echo \"Security scan complete. Report saved to $REPORT_DIR /\" Security Patch Process \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/bin/bash # scripts/apply-security-patches.sh IMAGE_NAME = $1 CVE_ID = $2 if [[ -z \" $IMAGE_NAME \" || -z \" $CVE_ID \" ]] ; then echo \"Usage: $0 <image-name> <cve-id>\" exit 1 fi echo \"Applying security patch for $CVE_ID in $IMAGE_NAME \" # Create branch for security fix git checkout -b \"security-fix- $CVE_ID - $IMAGE_NAME \" # Update image with security fixes case $IMAGE_NAME in \"rust-ci-runner\" | \"rust-releaser\" ) # Update Rust packages echo \"Updating Rust packages...\" # Add specific package updates to Dockerfile ;; \"github-runner\" | \"playwright-runner\" ) # Update system packages echo \"Updating system packages...\" # Update package versions in Dockerfile ;; \"helm-deploy\" | \"act-runner\" ) # Update Alpine packages echo \"Updating Alpine packages...\" # Update apk packages in Dockerfile ;; esac # Build and test docker build -t \"webgrip/ $IMAGE_NAME :security-fix\" \"ops/docker/ $IMAGE_NAME /\" # Run security scan to verify fix trivy image \"webgrip/ $IMAGE_NAME :security-fix\" --severity HIGH,CRITICAL echo \"Security patch applied. Please review and test before merging.\" Performance Maintenance \u00b6 Build Time Optimization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/bin/bash # scripts/optimize-build-times.sh IMAGES =( rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ) echo \"Analyzing build performance...\" for image in \" ${ IMAGES [@] } \" ; do echo \"Testing $image build time...\" # Clean build start_time = $( date +%s ) docker build --no-cache -t \"webgrip/ $image :perf-test\" \"ops/docker/ $image /\" > /dev/null 2 > & 1 end_time = $( date +%s ) clean_build_time = $(( end_time - start_time )) # Cached build start_time = $( date +%s ) docker build -t \"webgrip/ $image :perf-test-cached\" \"ops/docker/ $image /\" > /dev/null 2 > & 1 end_time = $( date +%s ) cached_build_time = $(( end_time - start_time )) # Image size size = $( docker images \"webgrip/ $image :perf-test\" --format \"table {{.Size}}\" | tail -1 ) echo \" $image : Clean= ${ clean_build_time } s, Cached= ${ cached_build_time } s, Size= $size \" # Cleanup docker rmi \"webgrip/ $image :perf-test\" \"webgrip/ $image :perf-test-cached\" > /dev/null 2 > & 1 done Image Size Monitoring \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash # scripts/monitor-image-sizes.sh echo \"Image Size Report - $( date ) \" > image-sizes.md echo \"==========================\" >> image-sizes.md echo \"\" >> image-sizes.md docker images webgrip/* --format \"table {{.Repository}}:{{.Tag}}\\t{{.Size}}\\t{{.CreatedAt}}\" | \\ grep -v \"REPOSITORY\" | \\ sort -k1 >> image-sizes.md # Check for images over size threshold echo \"\" >> image-sizes.md echo \"Large Images (>1GB):\" >> image-sizes.md docker images webgrip/* --format \"table {{.Repository}}:{{.Tag}}\\t{{.Size}}\" | \\ grep -E \"[0-9\\.]+GB\" >> image-sizes.md || echo \"None\" >> image-sizes.md echo \"Image size report generated: image-sizes.md\" Documentation Maintenance \u00b6 Automated Link Checking \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash # scripts/check-documentation-links.sh echo \"Checking documentation links...\" cd docs/techdocs/docs # Install markdown-link-check if not present if ! command -v markdown-link-check & > /dev/null ; then npm install -g markdown-link-check fi # Create config file for link checking cat > /tmp/link-check-config.json << EOF { \"ignorePatterns\": [ { \"pattern\": \"^http://localhost\" }, { \"pattern\": \"^https://localhost\" } ], \"timeout\": \"20s\", \"retryOn429\": true, \"retryCount\": 3, \"fallbackRetryDelay\": \"30s\" } EOF # Check all markdown files find . -name \"*.md\" -print0 | xargs -0 -I {} markdown-link-check {} -c /tmp/link-check-config.json # Cleanup rm /tmp/link-check-config.json echo \"Link checking complete\" Content Validation \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash # scripts/validate-documentation.sh echo \"Validating documentation content...\" # Check for broken internal references echo \"Checking internal references...\" find docs/techdocs/docs -name \"*.md\" -exec grep -H \"\\(\\.\\./\\|docs/\\)\" {} \\; | \\ while read -r line ; do file = $( echo \" $line \" | cut -d: -f1 ) ref = $( echo \" $line \" | cut -d: -f2- | grep -o '\\(docs/[^)]*\\|\\.\\./[^)]*\\)' | head -1 ) if [[ -n \" $ref \" ]] ; then # Convert relative path to absolute abs_path = $( realpath --relative-to = \" $( pwd ) \" \" $( dirname \" $file \" ) / $ref \" 2 >/dev/null ) if [[ ! -f \" $abs_path \" ]] ; then echo \"\u274c Broken reference in $file : $ref \" fi fi done # Check for outdated version references echo \"Checking for outdated version references...\" grep -r \"v1\\.[0-9]\\+\\.[0-9]\\+\" docs/techdocs/docs --include = \"*.md\" | \\ grep -v \"example\\|placeholder\" | \\ while read -r line ; do echo \"\u26a0\ufe0f Version reference found: $line \" done # Check for TODO/FIXME comments echo \"Checking for TODO/FIXME items...\" grep -r \"TODO\\|FIXME\\|XXX\" docs/techdocs/docs --include = \"*.md\" | \\ while read -r line ; do echo \"\ud83d\udcdd Action item: $line \" done echo \"Documentation validation complete\" Version Synchronization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash # scripts/sync-versions.sh echo \"Synchronizing version information...\" # Get current image versions from registry declare -A CURRENT_VERSIONS IMAGES =( rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ) for image in \" ${ IMAGES [@] } \" ; do # Get image creation date and size info = $( docker inspect \"webgrip/ $image :latest\" --format \"{{.Created}} {{.Size}}\" 2 >/dev/null ) if [[ $? -eq 0 ]] ; then CURRENT_VERSIONS [ $image ]= $info echo \"Found $image : $info \" else echo \"\u26a0\ufe0f Could not fetch info for $image \" fi done # Update documentation with current versions for image in \" ${ IMAGES [@] } \" ; do doc_file = \"docs/techdocs/docs/docker-images/ $image .md\" if [[ -f \" $doc_file \" ]] ; then echo \"Updating version info in $doc_file \" # This would involve updating the version tables in documentation # Implementation depends on specific format used fi done echo \"Version synchronization complete\" Quality Assurance \u00b6 Automated Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/bash # scripts/qa-check.sh echo \"Running quality assurance checks...\" # 1. Docker image builds echo \"Testing image builds...\" for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Building $image ...\" if docker build -q -t \"qa-test- $image \" \"ops/docker/ $image /\" > /dev/null ; then echo \"\u2705 $image builds successfully\" docker rmi \"qa-test- $image \" > /dev/null else echo \"\u274c $image build failed\" fi done # 2. Documentation build echo \"Testing documentation build...\" cd docs/techdocs if mkdocs build > /dev/null 2 > & 1 ; then echo \"\u2705 Documentation builds successfully\" rm -rf site/ else echo \"\u274c Documentation build failed\" fi cd ../.. # 3. Link validation echo \"Validating links...\" ./scripts/check-documentation-links.sh > /dev/null 2 > & 1 if [[ $? -eq 0 ]] ; then echo \"\u2705 All links are valid\" else echo \"\u274c Some links are broken\" fi # 4. Security scan echo \"Running security scans...\" ./scripts/security-scan.sh > /dev/null 2 > & 1 echo \"\u2705 Security scans completed\" echo \"Quality assurance checks complete\" Continuous Monitoring \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # .github/workflows/maintenance.yml name : Maintenance Tasks on : schedule : # Weekly security scans (Mondays at 2 AM UTC) - cron : '0 2 * * 1' # Monthly full maintenance (First Monday of month at 4 AM UTC) - cron : '0 4 1-7 * 1' jobs : security-scan : if : github.event.schedule == '0 2 * * 1' runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Run security scans run : ./scripts/security-scan.sh - name : Upload security reports uses : actions/upload-artifact@v3 with : name : security-reports path : security-reports/ full-maintenance : if : github.event.schedule == '0 4 1-7 * 1' runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Check base image updates run : ./scripts/monitor-base-images.sh - name : Validate documentation run : ./scripts/validate-documentation.sh - name : Performance analysis run : ./scripts/optimize-build-times.sh - name : Create maintenance report run : | echo \"# Monthly Maintenance Report - $(date)\" > maintenance-report.md echo \"Generated on $(date)\" >> maintenance-report.md # Add report sections - name : Upload maintenance report uses : actions/upload-artifact@v3 with : name : maintenance-report path : maintenance-report.md Incident Response \u00b6 Image Failure Response \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #!/bin/bash # scripts/incident-response.sh INCIDENT_TYPE = $1 AFFECTED_IMAGE = $2 case $INCIDENT_TYPE in \"build-failure\" ) echo \"Responding to build failure for $AFFECTED_IMAGE \" # Check recent changes git log --oneline -10 \"ops/docker/ $AFFECTED_IMAGE /\" # Attempt to build with previous version previous_commit = $( git log --format = \"%H\" -n 2 \"ops/docker/ $AFFECTED_IMAGE /\" | tail -1 ) git checkout \" $previous_commit \" -- \"ops/docker/ $AFFECTED_IMAGE /\" if docker build -t \"webgrip/ $AFFECTED_IMAGE :rollback\" \"ops/docker/ $AFFECTED_IMAGE /\" ; then echo \"\u2705 Previous version builds successfully\" echo \"Consider rolling back recent changes\" else echo \"\u274c Previous version also fails to build\" echo \"Deeper investigation required\" fi ;; \"security-vulnerability\" ) echo \"Responding to security vulnerability in $AFFECTED_IMAGE \" # Pull latest base image base_image = $( grep \"FROM\" \"ops/docker/ $AFFECTED_IMAGE /Dockerfile\" | head -1 | awk '{print $2}' ) docker pull \" $base_image \" # Rebuild with latest base docker build --no-cache -t \"webgrip/ $AFFECTED_IMAGE :security-fix\" \"ops/docker/ $AFFECTED_IMAGE /\" # Run security scan trivy image \"webgrip/ $AFFECTED_IMAGE :security-fix\" --severity HIGH,CRITICAL ;; \"performance-degradation\" ) echo \"Responding to performance issues in $AFFECTED_IMAGE \" # Analyze recent build times echo \"Recent build performance analysis needed\" ./scripts/optimize-build-times.sh ;; esac Emergency Rollback \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash # scripts/emergency-rollback.sh IMAGE_NAME = $1 TARGET_SHA = ${ 2 :- HEAD ~1 } if [[ -z \" $IMAGE_NAME \" ]] ; then echo \"Usage: $0 <image-name> [target-sha]\" exit 1 fi echo \"Emergency rollback for $IMAGE_NAME to $TARGET_SHA \" # Create emergency branch git checkout -b \"emergency-rollback- $IMAGE_NAME - $( date +%s ) \" # Rollback to target commit git checkout \" $TARGET_SHA \" -- \"ops/docker/ $IMAGE_NAME /\" # Build and test docker build -t \"webgrip/ $IMAGE_NAME :emergency-rollback\" \"ops/docker/ $IMAGE_NAME /\" # Basic smoke test case $IMAGE_NAME in \"rust-ci-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :emergency-rollback\" rustc --version ;; # Add other image tests as needed esac if [[ $? -eq 0 ]] ; then echo \"\u2705 Emergency rollback successful\" echo \"Create PR to merge emergency rollback\" else echo \"\u274c Emergency rollback failed\" exit 1 fi Documentation Lifecycle \u00b6 Quarterly Review Process \u00b6 Content Audit : Review all documentation for accuracy and completeness Link Validation : Verify all internal and external links Version Updates : Synchronize version information across all docs Usage Analytics : Review most-accessed content and optimize accordingly Community Feedback : Incorporate feedback from GitHub issues and discussions Continuous Improvement \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash # scripts/doc-improvement.sh echo \"Analyzing documentation for improvement opportunities...\" # Find pages with outdated information find docs/techdocs/docs -name \"*.md\" -exec grep -l \"TODO\\|FIXME\\|XXX\" {} \\; # Find pages that haven't been updated recently find docs/techdocs/docs -name \"*.md\" -not -newer /tmp/30-days-ago # Analyze link density (pages with few links might need more cross-references) find docs/techdocs/docs -name \"*.md\" -exec sh -c 'echo \"$(grep -o \"\\[.*\\](.*)\" \"$1\" | wc -l) links in $1\"' _ {} \\; | \\ sort -n | head -10 echo \"Documentation improvement analysis complete\" Related Documentation \u00b6 Building Locally - Local development and testing procedures Contributing Images - Guidelines for contributing new images CI/CD Pipeline - Automated building and deployment Architecture Overview - Overall system architecture Assumption : Maintenance tasks can be automated through scripts and CI/CD pipelines. Manual intervention may be required for complex issues or major version updates. Validation needed: Confirm automation capabilities and manual oversight requirements with operations team. Maintainer : WebGrip Ops Team Scripts : Available in repository scripts/ directory Monitoring : GitHub Actions workflows for automated maintenance tasks","title":"Maintenance"},{"location":"operations/maintenance/#maintenance","text":"Comprehensive guide for maintaining and updating the WebGrip infrastructure Docker images and documentation.","title":"Maintenance"},{"location":"operations/maintenance/#overview","text":"Maintenance encompasses: \u2705 Regular updates to base images and dependencies \u2705 Security patch management and vulnerability remediation \u2705 Performance monitoring and optimization \u2705 Documentation maintenance to ensure accuracy and relevance \u2705 Quality assurance through automated testing and validation","title":"Overview"},{"location":"operations/maintenance/#maintenance-schedule","text":"","title":"Maintenance Schedule"},{"location":"operations/maintenance/#weekly-tasks","text":"gantt title Weekly Maintenance Schedule dateFormat YYYY-MM-DD section Security Security Scans :2024-01-01, 1d Vulnerability Review :2024-01-02, 1d section Performance Build Time Analysis :2024-01-03, 1d section Quality Documentation Review :2024-01-04, 1d Link Validation :2024-01-05, 1d Every Monday : Security and vulnerability scanning 1 2 3 4 5 6 # Automated security scan script #!/bin/bash for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Scanning webgrip/ $image :latest\" trivy image \"webgrip/ $image :latest\" --severity HIGH,CRITICAL done Every Wednesday : Performance and build time monitoring 1 2 3 4 5 6 7 # Performance monitoring script #!/bin/bash for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Testing $image performance...\" time docker pull \"webgrip/ $image :latest\" time docker run --rm \"webgrip/ $image :latest\" echo \"Performance test\" done Every Friday : Documentation review and link validation 1 2 3 # Documentation validation cd docs/techdocs/docs find . -name \"*.md\" -exec markdown-link-check {} \\;","title":"Weekly Tasks"},{"location":"operations/maintenance/#monthly-tasks","text":"First Monday of Month : Base image updates - Review base image security advisories - Test updated base images - Update Dockerfiles with new base image versions - Rebuild and test all images Second Monday : Dependency updates - Update language runtimes (Rust, Node.js, PHP, Python) - Update CLI tools and utilities - Test compatibility with existing workflows Third Monday : Performance optimization - Analyze image sizes and build times - Optimize Dockerfile layer caching - Review and update build arguments Fourth Monday : Documentation review - Review and update all image documentation - Validate links and references - Update version information and compatibility matrices","title":"Monthly Tasks"},{"location":"operations/maintenance/#quarterly-tasks","text":"Security Review : - Comprehensive security audit of all images - Review and update security practices - Update base images to latest stable versions - Implement new security features Architecture Review : - Evaluate image architecture and dependencies - Consider consolidation or splitting of images - Review integration patterns and usage - Plan for new image requirements Community Feedback : - Review GitHub issues and discussions - Analyze usage patterns from logs - Gather feedback from development teams - Plan improvements based on feedback","title":"Quarterly Tasks"},{"location":"operations/maintenance/#image-maintenance","text":"","title":"Image Maintenance"},{"location":"operations/maintenance/#base-image-updates","text":"flowchart TD MONITOR[Monitor Base Images] --> CHECK[Check for Updates] CHECK --> SECURITY[Security Advisory Review] SECURITY --> TEST[Test Updated Images] TEST --> COMPATIBLE{Compatible?} COMPATIBLE -->|Yes| UPDATE[Update Dockerfiles] COMPATIBLE -->|No| INVESTIGATE[Investigate Issues] INVESTIGATE --> FIX[Apply Fixes] FIX --> TEST UPDATE --> BUILD[Rebuild Images] BUILD --> DEPLOY[Deploy to Registry] DEPLOY --> VERIFY[Verify Deployment]","title":"Base Image Updates"},{"location":"operations/maintenance/#monitoring-base-images","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # scripts/monitor-base-images.sh declare -A BASE_IMAGES =( [ \"rust-ci-runner\" ]= \"rust:1.87.0-slim-bookworm\" [ \"github-runner\" ]= \"ghcr.io/actions/actions-runner:2.328.0\" [ \"helm-deploy\" ]= \"alpine:3.21.3\" [ \"playwright-runner\" ]= \"mcr.microsoft.com/playwright:v1.51.0-noble\" [ \"act-runner\" ]= \"alpine:3.22.1\" [ \"rust-releaser\" ]= \"node:22-bookworm-slim\" ) echo \"Checking base image updates...\" for image in \" ${ !BASE_IMAGES[@] } \" ; do base = \" ${ BASE_IMAGES [ $image ] } \" echo \"Checking $image (base: $base )\" # Check for newer versions if docker pull \" $base \" ; then echo \"\u2705 $base is current\" else echo \"\u274c Failed to pull $base \" fi # Check for security vulnerabilities trivy image \" $base \" --severity HIGH,CRITICAL --quiet done","title":"Monitoring Base Images"},{"location":"operations/maintenance/#update-process","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #!/bin/bash # scripts/update-base-image.sh IMAGE_NAME = $1 NEW_BASE_VERSION = $2 if [[ -z \" $IMAGE_NAME \" || -z \" $NEW_BASE_VERSION \" ]] ; then echo \"Usage: $0 <image-name> <new-base-version>\" exit 1 fi echo \"Updating $IMAGE_NAME to use base image $NEW_BASE_VERSION \" # Update Dockerfile sed -i \"s/FROM .*/FROM $NEW_BASE_VERSION /\" \"ops/docker/ $IMAGE_NAME /Dockerfile\" # Build and test docker build -t \"webgrip/ $IMAGE_NAME :test-update\" \"ops/docker/ $IMAGE_NAME /\" # Run basic tests echo \"Running basic tests...\" case $IMAGE_NAME in \"rust-ci-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" rustc --version ;; \"github-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" php --version ;; \"helm-deploy\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" helm version ;; \"playwright-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" npx playwright --version ;; \"act-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" act --version ;; \"rust-releaser\" ) docker run --rm \"webgrip/ $IMAGE_NAME :test-update\" node --version ;; esac if [[ $? -eq 0 ]] ; then echo \"\u2705 Update successful for $IMAGE_NAME \" echo \"Ready to commit and push changes\" else echo \"\u274c Update failed for $IMAGE_NAME \" exit 1 fi","title":"Update Process"},{"location":"operations/maintenance/#dependency-management","text":"","title":"Dependency Management"},{"location":"operations/maintenance/#language-runtime-updates","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash # scripts/update-runtimes.sh # Rust updates echo \"Checking Rust versions...\" LATEST_RUST = $( curl -s https://forge.rust-lang.org/infra/channel-releases.html | grep -o \"1\\.[0-9]\\+\\.[0-9]\\+\" | head -1 ) echo \"Latest Rust: $LATEST_RUST \" # Node.js updates echo \"Checking Node.js versions...\" LATEST_NODE = $( curl -s https://nodejs.org/dist/index.json | jq -r '.[0].version' | sed 's/v//' ) echo \"Latest Node.js: $LATEST_NODE \" # PHP updates echo \"Checking PHP versions...\" LATEST_PHP = $( curl -s https://www.php.net/releases/index.php | grep -o \"8\\.[0-9]\\+\\.[0-9]\\+\" | head -1 ) echo \"Latest PHP: $LATEST_PHP \" # Update Dockerfiles with new versions # This would typically involve careful testing and validation","title":"Language Runtime Updates"},{"location":"operations/maintenance/#tool-updates","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash # scripts/update-tools.sh declare -A TOOLS =( [ \"helm\" ]= \"https://api.github.com/repos/helm/helm/releases/latest\" [ \"kubectl\" ]= \"https://storage.googleapis.com/kubernetes-release/release/stable.txt\" [ \"act\" ]= \"https://api.github.com/repos/nektos/act/releases/latest\" [ \"sops\" ]= \"https://api.github.com/repos/mozilla/sops/releases/latest\" ) for tool in \" ${ !TOOLS[@] } \" ; do echo \"Checking $tool updates...\" case $tool in \"kubectl\" ) latest = $( curl -s \" ${ TOOLS [ $tool ] } \" ) ;; * ) latest = $( curl -s \" ${ TOOLS [ $tool ] } \" | jq -r '.tag_name' ) ;; esac echo \" $tool latest version: $latest \" done","title":"Tool Updates"},{"location":"operations/maintenance/#security-maintenance","text":"","title":"Security Maintenance"},{"location":"operations/maintenance/#vulnerability-scanning","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/bash # scripts/security-scan.sh IMAGES =( \"webgrip/rust-ci-runner:latest\" \"webgrip/github-runner:latest\" \"webgrip/helm-deploy:latest\" \"webgrip/playwright-runner:latest\" \"webgrip/act-runner:latest\" \"webgrip/rust-releaser:latest\" ) REPORT_DIR = \"security-reports/ $( date +%Y-%m-%d ) \" mkdir -p \" $REPORT_DIR \" for image in \" ${ IMAGES [@] } \" ; do echo \"Scanning $image ...\" # Trivy scan trivy image \" $image \" \\ --format json \\ --output \" $REPORT_DIR / $( basename $image ) -trivy.json\" # Summary report trivy image \" $image \" \\ --severity HIGH,CRITICAL \\ --format table \\ > \" $REPORT_DIR / $( basename $image ) -summary.txt\" done # Generate overall report echo \"# Security Scan Report - $( date ) \" > \" $REPORT_DIR /README.md\" echo \"\" >> \" $REPORT_DIR /README.md\" for image in \" ${ IMAGES [@] } \" ; do echo \"## $( basename $image ) \" >> \" $REPORT_DIR /README.md\" echo '```' >> \" $REPORT_DIR /README.md\" cat \" $REPORT_DIR / $( basename $image ) -summary.txt\" >> \" $REPORT_DIR /README.md\" echo '```' >> \" $REPORT_DIR /README.md\" echo \"\" >> \" $REPORT_DIR /README.md\" done echo \"Security scan complete. Report saved to $REPORT_DIR /\"","title":"Vulnerability Scanning"},{"location":"operations/maintenance/#security-patch-process","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/bin/bash # scripts/apply-security-patches.sh IMAGE_NAME = $1 CVE_ID = $2 if [[ -z \" $IMAGE_NAME \" || -z \" $CVE_ID \" ]] ; then echo \"Usage: $0 <image-name> <cve-id>\" exit 1 fi echo \"Applying security patch for $CVE_ID in $IMAGE_NAME \" # Create branch for security fix git checkout -b \"security-fix- $CVE_ID - $IMAGE_NAME \" # Update image with security fixes case $IMAGE_NAME in \"rust-ci-runner\" | \"rust-releaser\" ) # Update Rust packages echo \"Updating Rust packages...\" # Add specific package updates to Dockerfile ;; \"github-runner\" | \"playwright-runner\" ) # Update system packages echo \"Updating system packages...\" # Update package versions in Dockerfile ;; \"helm-deploy\" | \"act-runner\" ) # Update Alpine packages echo \"Updating Alpine packages...\" # Update apk packages in Dockerfile ;; esac # Build and test docker build -t \"webgrip/ $IMAGE_NAME :security-fix\" \"ops/docker/ $IMAGE_NAME /\" # Run security scan to verify fix trivy image \"webgrip/ $IMAGE_NAME :security-fix\" --severity HIGH,CRITICAL echo \"Security patch applied. Please review and test before merging.\"","title":"Security Patch Process"},{"location":"operations/maintenance/#performance-maintenance","text":"","title":"Performance Maintenance"},{"location":"operations/maintenance/#build-time-optimization","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/bin/bash # scripts/optimize-build-times.sh IMAGES =( rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ) echo \"Analyzing build performance...\" for image in \" ${ IMAGES [@] } \" ; do echo \"Testing $image build time...\" # Clean build start_time = $( date +%s ) docker build --no-cache -t \"webgrip/ $image :perf-test\" \"ops/docker/ $image /\" > /dev/null 2 > & 1 end_time = $( date +%s ) clean_build_time = $(( end_time - start_time )) # Cached build start_time = $( date +%s ) docker build -t \"webgrip/ $image :perf-test-cached\" \"ops/docker/ $image /\" > /dev/null 2 > & 1 end_time = $( date +%s ) cached_build_time = $(( end_time - start_time )) # Image size size = $( docker images \"webgrip/ $image :perf-test\" --format \"table {{.Size}}\" | tail -1 ) echo \" $image : Clean= ${ clean_build_time } s, Cached= ${ cached_build_time } s, Size= $size \" # Cleanup docker rmi \"webgrip/ $image :perf-test\" \"webgrip/ $image :perf-test-cached\" > /dev/null 2 > & 1 done","title":"Build Time Optimization"},{"location":"operations/maintenance/#image-size-monitoring","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash # scripts/monitor-image-sizes.sh echo \"Image Size Report - $( date ) \" > image-sizes.md echo \"==========================\" >> image-sizes.md echo \"\" >> image-sizes.md docker images webgrip/* --format \"table {{.Repository}}:{{.Tag}}\\t{{.Size}}\\t{{.CreatedAt}}\" | \\ grep -v \"REPOSITORY\" | \\ sort -k1 >> image-sizes.md # Check for images over size threshold echo \"\" >> image-sizes.md echo \"Large Images (>1GB):\" >> image-sizes.md docker images webgrip/* --format \"table {{.Repository}}:{{.Tag}}\\t{{.Size}}\" | \\ grep -E \"[0-9\\.]+GB\" >> image-sizes.md || echo \"None\" >> image-sizes.md echo \"Image size report generated: image-sizes.md\"","title":"Image Size Monitoring"},{"location":"operations/maintenance/#documentation-maintenance","text":"","title":"Documentation Maintenance"},{"location":"operations/maintenance/#automated-link-checking","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash # scripts/check-documentation-links.sh echo \"Checking documentation links...\" cd docs/techdocs/docs # Install markdown-link-check if not present if ! command -v markdown-link-check & > /dev/null ; then npm install -g markdown-link-check fi # Create config file for link checking cat > /tmp/link-check-config.json << EOF { \"ignorePatterns\": [ { \"pattern\": \"^http://localhost\" }, { \"pattern\": \"^https://localhost\" } ], \"timeout\": \"20s\", \"retryOn429\": true, \"retryCount\": 3, \"fallbackRetryDelay\": \"30s\" } EOF # Check all markdown files find . -name \"*.md\" -print0 | xargs -0 -I {} markdown-link-check {} -c /tmp/link-check-config.json # Cleanup rm /tmp/link-check-config.json echo \"Link checking complete\"","title":"Automated Link Checking"},{"location":"operations/maintenance/#content-validation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash # scripts/validate-documentation.sh echo \"Validating documentation content...\" # Check for broken internal references echo \"Checking internal references...\" find docs/techdocs/docs -name \"*.md\" -exec grep -H \"\\(\\.\\./\\|docs/\\)\" {} \\; | \\ while read -r line ; do file = $( echo \" $line \" | cut -d: -f1 ) ref = $( echo \" $line \" | cut -d: -f2- | grep -o '\\(docs/[^)]*\\|\\.\\./[^)]*\\)' | head -1 ) if [[ -n \" $ref \" ]] ; then # Convert relative path to absolute abs_path = $( realpath --relative-to = \" $( pwd ) \" \" $( dirname \" $file \" ) / $ref \" 2 >/dev/null ) if [[ ! -f \" $abs_path \" ]] ; then echo \"\u274c Broken reference in $file : $ref \" fi fi done # Check for outdated version references echo \"Checking for outdated version references...\" grep -r \"v1\\.[0-9]\\+\\.[0-9]\\+\" docs/techdocs/docs --include = \"*.md\" | \\ grep -v \"example\\|placeholder\" | \\ while read -r line ; do echo \"\u26a0\ufe0f Version reference found: $line \" done # Check for TODO/FIXME comments echo \"Checking for TODO/FIXME items...\" grep -r \"TODO\\|FIXME\\|XXX\" docs/techdocs/docs --include = \"*.md\" | \\ while read -r line ; do echo \"\ud83d\udcdd Action item: $line \" done echo \"Documentation validation complete\"","title":"Content Validation"},{"location":"operations/maintenance/#version-synchronization","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash # scripts/sync-versions.sh echo \"Synchronizing version information...\" # Get current image versions from registry declare -A CURRENT_VERSIONS IMAGES =( rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ) for image in \" ${ IMAGES [@] } \" ; do # Get image creation date and size info = $( docker inspect \"webgrip/ $image :latest\" --format \"{{.Created}} {{.Size}}\" 2 >/dev/null ) if [[ $? -eq 0 ]] ; then CURRENT_VERSIONS [ $image ]= $info echo \"Found $image : $info \" else echo \"\u26a0\ufe0f Could not fetch info for $image \" fi done # Update documentation with current versions for image in \" ${ IMAGES [@] } \" ; do doc_file = \"docs/techdocs/docs/docker-images/ $image .md\" if [[ -f \" $doc_file \" ]] ; then echo \"Updating version info in $doc_file \" # This would involve updating the version tables in documentation # Implementation depends on specific format used fi done echo \"Version synchronization complete\"","title":"Version Synchronization"},{"location":"operations/maintenance/#quality-assurance","text":"","title":"Quality Assurance"},{"location":"operations/maintenance/#automated-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/bash # scripts/qa-check.sh echo \"Running quality assurance checks...\" # 1. Docker image builds echo \"Testing image builds...\" for image in rust-ci-runner github-runner helm-deploy playwright-runner act-runner rust-releaser ; do echo \"Building $image ...\" if docker build -q -t \"qa-test- $image \" \"ops/docker/ $image /\" > /dev/null ; then echo \"\u2705 $image builds successfully\" docker rmi \"qa-test- $image \" > /dev/null else echo \"\u274c $image build failed\" fi done # 2. Documentation build echo \"Testing documentation build...\" cd docs/techdocs if mkdocs build > /dev/null 2 > & 1 ; then echo \"\u2705 Documentation builds successfully\" rm -rf site/ else echo \"\u274c Documentation build failed\" fi cd ../.. # 3. Link validation echo \"Validating links...\" ./scripts/check-documentation-links.sh > /dev/null 2 > & 1 if [[ $? -eq 0 ]] ; then echo \"\u2705 All links are valid\" else echo \"\u274c Some links are broken\" fi # 4. Security scan echo \"Running security scans...\" ./scripts/security-scan.sh > /dev/null 2 > & 1 echo \"\u2705 Security scans completed\" echo \"Quality assurance checks complete\"","title":"Automated Testing"},{"location":"operations/maintenance/#continuous-monitoring","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # .github/workflows/maintenance.yml name : Maintenance Tasks on : schedule : # Weekly security scans (Mondays at 2 AM UTC) - cron : '0 2 * * 1' # Monthly full maintenance (First Monday of month at 4 AM UTC) - cron : '0 4 1-7 * 1' jobs : security-scan : if : github.event.schedule == '0 2 * * 1' runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Run security scans run : ./scripts/security-scan.sh - name : Upload security reports uses : actions/upload-artifact@v3 with : name : security-reports path : security-reports/ full-maintenance : if : github.event.schedule == '0 4 1-7 * 1' runs-on : ubuntu-latest steps : - uses : actions/checkout@v4 - name : Check base image updates run : ./scripts/monitor-base-images.sh - name : Validate documentation run : ./scripts/validate-documentation.sh - name : Performance analysis run : ./scripts/optimize-build-times.sh - name : Create maintenance report run : | echo \"# Monthly Maintenance Report - $(date)\" > maintenance-report.md echo \"Generated on $(date)\" >> maintenance-report.md # Add report sections - name : Upload maintenance report uses : actions/upload-artifact@v3 with : name : maintenance-report path : maintenance-report.md","title":"Continuous Monitoring"},{"location":"operations/maintenance/#incident-response","text":"","title":"Incident Response"},{"location":"operations/maintenance/#image-failure-response","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #!/bin/bash # scripts/incident-response.sh INCIDENT_TYPE = $1 AFFECTED_IMAGE = $2 case $INCIDENT_TYPE in \"build-failure\" ) echo \"Responding to build failure for $AFFECTED_IMAGE \" # Check recent changes git log --oneline -10 \"ops/docker/ $AFFECTED_IMAGE /\" # Attempt to build with previous version previous_commit = $( git log --format = \"%H\" -n 2 \"ops/docker/ $AFFECTED_IMAGE /\" | tail -1 ) git checkout \" $previous_commit \" -- \"ops/docker/ $AFFECTED_IMAGE /\" if docker build -t \"webgrip/ $AFFECTED_IMAGE :rollback\" \"ops/docker/ $AFFECTED_IMAGE /\" ; then echo \"\u2705 Previous version builds successfully\" echo \"Consider rolling back recent changes\" else echo \"\u274c Previous version also fails to build\" echo \"Deeper investigation required\" fi ;; \"security-vulnerability\" ) echo \"Responding to security vulnerability in $AFFECTED_IMAGE \" # Pull latest base image base_image = $( grep \"FROM\" \"ops/docker/ $AFFECTED_IMAGE /Dockerfile\" | head -1 | awk '{print $2}' ) docker pull \" $base_image \" # Rebuild with latest base docker build --no-cache -t \"webgrip/ $AFFECTED_IMAGE :security-fix\" \"ops/docker/ $AFFECTED_IMAGE /\" # Run security scan trivy image \"webgrip/ $AFFECTED_IMAGE :security-fix\" --severity HIGH,CRITICAL ;; \"performance-degradation\" ) echo \"Responding to performance issues in $AFFECTED_IMAGE \" # Analyze recent build times echo \"Recent build performance analysis needed\" ./scripts/optimize-build-times.sh ;; esac","title":"Image Failure Response"},{"location":"operations/maintenance/#emergency-rollback","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash # scripts/emergency-rollback.sh IMAGE_NAME = $1 TARGET_SHA = ${ 2 :- HEAD ~1 } if [[ -z \" $IMAGE_NAME \" ]] ; then echo \"Usage: $0 <image-name> [target-sha]\" exit 1 fi echo \"Emergency rollback for $IMAGE_NAME to $TARGET_SHA \" # Create emergency branch git checkout -b \"emergency-rollback- $IMAGE_NAME - $( date +%s ) \" # Rollback to target commit git checkout \" $TARGET_SHA \" -- \"ops/docker/ $IMAGE_NAME /\" # Build and test docker build -t \"webgrip/ $IMAGE_NAME :emergency-rollback\" \"ops/docker/ $IMAGE_NAME /\" # Basic smoke test case $IMAGE_NAME in \"rust-ci-runner\" ) docker run --rm \"webgrip/ $IMAGE_NAME :emergency-rollback\" rustc --version ;; # Add other image tests as needed esac if [[ $? -eq 0 ]] ; then echo \"\u2705 Emergency rollback successful\" echo \"Create PR to merge emergency rollback\" else echo \"\u274c Emergency rollback failed\" exit 1 fi","title":"Emergency Rollback"},{"location":"operations/maintenance/#documentation-lifecycle","text":"","title":"Documentation Lifecycle"},{"location":"operations/maintenance/#quarterly-review-process","text":"Content Audit : Review all documentation for accuracy and completeness Link Validation : Verify all internal and external links Version Updates : Synchronize version information across all docs Usage Analytics : Review most-accessed content and optimize accordingly Community Feedback : Incorporate feedback from GitHub issues and discussions","title":"Quarterly Review Process"},{"location":"operations/maintenance/#continuous-improvement","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash # scripts/doc-improvement.sh echo \"Analyzing documentation for improvement opportunities...\" # Find pages with outdated information find docs/techdocs/docs -name \"*.md\" -exec grep -l \"TODO\\|FIXME\\|XXX\" {} \\; # Find pages that haven't been updated recently find docs/techdocs/docs -name \"*.md\" -not -newer /tmp/30-days-ago # Analyze link density (pages with few links might need more cross-references) find docs/techdocs/docs -name \"*.md\" -exec sh -c 'echo \"$(grep -o \"\\[.*\\](.*)\" \"$1\" | wc -l) links in $1\"' _ {} \\; | \\ sort -n | head -10 echo \"Documentation improvement analysis complete\"","title":"Continuous Improvement"},{"location":"operations/maintenance/#related-documentation","text":"Building Locally - Local development and testing procedures Contributing Images - Guidelines for contributing new images CI/CD Pipeline - Automated building and deployment Architecture Overview - Overall system architecture Assumption : Maintenance tasks can be automated through scripts and CI/CD pipelines. Manual intervention may be required for complex issues or major version updates. Validation needed: Confirm automation capabilities and manual oversight requirements with operations team. Maintainer : WebGrip Ops Team Scripts : Available in repository scripts/ directory Monitoring : GitHub Actions workflows for automated maintenance tasks","title":"Related Documentation"},{"location":"overview/architecture/","text":"Architecture Overview \u00b6 System Architecture \u00b6 The WebGrip Infrastructure follows a service-oriented architecture where each Docker image serves as a specialized microservice for different aspects of our CI/CD pipeline. flowchart TB subgraph \"Development\" DEV[Developer] --> LOCAL[Local Development] LOCAL --> ACT[ACT Runner<br/>Local Testing] LOCAL --> RUST_CI[Rust CI Runner<br/>Development Environment] end subgraph \"CI/CD Pipeline\" GH[GitHub Repository] --> ACTIONS[GitHub Actions] ACTIONS --> GH_RUNNER[GitHub Runner<br/>Self-hosted] ACTIONS --> PLAYWRIGHT[Playwright Runner<br/>E2E Testing] ACTIONS --> RUST_REL[Rust Releaser<br/>Release Automation] end subgraph \"Deployment\" ACTIONS --> HELM[Helm Deploy<br/>K8s Deployment] HELM --> K8S[Kubernetes Cluster] end subgraph \"Image Registry\" DOCKER[Docker Registry] --> GH_RUNNER DOCKER --> PLAYWRIGHT DOCKER --> HELM DOCKER --> RUST_CI DOCKER --> ACT DOCKER --> RUST_REL end GH_RUNNER --> DOCKER PLAYWRIGHT --> DOCKER RUST_REL --> DOCKER HELM --> DOCKER RUST_CI --> DOCKER ACT --> DOCKER Component Architecture \u00b6 Docker Image Services \u00b6 Each Docker image is designed as a self-contained service with specific responsibilities: flowchart LR subgraph \"Base Images\" ALPINE[Alpine Linux] RUST[Rust Official] NODE[Node.js] PLAYWRIGHT_BASE[Playwright Base] ACTIONS_BASE[Actions Runner Base] end subgraph \"Our Images\" RUST_CI[Rust CI Runner] GH_RUNNER[GitHub Runner] HELM[Helm Deploy] PLAYWRIGHT[Playwright Runner] ACT[ACT Runner] RUST_REL[Rust Releaser] end ALPINE --> HELM ALPINE --> ACT RUST --> RUST_CI NODE --> RUST_REL PLAYWRIGHT_BASE --> PLAYWRIGHT ACTIONS_BASE --> GH_RUNNER Automation Architecture \u00b6 Our automation follows an event-driven pattern triggered by repository changes: sequenceDiagram participant Dev as Developer participant GH as GitHub participant Actions as GitHub Actions participant Registry as Docker Registry participant K8s as Kubernetes Dev->>GH: Push Dockerfile changes GH->>Actions: Trigger workflow Actions->>Actions: Determine changed directories Actions->>Actions: Build changed images Actions->>Registry: Push new images Note over Registry: Images available for use Dev->>GH: Push application code GH->>Actions: Trigger deployment Actions->>Registry: Pull deployment image Actions->>K8s: Deploy using Helm Design Principles \u00b6 \ud83c\udfaf Single Responsibility \u00b6 Each Docker image has one primary purpose and contains only the tools necessary for that specific function. Example : The Helm Deploy image contains only Alpine Linux + Helm + kubectl, not development tools or testing frameworks. \ud83d\udd27 Composability \u00b6 Images can be used independently or combined in workflows to create more complex automation pipelines. Example : A typical deployment workflow uses: 1. rust-ci-runner for building 2. playwright-runner for testing 3. helm-deploy for deployment \ud83d\udce6 Immutability \u00b6 Images are versioned and immutable. Changes result in new image versions rather than modifying existing ones. Implementation : Each image is tagged with both :latest and :${{ github.sha }} for different use cases. \ud83d\ude80 Performance \u00b6 Images are optimized for fast startup and minimal resource usage in CI/CD environments. Techniques : - Multi-stage builds to reduce final image size - Layer caching optimization - Minimal base images where possible Data Flow \u00b6 Build Pipeline Data Flow \u00b6 flowchart TD SOURCE[Source Code] --> DETECT[Change Detection] DETECT --> BUILD[Image Build] BUILD --> TEST[Image Testing] TEST --> PUSH[Registry Push] PUSH --> TAG[Version Tagging] TAG --> NOTIFY[Availability Notification] Usage Data Flow \u00b6 flowchart TD TRIGGER[Workflow Trigger] --> PULL[Pull Image] PULL --> RUN[Execute Container] RUN --> PROCESS[Process Artifacts] PROCESS --> OUTPUT[Generate Output] OUTPUT --> CLEANUP[Container Cleanup] Technology Stack \u00b6 Core Technologies \u00b6 Layer Technology Purpose Container Runtime Docker Container orchestration and execution CI/CD Platform GitHub Actions Automation workflows and triggering Image Registry Docker Hub Image storage and distribution Documentation MkDocs + Backstage Technical documentation platform Orchestration Kubernetes + Helm Production deployment platform Per-Image Technology Stack \u00b6 Image Base Primary Tools Purpose Rust CI Runner rust:slim-bookworm Rust toolchain, cargo-audit, cargo-tarpaulin Rust development and CI GitHub Runner actions/actions-runner GitHub Actions runner, Helm Self-hosted Actions execution Helm Deploy alpine:3.21.3 Helm, kubectl, git Kubernetes deployment Playwright Runner mcr.microsoft.com/playwright Playwright, Node.js End-to-end browser testing ACT Runner alpine:3.22.1 ACT, Docker, git Local GitHub Actions testing Rust Releaser node:22-bookworm-slim Node.js, Rust, cross-compilation tools Release automation Security Architecture \u00b6 Container Security \u00b6 flowchart TD BASE[Base Image Security] --> SCAN[Vulnerability Scanning] SCAN --> MINIMAL[Minimal Attack Surface] MINIMAL --> USER[Non-root User] USER --> SECRETS[Secret Management] SECRETS --> NETWORK[Network Isolation] Security Measures : - Regular base image updates - Minimal package installation - Non-root user execution where possible - No secrets baked into images - Security scanning in CI pipeline Access Control \u00b6 Registry Access : Controlled via Docker Hub credentials GitHub Actions : Uses repository-level secrets and permissions Kubernetes : RBAC-controlled deployment permissions Scalability Considerations \u00b6 Horizontal Scaling \u00b6 Multiple runner instances can use the same images Registry caching reduces download times Parallel workflow execution supported Vertical Scaling \u00b6 Images designed for various resource profiles Configurable resource limits in Kubernetes Efficient memory and CPU usage patterns Integration Points \u00b6 External Dependencies \u00b6 flowchart LR REPO[This Repository] --> DOCKER_HUB[Docker Hub Registry] REPO --> GH_ACTIONS[GitHub Actions Platform] REPO --> WORKFLOWS[webgrip/workflows Repository] REPO --> K8S[Kubernetes Clusters] REPO --> BACKSTAGE[Backstage Platform] Internal Dependencies \u00b6 Base Images : Official Docker images (Alpine, Rust, Node.js, etc.) Shared Workflows : Reusable workflows from webgrip/workflows Configuration : Settings from catalog-info.yml Operational Architecture \u00b6 Monitoring & Observability \u00b6 Currently implemented: - \u2705 Build success/failure notifications via GitHub Actions - \u2705 Image vulnerability scanning - \u2705 Workflow execution logs Assumption : Detailed runtime monitoring (container metrics, resource usage) is handled by the Kubernetes platform and not part of this repository's scope. Validation needed: Confirm monitoring strategy with ops team. Backup & Recovery \u00b6 Source Code : Backed up via GitHub Images : Stored in Docker Hub with version history Configuration : Version controlled in this repository Disaster Recovery \u00b6 In case of image unavailability: 1. Images can be rebuilt from source using local Docker 2. Alternative registries can be configured 3. Local development possible using docker-compose.yml Related Documentation \u00b6 Purpose & Scope - Why this architecture was chosen Quick Start Guide - How to use this architecture Docker Images - Detailed documentation for each component Operations - Maintenance and operational procedures","title":"Architecture"},{"location":"overview/architecture/#architecture-overview","text":"","title":"Architecture Overview"},{"location":"overview/architecture/#system-architecture","text":"The WebGrip Infrastructure follows a service-oriented architecture where each Docker image serves as a specialized microservice for different aspects of our CI/CD pipeline. flowchart TB subgraph \"Development\" DEV[Developer] --> LOCAL[Local Development] LOCAL --> ACT[ACT Runner<br/>Local Testing] LOCAL --> RUST_CI[Rust CI Runner<br/>Development Environment] end subgraph \"CI/CD Pipeline\" GH[GitHub Repository] --> ACTIONS[GitHub Actions] ACTIONS --> GH_RUNNER[GitHub Runner<br/>Self-hosted] ACTIONS --> PLAYWRIGHT[Playwright Runner<br/>E2E Testing] ACTIONS --> RUST_REL[Rust Releaser<br/>Release Automation] end subgraph \"Deployment\" ACTIONS --> HELM[Helm Deploy<br/>K8s Deployment] HELM --> K8S[Kubernetes Cluster] end subgraph \"Image Registry\" DOCKER[Docker Registry] --> GH_RUNNER DOCKER --> PLAYWRIGHT DOCKER --> HELM DOCKER --> RUST_CI DOCKER --> ACT DOCKER --> RUST_REL end GH_RUNNER --> DOCKER PLAYWRIGHT --> DOCKER RUST_REL --> DOCKER HELM --> DOCKER RUST_CI --> DOCKER ACT --> DOCKER","title":"System Architecture"},{"location":"overview/architecture/#component-architecture","text":"","title":"Component Architecture"},{"location":"overview/architecture/#docker-image-services","text":"Each Docker image is designed as a self-contained service with specific responsibilities: flowchart LR subgraph \"Base Images\" ALPINE[Alpine Linux] RUST[Rust Official] NODE[Node.js] PLAYWRIGHT_BASE[Playwright Base] ACTIONS_BASE[Actions Runner Base] end subgraph \"Our Images\" RUST_CI[Rust CI Runner] GH_RUNNER[GitHub Runner] HELM[Helm Deploy] PLAYWRIGHT[Playwright Runner] ACT[ACT Runner] RUST_REL[Rust Releaser] end ALPINE --> HELM ALPINE --> ACT RUST --> RUST_CI NODE --> RUST_REL PLAYWRIGHT_BASE --> PLAYWRIGHT ACTIONS_BASE --> GH_RUNNER","title":"Docker Image Services"},{"location":"overview/architecture/#automation-architecture","text":"Our automation follows an event-driven pattern triggered by repository changes: sequenceDiagram participant Dev as Developer participant GH as GitHub participant Actions as GitHub Actions participant Registry as Docker Registry participant K8s as Kubernetes Dev->>GH: Push Dockerfile changes GH->>Actions: Trigger workflow Actions->>Actions: Determine changed directories Actions->>Actions: Build changed images Actions->>Registry: Push new images Note over Registry: Images available for use Dev->>GH: Push application code GH->>Actions: Trigger deployment Actions->>Registry: Pull deployment image Actions->>K8s: Deploy using Helm","title":"Automation Architecture"},{"location":"overview/architecture/#design-principles","text":"","title":"Design Principles"},{"location":"overview/architecture/#single-responsibility","text":"Each Docker image has one primary purpose and contains only the tools necessary for that specific function. Example : The Helm Deploy image contains only Alpine Linux + Helm + kubectl, not development tools or testing frameworks.","title":"\ud83c\udfaf Single Responsibility"},{"location":"overview/architecture/#composability","text":"Images can be used independently or combined in workflows to create more complex automation pipelines. Example : A typical deployment workflow uses: 1. rust-ci-runner for building 2. playwright-runner for testing 3. helm-deploy for deployment","title":"\ud83d\udd27 Composability"},{"location":"overview/architecture/#immutability","text":"Images are versioned and immutable. Changes result in new image versions rather than modifying existing ones. Implementation : Each image is tagged with both :latest and :${{ github.sha }} for different use cases.","title":"\ud83d\udce6 Immutability"},{"location":"overview/architecture/#performance","text":"Images are optimized for fast startup and minimal resource usage in CI/CD environments. Techniques : - Multi-stage builds to reduce final image size - Layer caching optimization - Minimal base images where possible","title":"\ud83d\ude80 Performance"},{"location":"overview/architecture/#data-flow","text":"","title":"Data Flow"},{"location":"overview/architecture/#build-pipeline-data-flow","text":"flowchart TD SOURCE[Source Code] --> DETECT[Change Detection] DETECT --> BUILD[Image Build] BUILD --> TEST[Image Testing] TEST --> PUSH[Registry Push] PUSH --> TAG[Version Tagging] TAG --> NOTIFY[Availability Notification]","title":"Build Pipeline Data Flow"},{"location":"overview/architecture/#usage-data-flow","text":"flowchart TD TRIGGER[Workflow Trigger] --> PULL[Pull Image] PULL --> RUN[Execute Container] RUN --> PROCESS[Process Artifacts] PROCESS --> OUTPUT[Generate Output] OUTPUT --> CLEANUP[Container Cleanup]","title":"Usage Data Flow"},{"location":"overview/architecture/#technology-stack","text":"","title":"Technology Stack"},{"location":"overview/architecture/#core-technologies","text":"Layer Technology Purpose Container Runtime Docker Container orchestration and execution CI/CD Platform GitHub Actions Automation workflows and triggering Image Registry Docker Hub Image storage and distribution Documentation MkDocs + Backstage Technical documentation platform Orchestration Kubernetes + Helm Production deployment platform","title":"Core Technologies"},{"location":"overview/architecture/#per-image-technology-stack","text":"Image Base Primary Tools Purpose Rust CI Runner rust:slim-bookworm Rust toolchain, cargo-audit, cargo-tarpaulin Rust development and CI GitHub Runner actions/actions-runner GitHub Actions runner, Helm Self-hosted Actions execution Helm Deploy alpine:3.21.3 Helm, kubectl, git Kubernetes deployment Playwright Runner mcr.microsoft.com/playwright Playwright, Node.js End-to-end browser testing ACT Runner alpine:3.22.1 ACT, Docker, git Local GitHub Actions testing Rust Releaser node:22-bookworm-slim Node.js, Rust, cross-compilation tools Release automation","title":"Per-Image Technology Stack"},{"location":"overview/architecture/#security-architecture","text":"","title":"Security Architecture"},{"location":"overview/architecture/#container-security","text":"flowchart TD BASE[Base Image Security] --> SCAN[Vulnerability Scanning] SCAN --> MINIMAL[Minimal Attack Surface] MINIMAL --> USER[Non-root User] USER --> SECRETS[Secret Management] SECRETS --> NETWORK[Network Isolation] Security Measures : - Regular base image updates - Minimal package installation - Non-root user execution where possible - No secrets baked into images - Security scanning in CI pipeline","title":"Container Security"},{"location":"overview/architecture/#access-control","text":"Registry Access : Controlled via Docker Hub credentials GitHub Actions : Uses repository-level secrets and permissions Kubernetes : RBAC-controlled deployment permissions","title":"Access Control"},{"location":"overview/architecture/#scalability-considerations","text":"","title":"Scalability Considerations"},{"location":"overview/architecture/#horizontal-scaling","text":"Multiple runner instances can use the same images Registry caching reduces download times Parallel workflow execution supported","title":"Horizontal Scaling"},{"location":"overview/architecture/#vertical-scaling","text":"Images designed for various resource profiles Configurable resource limits in Kubernetes Efficient memory and CPU usage patterns","title":"Vertical Scaling"},{"location":"overview/architecture/#integration-points","text":"","title":"Integration Points"},{"location":"overview/architecture/#external-dependencies","text":"flowchart LR REPO[This Repository] --> DOCKER_HUB[Docker Hub Registry] REPO --> GH_ACTIONS[GitHub Actions Platform] REPO --> WORKFLOWS[webgrip/workflows Repository] REPO --> K8S[Kubernetes Clusters] REPO --> BACKSTAGE[Backstage Platform]","title":"External Dependencies"},{"location":"overview/architecture/#internal-dependencies","text":"Base Images : Official Docker images (Alpine, Rust, Node.js, etc.) Shared Workflows : Reusable workflows from webgrip/workflows Configuration : Settings from catalog-info.yml","title":"Internal Dependencies"},{"location":"overview/architecture/#operational-architecture","text":"","title":"Operational Architecture"},{"location":"overview/architecture/#monitoring-observability","text":"Currently implemented: - \u2705 Build success/failure notifications via GitHub Actions - \u2705 Image vulnerability scanning - \u2705 Workflow execution logs Assumption : Detailed runtime monitoring (container metrics, resource usage) is handled by the Kubernetes platform and not part of this repository's scope. Validation needed: Confirm monitoring strategy with ops team.","title":"Monitoring &amp; Observability"},{"location":"overview/architecture/#backup-recovery","text":"Source Code : Backed up via GitHub Images : Stored in Docker Hub with version history Configuration : Version controlled in this repository","title":"Backup &amp; Recovery"},{"location":"overview/architecture/#disaster-recovery","text":"In case of image unavailability: 1. Images can be rebuilt from source using local Docker 2. Alternative registries can be configured 3. Local development possible using docker-compose.yml","title":"Disaster Recovery"},{"location":"overview/architecture/#related-documentation","text":"Purpose & Scope - Why this architecture was chosen Quick Start Guide - How to use this architecture Docker Images - Detailed documentation for each component Operations - Maintenance and operational procedures","title":"Related Documentation"},{"location":"overview/purpose/","text":"Purpose & Scope \u00b6 Mission Statement \u00b6 The WebGrip Infrastructure repository serves as the centralized foundation for our organization's CI/CD infrastructure, providing specialized Docker images and automation workflows that enable consistent, reliable, and efficient development and deployment processes across all WebGrip projects. Primary Objectives \u00b6 \ud83c\udfaf Standardization \u00b6 Provide consistent, well-tested environments for development, testing, and deployment across all WebGrip projects. Each Docker image encapsulates specific tooling and configurations needed for different stages of our software lifecycle. \ud83d\ude80 Efficiency \u00b6 Reduce setup time and eliminate \"works on my machine\" issues by providing pre-configured environments that developers can use immediately without lengthy local setup procedures. \ud83d\udd27 Automation \u00b6 Enable automated building, testing, and deployment workflows through specialized container images that integrate seamlessly with GitHub Actions and Kubernetes infrastructure. \ud83d\udcc8 Scalability \u00b6 Support the growing needs of WebGrip's development teams with infrastructure that can handle multiple projects, different technology stacks, and varying deployment requirements. Scope & Boundaries \u00b6 \u2705 In Scope \u00b6 Docker Images for CI/CD - Development environments (Rust CI Runner) - Testing infrastructure (Playwright Runner) - Deployment tooling (Helm Deploy) - Automation runners (GitHub Actions Runner, ACT Runner) - Release processes (Rust Releaser) Automation Workflows - Automated Docker image building and publishing - Version management and tagging - Multi-platform build support Testing Infrastructure - End-to-end testing with Playwright - Local workflow testing with ACT Documentation & Standards - Comprehensive usage documentation - Best practices and conventions - Architectural decision records \u274c Out of Scope \u00b6 Application Code - Business logic or application-specific code - Project-specific deployment configurations - Individual project dependencies Production Infrastructure - Kubernetes cluster management - Production monitoring and alerting - Database administration - Network configuration Security Management - Secrets management (beyond basic container security) - Access control policies - Compliance frameworks Target Audiences \u00b6 \ud83d\udc68\u200d\ud83d\udcbb Developers \u00b6 Need consistent development environments Want to test GitHub Actions workflows locally Require reliable CI/CD tooling \ud83d\udd27 DevOps Engineers \u00b6 Manage deployment pipelines Maintain CI/CD infrastructure Optimize build and deployment processes \ud83e\uddea QA Engineers \u00b6 Run end-to-end tests consistently Need reliable testing environments Validate deployment processes \ud83d\udcda New Team Members \u00b6 Need to understand our infrastructure Want quick onboarding to development processes Require clear documentation and examples Value Proposition \u00b6 For Individual Developers \u00b6 Faster Onboarding : Get productive immediately with pre-configured environments Consistent Experience : Same tooling and versions across all environments Local Testing : Test CI/CD workflows locally before pushing changes For Development Teams \u00b6 Reduced Friction : Eliminate environment-specific issues Better Collaboration : Shared understanding of infrastructure and processes Quality Assurance : Consistent testing and deployment practices For WebGrip Organization \u00b6 Cost Efficiency : Reduced setup time and infrastructure maintenance overhead Risk Reduction : Standardized, tested infrastructure components Faster Delivery : Streamlined development and deployment processes Success Metrics \u00b6 We measure the success of this infrastructure through: Onboarding Time : New developers productive within hours, not days Build Reliability : >99% success rate for automated builds Developer Satisfaction : Positive feedback on development experience Maintenance Overhead : Minimal time spent on environment issues Integration Points \u00b6 This infrastructure integrates with: GitHub Actions : Primary CI/CD platform using our runner images Kubernetes : Deployment target using Helm Deploy image Docker Registry : Image storage and distribution Backstage : Service catalog and documentation platform Individual Projects : Consumed as base images and tools Assumption : Teams are primarily using GitHub for source control and GitHub Actions for CI/CD. If teams need integration with other platforms (GitLab, Jenkins, etc.), this would require extending our image set or creating new specialized images. Related Documentation \u00b6 Architecture Overview - Technical architecture and design decisions Quick Start Guide - Get started using these tools Contributing Images - Add new infrastructure components","title":"Purpose & Scope"},{"location":"overview/purpose/#purpose-scope","text":"","title":"Purpose &amp; Scope"},{"location":"overview/purpose/#mission-statement","text":"The WebGrip Infrastructure repository serves as the centralized foundation for our organization's CI/CD infrastructure, providing specialized Docker images and automation workflows that enable consistent, reliable, and efficient development and deployment processes across all WebGrip projects.","title":"Mission Statement"},{"location":"overview/purpose/#primary-objectives","text":"","title":"Primary Objectives"},{"location":"overview/purpose/#standardization","text":"Provide consistent, well-tested environments for development, testing, and deployment across all WebGrip projects. Each Docker image encapsulates specific tooling and configurations needed for different stages of our software lifecycle.","title":"\ud83c\udfaf Standardization"},{"location":"overview/purpose/#efficiency","text":"Reduce setup time and eliminate \"works on my machine\" issues by providing pre-configured environments that developers can use immediately without lengthy local setup procedures.","title":"\ud83d\ude80 Efficiency"},{"location":"overview/purpose/#automation","text":"Enable automated building, testing, and deployment workflows through specialized container images that integrate seamlessly with GitHub Actions and Kubernetes infrastructure.","title":"\ud83d\udd27 Automation"},{"location":"overview/purpose/#scalability","text":"Support the growing needs of WebGrip's development teams with infrastructure that can handle multiple projects, different technology stacks, and varying deployment requirements.","title":"\ud83d\udcc8 Scalability"},{"location":"overview/purpose/#scope-boundaries","text":"","title":"Scope &amp; Boundaries"},{"location":"overview/purpose/#in-scope","text":"Docker Images for CI/CD - Development environments (Rust CI Runner) - Testing infrastructure (Playwright Runner) - Deployment tooling (Helm Deploy) - Automation runners (GitHub Actions Runner, ACT Runner) - Release processes (Rust Releaser) Automation Workflows - Automated Docker image building and publishing - Version management and tagging - Multi-platform build support Testing Infrastructure - End-to-end testing with Playwright - Local workflow testing with ACT Documentation & Standards - Comprehensive usage documentation - Best practices and conventions - Architectural decision records","title":"\u2705 In Scope"},{"location":"overview/purpose/#out-of-scope","text":"Application Code - Business logic or application-specific code - Project-specific deployment configurations - Individual project dependencies Production Infrastructure - Kubernetes cluster management - Production monitoring and alerting - Database administration - Network configuration Security Management - Secrets management (beyond basic container security) - Access control policies - Compliance frameworks","title":"\u274c Out of Scope"},{"location":"overview/purpose/#target-audiences","text":"","title":"Target Audiences"},{"location":"overview/purpose/#developers","text":"Need consistent development environments Want to test GitHub Actions workflows locally Require reliable CI/CD tooling","title":"\ud83d\udc68\u200d\ud83d\udcbb Developers"},{"location":"overview/purpose/#devops-engineers","text":"Manage deployment pipelines Maintain CI/CD infrastructure Optimize build and deployment processes","title":"\ud83d\udd27 DevOps Engineers"},{"location":"overview/purpose/#qa-engineers","text":"Run end-to-end tests consistently Need reliable testing environments Validate deployment processes","title":"\ud83e\uddea QA Engineers"},{"location":"overview/purpose/#new-team-members","text":"Need to understand our infrastructure Want quick onboarding to development processes Require clear documentation and examples","title":"\ud83d\udcda New Team Members"},{"location":"overview/purpose/#value-proposition","text":"","title":"Value Proposition"},{"location":"overview/purpose/#for-individual-developers","text":"Faster Onboarding : Get productive immediately with pre-configured environments Consistent Experience : Same tooling and versions across all environments Local Testing : Test CI/CD workflows locally before pushing changes","title":"For Individual Developers"},{"location":"overview/purpose/#for-development-teams","text":"Reduced Friction : Eliminate environment-specific issues Better Collaboration : Shared understanding of infrastructure and processes Quality Assurance : Consistent testing and deployment practices","title":"For Development Teams"},{"location":"overview/purpose/#for-webgrip-organization","text":"Cost Efficiency : Reduced setup time and infrastructure maintenance overhead Risk Reduction : Standardized, tested infrastructure components Faster Delivery : Streamlined development and deployment processes","title":"For WebGrip Organization"},{"location":"overview/purpose/#success-metrics","text":"We measure the success of this infrastructure through: Onboarding Time : New developers productive within hours, not days Build Reliability : >99% success rate for automated builds Developer Satisfaction : Positive feedback on development experience Maintenance Overhead : Minimal time spent on environment issues","title":"Success Metrics"},{"location":"overview/purpose/#integration-points","text":"This infrastructure integrates with: GitHub Actions : Primary CI/CD platform using our runner images Kubernetes : Deployment target using Helm Deploy image Docker Registry : Image storage and distribution Backstage : Service catalog and documentation platform Individual Projects : Consumed as base images and tools Assumption : Teams are primarily using GitHub for source control and GitHub Actions for CI/CD. If teams need integration with other platforms (GitLab, Jenkins, etc.), this would require extending our image set or creating new specialized images.","title":"Integration Points"},{"location":"overview/purpose/#related-documentation","text":"Architecture Overview - Technical architecture and design decisions Quick Start Guide - Get started using these tools Contributing Images - Add new infrastructure components","title":"Related Documentation"},{"location":"overview/quick-start/","text":"Quick Start Guide \u00b6 Get up and running with WebGrip Infrastructure in minutes, not hours. Prerequisites \u00b6 Before you begin, ensure you have: Docker installed and running Git for cloning repositories Access to the WebGrip organization on GitHub Option 1: Using Pre-built Images (Recommended) \u00b6 The fastest way to get started is using our pre-built images from Docker Hub. \ud83e\udd80 Rust Development \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Pull the latest Rust CI image docker pull webgrip/rust-ci-runner:latest # Start a Rust development environment docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash # Inside the container, you now have access to: # - Rust toolchain (latest stable) # - cargo-audit, cargo-tarpaulin # - Common build tools \ud83c\udfad End-to-End Testing \u00b6 1 2 3 4 5 6 7 8 9 # Pull the Playwright testing image docker pull webgrip/playwright-runner:latest # Run in your project directory with tests docker run -it --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test \u2699\ufe0f Local GitHub Actions Testing \u00b6 1 2 3 4 5 6 7 8 9 10 # Pull the ACT runner image docker pull webgrip/act-runner:latest # Test your GitHub Actions workflows locally docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ act \u2638\ufe0f Kubernetes Deployment \u00b6 1 2 3 4 5 6 7 8 9 10 # Pull the Helm deployment image docker pull webgrip/helm-deploy:latest # Deploy to Kubernetes (requires kubectl config) docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp Option 2: Building Locally \u00b6 If you need to modify images or test local changes: Clone the Repository \u00b6 1 2 git clone https://github.com/webgrip/infrastructure.git cd infrastructure Build Specific Images \u00b6 1 2 3 4 5 6 7 # Build all images docker-compose build # Or build specific images docker build -t my-rust-ci ops/docker/rust-ci-runner/ docker build -t my-playwright ops/docker/playwright-runner/ docker build -t my-helm-deploy ops/docker/helm-deploy/ Verify Local Builds \u00b6 1 2 3 4 5 6 7 8 # Test the Rust CI runner docker run --rm my-rust-ci rustc --version # Test the Playwright runner docker run --rm my-playwright npx playwright --version # Test the Helm deploy image docker run --rm my-helm-deploy helm version Common Use Cases \u00b6 \ud83d\udd04 Setting Up CI/CD for a New Project \u00b6 Choose the appropriate images for your technology stack: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # .github/workflows/ci.yml jobs : test : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - uses : actions/checkout@v4 - run : cargo test e2e-test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest steps : - uses : actions/checkout@v4 - run : npx playwright test Configure deployment using the Helm image: 1 2 3 4 5 6 7 deploy : needs : [ test , e2e-test ] runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - uses : actions/checkout@v4 - run : helm upgrade --install myapp ./charts/myapp \ud83e\uddea Local Development Workflow \u00b6 Start your development environment : 1 2 3 # For Rust projects docker run -it --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest bash Test your changes locally before pushing: 1 2 3 4 # Test GitHub Actions workflows docker run -it --rm -v $( pwd ) :/workspace -w /workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/act-runner:latest act Run end-to-end tests : 1 2 docker run -it --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest npx playwright test \ud83d\ude80 Release Process \u00b6 For Rust projects, use our release automation: 1 2 3 4 5 6 7 8 9 10 # Pull the release image docker pull webgrip/rust-releaser:latest # Run release process (configure via environment variables) docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ ./release-script.sh Environment-Specific Configurations \u00b6 Development Environment \u00b6 1 2 3 4 5 6 # Use latest images for development export IMAGE_TAG = latest # Enable verbose logging export RUST_LOG = debug export PLAYWRIGHT_DEBUG = 1 Production Environment \u00b6 1 2 3 4 5 6 # Use specific SHA tags for production export IMAGE_TAG = ${ { github.sha } } # Optimize for production export RUST_LOG = info export NODE_ENV = production Troubleshooting \u00b6 Common Issues \u00b6 \"Permission denied\" errors 1 2 3 4 # Fix file permissions docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ chown -R $( id -u ) : $( id -g ) . Image not found 1 2 3 4 5 # Verify image exists docker images | grep webgrip # Pull latest version docker pull webgrip/rust-ci-runner:latest Container exits immediately 1 2 3 4 5 # Check container logs docker logs <container-id> # Run with interactive shell for debugging docker run -it --entrypoint = /bin/bash webgrip/rust-ci-runner:latest Getting Help \u00b6 Check the logs first: 1 docker logs -f <container-name> Verify image integrity : 1 docker inspect webgrip/rust-ci-runner:latest Test with minimal setup : 1 docker run --rm webgrip/rust-ci-runner:latest rustc --version Next Steps \u00b6 Now that you're up and running: Explore individual images : Check out detailed documentation for each Docker image Understand the CI/CD pipeline : Learn about our automated building process Contribute improvements : Read our contributing guide Set up testing : Configure Playwright testing for your projects Quick Reference \u00b6 Image Quick Reference \u00b6 Need Use This Image Quick Command Rust development webgrip/rust-ci-runner docker run -it --rm -v $(pwd):/workspace webgrip/rust-ci-runner bash E2E testing webgrip/playwright-runner docker run --rm -v $(pwd):/app webgrip/playwright-runner npx playwright test K8s deployment webgrip/helm-deploy docker run --rm -v $(pwd):/workspace webgrip/helm-deploy helm version Local Actions testing webgrip/act-runner docker run --rm -v $(pwd):/workspace webgrip/act-runner act GitHub Actions runner webgrip/github-runner See GitHub Runner docs Release automation webgrip/rust-releaser See Rust Releaser docs Resource Links \u00b6 \ud83d\udcd6 Architecture Overview - Understanding the big picture \ud83d\udee0\ufe0f Operations Guide - Building and maintaining images \ud83d\udc1b Issue Tracker - Report problems or request features \ud83d\udcac Team Contact - Get help from the ops team","title":"Quick Start"},{"location":"overview/quick-start/#quick-start-guide","text":"Get up and running with WebGrip Infrastructure in minutes, not hours.","title":"Quick Start Guide"},{"location":"overview/quick-start/#prerequisites","text":"Before you begin, ensure you have: Docker installed and running Git for cloning repositories Access to the WebGrip organization on GitHub","title":"Prerequisites"},{"location":"overview/quick-start/#option-1-using-pre-built-images-recommended","text":"The fastest way to get started is using our pre-built images from Docker Hub.","title":"Option 1: Using Pre-built Images (Recommended)"},{"location":"overview/quick-start/#rust-development","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Pull the latest Rust CI image docker pull webgrip/rust-ci-runner:latest # Start a Rust development environment docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ webgrip/rust-ci-runner:latest \\ bash # Inside the container, you now have access to: # - Rust toolchain (latest stable) # - cargo-audit, cargo-tarpaulin # - Common build tools","title":"\ud83e\udd80 Rust Development"},{"location":"overview/quick-start/#end-to-end-testing","text":"1 2 3 4 5 6 7 8 9 # Pull the Playwright testing image docker pull webgrip/playwright-runner:latest # Run in your project directory with tests docker run -it --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ npx playwright test","title":"\ud83c\udfad End-to-End Testing"},{"location":"overview/quick-start/#local-github-actions-testing","text":"1 2 3 4 5 6 7 8 9 10 # Pull the ACT runner image docker pull webgrip/act-runner:latest # Test your GitHub Actions workflows locally docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -w /workspace \\ webgrip/act-runner:latest \\ act","title":"\u2699\ufe0f Local GitHub Actions Testing"},{"location":"overview/quick-start/#kubernetes-deployment","text":"1 2 3 4 5 6 7 8 9 10 # Pull the Helm deployment image docker pull webgrip/helm-deploy:latest # Deploy to Kubernetes (requires kubectl config) docker run -it --rm \\ -v $( pwd ) :/workspace \\ -v ~/.kube:/root/.kube \\ -w /workspace \\ webgrip/helm-deploy:latest \\ helm upgrade --install myapp ./charts/myapp","title":"\u2638\ufe0f Kubernetes Deployment"},{"location":"overview/quick-start/#option-2-building-locally","text":"If you need to modify images or test local changes:","title":"Option 2: Building Locally"},{"location":"overview/quick-start/#clone-the-repository","text":"1 2 git clone https://github.com/webgrip/infrastructure.git cd infrastructure","title":"Clone the Repository"},{"location":"overview/quick-start/#build-specific-images","text":"1 2 3 4 5 6 7 # Build all images docker-compose build # Or build specific images docker build -t my-rust-ci ops/docker/rust-ci-runner/ docker build -t my-playwright ops/docker/playwright-runner/ docker build -t my-helm-deploy ops/docker/helm-deploy/","title":"Build Specific Images"},{"location":"overview/quick-start/#verify-local-builds","text":"1 2 3 4 5 6 7 8 # Test the Rust CI runner docker run --rm my-rust-ci rustc --version # Test the Playwright runner docker run --rm my-playwright npx playwright --version # Test the Helm deploy image docker run --rm my-helm-deploy helm version","title":"Verify Local Builds"},{"location":"overview/quick-start/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"overview/quick-start/#setting-up-cicd-for-a-new-project","text":"Choose the appropriate images for your technology stack: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # .github/workflows/ci.yml jobs : test : runs-on : ubuntu-latest container : webgrip/rust-ci-runner:latest steps : - uses : actions/checkout@v4 - run : cargo test e2e-test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest steps : - uses : actions/checkout@v4 - run : npx playwright test Configure deployment using the Helm image: 1 2 3 4 5 6 7 deploy : needs : [ test , e2e-test ] runs-on : ubuntu-latest container : webgrip/helm-deploy:latest steps : - uses : actions/checkout@v4 - run : helm upgrade --install myapp ./charts/myapp","title":"\ud83d\udd04 Setting Up CI/CD for a New Project"},{"location":"overview/quick-start/#local-development-workflow","text":"Start your development environment : 1 2 3 # For Rust projects docker run -it --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest bash Test your changes locally before pushing: 1 2 3 4 # Test GitHub Actions workflows docker run -it --rm -v $( pwd ) :/workspace -w /workspace \\ -v /var/run/docker.sock:/var/run/docker.sock \\ webgrip/act-runner:latest act Run end-to-end tests : 1 2 docker run -it --rm -v $( pwd ) :/app -w /app \\ webgrip/playwright-runner:latest npx playwright test","title":"\ud83e\uddea Local Development Workflow"},{"location":"overview/quick-start/#release-process","text":"For Rust projects, use our release automation: 1 2 3 4 5 6 7 8 9 10 # Pull the release image docker pull webgrip/rust-releaser:latest # Run release process (configure via environment variables) docker run -it --rm \\ -v $( pwd ) :/workspace \\ -w /workspace \\ -e GITHUB_TOKEN = $GITHUB_TOKEN \\ webgrip/rust-releaser:latest \\ ./release-script.sh","title":"\ud83d\ude80 Release Process"},{"location":"overview/quick-start/#environment-specific-configurations","text":"","title":"Environment-Specific Configurations"},{"location":"overview/quick-start/#development-environment","text":"1 2 3 4 5 6 # Use latest images for development export IMAGE_TAG = latest # Enable verbose logging export RUST_LOG = debug export PLAYWRIGHT_DEBUG = 1","title":"Development Environment"},{"location":"overview/quick-start/#production-environment","text":"1 2 3 4 5 6 # Use specific SHA tags for production export IMAGE_TAG = ${ { github.sha } } # Optimize for production export RUST_LOG = info export NODE_ENV = production","title":"Production Environment"},{"location":"overview/quick-start/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"overview/quick-start/#common-issues","text":"\"Permission denied\" errors 1 2 3 4 # Fix file permissions docker run --rm -v $( pwd ) :/workspace -w /workspace \\ webgrip/rust-ci-runner:latest \\ chown -R $( id -u ) : $( id -g ) . Image not found 1 2 3 4 5 # Verify image exists docker images | grep webgrip # Pull latest version docker pull webgrip/rust-ci-runner:latest Container exits immediately 1 2 3 4 5 # Check container logs docker logs <container-id> # Run with interactive shell for debugging docker run -it --entrypoint = /bin/bash webgrip/rust-ci-runner:latest","title":"Common Issues"},{"location":"overview/quick-start/#getting-help","text":"Check the logs first: 1 docker logs -f <container-name> Verify image integrity : 1 docker inspect webgrip/rust-ci-runner:latest Test with minimal setup : 1 docker run --rm webgrip/rust-ci-runner:latest rustc --version","title":"Getting Help"},{"location":"overview/quick-start/#next-steps","text":"Now that you're up and running: Explore individual images : Check out detailed documentation for each Docker image Understand the CI/CD pipeline : Learn about our automated building process Contribute improvements : Read our contributing guide Set up testing : Configure Playwright testing for your projects","title":"Next Steps"},{"location":"overview/quick-start/#quick-reference","text":"","title":"Quick Reference"},{"location":"overview/quick-start/#image-quick-reference","text":"Need Use This Image Quick Command Rust development webgrip/rust-ci-runner docker run -it --rm -v $(pwd):/workspace webgrip/rust-ci-runner bash E2E testing webgrip/playwright-runner docker run --rm -v $(pwd):/app webgrip/playwright-runner npx playwright test K8s deployment webgrip/helm-deploy docker run --rm -v $(pwd):/workspace webgrip/helm-deploy helm version Local Actions testing webgrip/act-runner docker run --rm -v $(pwd):/workspace webgrip/act-runner act GitHub Actions runner webgrip/github-runner See GitHub Runner docs Release automation webgrip/rust-releaser See Rust Releaser docs","title":"Image Quick Reference"},{"location":"overview/quick-start/#resource-links","text":"\ud83d\udcd6 Architecture Overview - Understanding the big picture \ud83d\udee0\ufe0f Operations Guide - Building and maintaining images \ud83d\udc1b Issue Tracker - Report problems or request features \ud83d\udcac Team Contact - Get help from the ops team","title":"Resource Links"},{"location":"testing/playwright-setup/","text":"Playwright Setup \u00b6 Comprehensive guide to setting up and using Playwright for end-to-end testing in WebGrip's infrastructure. Overview \u00b6 Our Playwright testing infrastructure provides: \u2705 Multi-browser testing across Chromium, Firefox, and WebKit \u2705 Containerized execution with consistent environments \u2705 PHP application support for full-stack testing \u2705 CI/CD integration with automated test execution \u2705 Visual regression testing capabilities \u2705 Parallel test execution for faster feedback Architecture \u00b6 Testing Environment Stack \u00b6 flowchart TD subgraph \"Host System\" REPO[Repository Code] CONFIG[Test Configuration] end subgraph \"Playwright Container\" PLAYWRIGHT[Playwright Test Runner] BROWSERS[Browser Engines] PHP[PHP Runtime] NODE[Node.js Runtime] end subgraph \"Test Targets\" LOCAL_APP[Local Application] STAGING[Staging Environment] API[API Endpoints] end subgraph \"Test Outputs\" REPORTS[HTML Reports] SCREENSHOTS[Screenshots] VIDEOS[Test Videos] TRACES[Execution Traces] end REPO --> PLAYWRIGHT CONFIG --> PLAYWRIGHT PLAYWRIGHT --> BROWSERS BROWSERS --> LOCAL_APP BROWSERS --> STAGING BROWSERS --> API PLAYWRIGHT --> REPORTS PLAYWRIGHT --> SCREENSHOTS PLAYWRIGHT --> VIDEOS PLAYWRIGHT --> TRACES Browser Testing Matrix \u00b6 flowchart LR subgraph \"Test Cases\" TESTS[Test Specifications] end subgraph \"Browser Matrix\" CHROMIUM[Chromium<br/>Desktop Chrome] FIREFOX[Firefox<br/>Desktop Firefox] WEBKIT[WebKit<br/>Desktop Safari] end subgraph \"Device Matrix\" DESKTOP[Desktop Viewports] MOBILE[Mobile Viewports] TABLET[Tablet Viewports] end TESTS --> CHROMIUM TESTS --> FIREFOX TESTS --> WEBKIT CHROMIUM --> DESKTOP FIREFOX --> DESKTOP WEBKIT --> DESKTOP CHROMIUM --> MOBILE WEBKIT --> MOBILE Configuration \u00b6 Current Configuration \u00b6 Our Playwright setup is located in tests/playwright-runner/ with the following structure: 1 2 3 4 5 tests/playwright-runner/ \u251c\u2500\u2500 package.json # Dependencies and scripts \u251c\u2500\u2500 playwright.config.ts # Main configuration \u2514\u2500\u2500 tests/ \u2514\u2500\u2500 google.spec.ts # Example test Playwright Configuration File \u00b6 Current configuration ( playwright.config.ts ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export default defineConfig ({ testDir : './tests' , fullyParallel : true , forbidOnly : !! process . env . CI , retries : process.env.CI ? 2 : 0 , workers : process.env.CI ? 1 : undefined , reporter : 'line' , use : { trace : 'on-first-retry' , }, projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, // Additional browsers commented out for now ], }); Recommended Production Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // playwright.config.ts - Enhanced configuration import { defineConfig , devices } from '@playwright/test' ; export default defineConfig ({ testDir : './tests' , // Execution settings fullyParallel : true , forbidOnly : !! process . env . CI , retries : process.env.CI ? 2 : 0 , workers : process.env.CI ? 2 : undefined , timeout : 30000 , // Reporting reporter : [ [ 'html' , { outputFolder : 'playwright-report' }], [ 'json' , { outputFile : 'test-results.json' }], [ 'junit' , { outputFile : 'test-results.xml' }], [ 'line' ] ], // Global test settings use : { baseURL : process.env.BASE_URL || 'http://localhost:8000' , trace : 'on-first-retry' , screenshot : 'only-on-failure' , video : 'retain-on-failure' , actionTimeout : 10000 , navigationTimeout : 15000 , }, // Browser projects projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, { name : 'mobile-chrome' , use : { ... devices [ 'Pixel 5' ] }, }, { name : 'mobile-safari' , use : { ... devices [ 'iPhone 12' ] }, }, ], // Web server for testing webServer : { command : 'php artisan serve' , url : 'http://localhost:8000' , reuseExistingServer : ! process . env . CI , timeout : 120000 , }, }); Installation and Setup \u00b6 Local Development Setup \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Navigate to test directory cd tests/playwright-runner # Install dependencies npm install # Install browser binaries npx playwright install # Install system dependencies (if needed) npx playwright install-deps Docker-based Setup (Recommended) \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Use our Playwright Runner image docker run -it --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash # Inside container - dependencies already installed cd tests/playwright-runner npm install # Install project-specific dependencies npx playwright test Project Integration \u00b6 1 2 3 4 5 6 7 8 # Add Playwright to existing project cd your-project npm init -y npm install -D @playwright/test npx playwright install # Generate initial configuration npx playwright init Writing Tests \u00b6 Basic Test Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // tests/example.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Application Tests' , () => { test . beforeEach ( async ({ page }) => { // Setup before each test await page . goto ( '/' ); }); test ( 'should load homepage' , async ({ page }) => { await expect ( page ). toHaveTitle ( /My Application/ ); await expect ( page . locator ( 'h1' )). toContainText ( 'Welcome' ); }); test ( 'should navigate to about page' , async ({ page }) => { await page . click ( 'a[href=\"/about\"]' ); await expect ( page ). toHaveURL ( /.*about/ ); await expect ( page . locator ( 'h1' )). toContainText ( 'About' ); }); }); API Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // tests/api.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'API Tests' , () => { test ( 'should fetch user data' , async ({ request }) => { const response = await request . get ( '/api/users' ); expect ( response . status ()). toBe ( 200 ); const users = await response . json (); expect ( users ). toHaveLength ( 3 ); expect ( users [ 0 ]). toHaveProperty ( 'name' ); expect ( users [ 0 ]). toHaveProperty ( 'email' ); }); test ( 'should create new user' , async ({ request }) => { const response = await request . post ( '/api/users' , { data : { name : 'Test User' , email : 'test@example.com' } }); expect ( response . status ()). toBe ( 201 ); const user = await response . json (); expect ( user . name ). toBe ( 'Test User' ); }); }); Visual Regression Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/visual.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Visual Regression' , () => { test ( 'should match homepage screenshot' , async ({ page }) => { await page . goto ( '/' ); // Wait for content to load await page . waitForLoadState ( 'networkidle' ); // Take screenshot and compare await expect ( page ). toHaveScreenshot ( 'homepage.png' ); }); test ( 'should match mobile view' , async ({ page }) => { await page . setViewportSize ({ width : 375 , height : 667 }); await page . goto ( '/' ); await expect ( page ). toHaveScreenshot ( 'homepage-mobile.png' ); }); }); PHP Application Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // tests/php-app.spec.ts import { test , expect } from '@playwright/test' ; import { execSync } from 'child_process' ; test . describe ( 'PHP Application' , () => { test . beforeEach ( async () => { // Reset database state execSync ( 'php artisan migrate:fresh --seed' , { stdio : 'inherit' }); }); test ( 'should register new user' , async ({ page }) => { await page . goto ( '/register' ); await page . fill ( '[name=\"name\"]' , 'John Doe' ); await page . fill ( '[name=\"email\"]' , 'john@example.com' ); await page . fill ( '[name=\"password\"]' , 'password123' ); await page . fill ( '[name=\"password_confirmation\"]' , 'password123' ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); await expect ( page . locator ( '.welcome' )). toContainText ( 'Welcome, John Doe' ); }); test ( 'should handle authentication' , async ({ page }) => { // Seed user first execSync ( 'php artisan tinker --execute=\"User::create([\\'name\\' => \\'Test\\', \\'email\\' => \\'test@test.com\\', \\'password\\' => bcrypt(\\'password\\')])\"' ); await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , 'test@test.com' ); await page . fill ( '[name=\"password\"]' , 'password' ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); }); }); Running Tests \u00b6 Basic Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Run all tests npx playwright test # Run specific test file npx playwright test tests/example.spec.ts # Run tests in specific browser npx playwright test --project = chromium # Run tests in headed mode (visible browser) npx playwright test --headed # Run tests with UI mode npx playwright test --ui Docker Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Run tests in Playwright container docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test # Run with custom configuration docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ -e BASE_URL = http://staging.example.com \\ webgrip/playwright-runner:latest \\ npx playwright test --config = tests/playwright-runner/playwright.config.ts CI/CD Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # .github/workflows/e2e-tests.yml name : E2E Tests on : [ push , pull_request ] jobs : test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest services : database : image : postgres:15 env : POSTGRES_PASSWORD : postgres options : >- --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5 steps : - uses : actions/checkout@v4 - name : Setup application run : | composer install php artisan key:generate php artisan migrate --force - name : Start web server run : php artisan serve & - name : Wait for server run : npx wait-on http://localhost:8000 - name : Run Playwright tests run : | cd tests/playwright-runner npm install npx playwright test - name : Upload test reports uses : actions/upload-artifact@v3 if : always() with : name : playwright-report path : tests/playwright-runner/playwright-report/ Test Organization \u00b6 Recommended Directory Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 tests/playwright-runner/ \u251c\u2500\u2500 package.json \u251c\u2500\u2500 playwright.config.ts \u251c\u2500\u2500 fixtures/ # Test data and utilities \u2502 \u251c\u2500\u2500 auth.ts # Authentication helpers \u2502 \u251c\u2500\u2500 database.ts # Database utilities \u2502 \u2514\u2500\u2500 api.ts # API helpers \u251c\u2500\u2500 tests/ \u2502 \u251c\u2500\u2500 auth/ # Authentication tests \u2502 \u2502 \u251c\u2500\u2500 login.spec.ts \u2502 \u2502 \u2514\u2500\u2500 registration.spec.ts \u2502 \u251c\u2500\u2500 api/ # API tests \u2502 \u2502 \u251c\u2500\u2500 users.spec.ts \u2502 \u2502 \u2514\u2500\u2500 orders.spec.ts \u2502 \u251c\u2500\u2500 e2e/ # End-to-end workflows \u2502 \u2502 \u251c\u2500\u2500 checkout.spec.ts \u2502 \u2502 \u2514\u2500\u2500 user-journey.spec.ts \u2502 \u2514\u2500\u2500 visual/ # Visual regression tests \u2502 \u251c\u2500\u2500 homepage.spec.ts \u2502 \u2514\u2500\u2500 components.spec.ts \u251c\u2500\u2500 test-results/ # Generated test results \u251c\u2500\u2500 playwright-report/ # HTML reports \u2514\u2500\u2500 screenshots/ # Visual regression baselines Test Categorization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 // Use test tags for organization test . describe ( 'User Management @smoke' , () => { // Smoke tests - critical functionality }); test . describe ( 'Advanced Features @integration' , () => { // Integration tests - complex workflows }); test . describe ( 'Visual Regression @visual' , () => { // Visual tests - UI consistency }); Running Categorized Tests \u00b6 1 2 3 4 5 6 7 8 # Run smoke tests only npx playwright test --grep \"@smoke\" # Run all except visual tests npx playwright test --grep-invert \"@visual\" # Run specific category npx playwright test tests/auth/ Debugging and Development \u00b6 Debug Mode \u00b6 1 2 3 4 5 6 7 8 # Debug specific test npx playwright test --debug tests/example.spec.ts # Debug with headed browser npx playwright test --headed --slowMo = 1000 # Debug in specific browser npx playwright test --project = chromium --debug Test Inspector \u00b6 1 2 3 4 5 6 // Add breakpoint in test test ( 'debug example' , async ({ page }) => { await page . goto ( '/' ); await page . pause (); // Opens Playwright Inspector await page . click ( 'button' ); }); Trace Viewer \u00b6 1 2 3 4 5 # Generate traces npx playwright test --trace = on # View traces npx playwright show-trace test-results/trace.zip Console and Network Monitoring \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 test ( 'monitor network' , async ({ page }) => { // Listen to console logs page . on ( 'console' , msg => console . log ( 'PAGE LOG:' , msg . text ())); // Monitor network requests page . on ( 'request' , request => { console . log ( 'REQUEST:' , request . url ()); }); page . on ( 'response' , response => { console . log ( 'RESPONSE:' , response . url (), response . status ()); }); await page . goto ( '/' ); }); Advanced Features \u00b6 Custom Fixtures \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // fixtures/auth.ts import { test as base } from '@playwright/test' ; type AuthFixtures = { authenticatedPage : Page ; }; export const test = base . extend < AuthFixtures > ({ authenticatedPage : async ({ page }, use ) => { // Login before each test await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , 'test@example.com' ); await page . fill ( '[name=\"password\"]' , 'password' ); await page . click ( 'button[type=\"submit\"]' ); await page . waitForURL ( '/dashboard' ); await use ( page ); }, }); // Usage in tests test ( 'authenticated user can access profile' , async ({ authenticatedPage }) => { await authenticatedPage . goto ( '/profile' ); await expect ( authenticatedPage ). toHaveURL ( '/profile' ); }); Page Object Model \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // pages/LoginPage.ts export class LoginPage { constructor ( private page : Page ) {} async goto () { await this . page . goto ( '/login' ); } async login ( email : string , password : string ) { await this . page . fill ( '[name=\"email\"]' , email ); await this . page . fill ( '[name=\"password\"]' , password ); await this . page . click ( 'button[type=\"submit\"]' ); } async getErrorMessage () { return await this . page . locator ( '.error-message' ). textContent (); } } // Usage in tests test ( 'login flow' , async ({ page }) => { const loginPage = new LoginPage ( page ); await loginPage . goto (); await loginPage . login ( 'invalid@email.com' , 'wrongpassword' ); const error = await loginPage . getErrorMessage (); expect ( error ). toContain ( 'Invalid credentials' ); }); Performance Testing \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 test ( 'performance metrics' , async ({ page }) => { await page . goto ( '/' ); // Wait for page to load completely await page . waitForLoadState ( 'networkidle' ); // Get performance metrics const performanceEntries = await page . evaluate (() => { return JSON . stringify ( performance . getEntriesByType ( 'navigation' )); }); const navigation = JSON . parse ( performanceEntries )[ 0 ]; const loadTime = navigation . loadEventEnd - navigation . fetchStart ; expect ( loadTime ). toBeLessThan ( 3000 ); // 3 second load time }); Troubleshooting \u00b6 Common Issues \u00b6 Browser launch failures 1 2 3 4 5 # Check browser installation npx playwright install --with-deps # Debug browser launch DEBUG = pw:browser npx playwright test Element not found errors 1 2 3 4 5 6 7 8 // Use proper waiting strategies await page . waitForSelector ( '[data-testid=\"submit-button\"]' ); await page . waitForLoadState ( 'networkidle' ); // Use more resilient selectors await page . click ( '[data-testid=\"submit\"]' ); // Better await page . click ( 'button:has-text(\"Submit\")' ); // Good await page . click ( 'button' ); // Fragile Flaky tests 1 2 3 4 5 6 7 // Add proper waits await page . waitForURL ( '/dashboard' ); await page . waitForSelector ( '.loading' , { state : 'detached' }); // Use assertions with auto-waiting await expect ( page . locator ( '.message' )). toBeVisible (); await expect ( page ). toHaveURL ( /dashboard/ ); Performance issues 1 2 3 4 5 # Run tests in parallel with limited workers npx playwright test --workers = 2 # Run specific browser only npx playwright test --project = chromium Related Documentation \u00b6 Playwright Runner Image - Container environment details Test Execution - Advanced execution strategies Architecture Overview - Testing in our infrastructure CI/CD Pipeline - Automated test execution Assumption : Tests primarily target web applications built with standard technologies (HTML, CSS, JavaScript, PHP). Complex SPA frameworks may require additional configuration and custom waiting strategies. Validation needed: Confirm application architecture and testing requirements with development teams. Maintainer : WebGrip Ops Team Configuration : tests/playwright-runner/playwright.config.ts Container : webgrip/playwright-runner","title":"Playwright Setup"},{"location":"testing/playwright-setup/#playwright-setup","text":"Comprehensive guide to setting up and using Playwright for end-to-end testing in WebGrip's infrastructure.","title":"Playwright Setup"},{"location":"testing/playwright-setup/#overview","text":"Our Playwright testing infrastructure provides: \u2705 Multi-browser testing across Chromium, Firefox, and WebKit \u2705 Containerized execution with consistent environments \u2705 PHP application support for full-stack testing \u2705 CI/CD integration with automated test execution \u2705 Visual regression testing capabilities \u2705 Parallel test execution for faster feedback","title":"Overview"},{"location":"testing/playwright-setup/#architecture","text":"","title":"Architecture"},{"location":"testing/playwright-setup/#testing-environment-stack","text":"flowchart TD subgraph \"Host System\" REPO[Repository Code] CONFIG[Test Configuration] end subgraph \"Playwright Container\" PLAYWRIGHT[Playwright Test Runner] BROWSERS[Browser Engines] PHP[PHP Runtime] NODE[Node.js Runtime] end subgraph \"Test Targets\" LOCAL_APP[Local Application] STAGING[Staging Environment] API[API Endpoints] end subgraph \"Test Outputs\" REPORTS[HTML Reports] SCREENSHOTS[Screenshots] VIDEOS[Test Videos] TRACES[Execution Traces] end REPO --> PLAYWRIGHT CONFIG --> PLAYWRIGHT PLAYWRIGHT --> BROWSERS BROWSERS --> LOCAL_APP BROWSERS --> STAGING BROWSERS --> API PLAYWRIGHT --> REPORTS PLAYWRIGHT --> SCREENSHOTS PLAYWRIGHT --> VIDEOS PLAYWRIGHT --> TRACES","title":"Testing Environment Stack"},{"location":"testing/playwright-setup/#browser-testing-matrix","text":"flowchart LR subgraph \"Test Cases\" TESTS[Test Specifications] end subgraph \"Browser Matrix\" CHROMIUM[Chromium<br/>Desktop Chrome] FIREFOX[Firefox<br/>Desktop Firefox] WEBKIT[WebKit<br/>Desktop Safari] end subgraph \"Device Matrix\" DESKTOP[Desktop Viewports] MOBILE[Mobile Viewports] TABLET[Tablet Viewports] end TESTS --> CHROMIUM TESTS --> FIREFOX TESTS --> WEBKIT CHROMIUM --> DESKTOP FIREFOX --> DESKTOP WEBKIT --> DESKTOP CHROMIUM --> MOBILE WEBKIT --> MOBILE","title":"Browser Testing Matrix"},{"location":"testing/playwright-setup/#configuration","text":"","title":"Configuration"},{"location":"testing/playwright-setup/#current-configuration","text":"Our Playwright setup is located in tests/playwright-runner/ with the following structure: 1 2 3 4 5 tests/playwright-runner/ \u251c\u2500\u2500 package.json # Dependencies and scripts \u251c\u2500\u2500 playwright.config.ts # Main configuration \u2514\u2500\u2500 tests/ \u2514\u2500\u2500 google.spec.ts # Example test","title":"Current Configuration"},{"location":"testing/playwright-setup/#playwright-configuration-file","text":"Current configuration ( playwright.config.ts ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export default defineConfig ({ testDir : './tests' , fullyParallel : true , forbidOnly : !! process . env . CI , retries : process.env.CI ? 2 : 0 , workers : process.env.CI ? 1 : undefined , reporter : 'line' , use : { trace : 'on-first-retry' , }, projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, // Additional browsers commented out for now ], });","title":"Playwright Configuration File"},{"location":"testing/playwright-setup/#recommended-production-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // playwright.config.ts - Enhanced configuration import { defineConfig , devices } from '@playwright/test' ; export default defineConfig ({ testDir : './tests' , // Execution settings fullyParallel : true , forbidOnly : !! process . env . CI , retries : process.env.CI ? 2 : 0 , workers : process.env.CI ? 2 : undefined , timeout : 30000 , // Reporting reporter : [ [ 'html' , { outputFolder : 'playwright-report' }], [ 'json' , { outputFile : 'test-results.json' }], [ 'junit' , { outputFile : 'test-results.xml' }], [ 'line' ] ], // Global test settings use : { baseURL : process.env.BASE_URL || 'http://localhost:8000' , trace : 'on-first-retry' , screenshot : 'only-on-failure' , video : 'retain-on-failure' , actionTimeout : 10000 , navigationTimeout : 15000 , }, // Browser projects projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, { name : 'mobile-chrome' , use : { ... devices [ 'Pixel 5' ] }, }, { name : 'mobile-safari' , use : { ... devices [ 'iPhone 12' ] }, }, ], // Web server for testing webServer : { command : 'php artisan serve' , url : 'http://localhost:8000' , reuseExistingServer : ! process . env . CI , timeout : 120000 , }, });","title":"Recommended Production Configuration"},{"location":"testing/playwright-setup/#installation-and-setup","text":"","title":"Installation and Setup"},{"location":"testing/playwright-setup/#local-development-setup","text":"1 2 3 4 5 6 7 8 9 10 11 # Navigate to test directory cd tests/playwright-runner # Install dependencies npm install # Install browser binaries npx playwright install # Install system dependencies (if needed) npx playwright install-deps","title":"Local Development Setup"},{"location":"testing/playwright-setup/#docker-based-setup-recommended","text":"1 2 3 4 5 6 7 8 9 10 11 # Use our Playwright Runner image docker run -it --rm \\ -v $( pwd ) :/app \\ -w /app \\ webgrip/playwright-runner:latest \\ bash # Inside container - dependencies already installed cd tests/playwright-runner npm install # Install project-specific dependencies npx playwright test","title":"Docker-based Setup (Recommended)"},{"location":"testing/playwright-setup/#project-integration","text":"1 2 3 4 5 6 7 8 # Add Playwright to existing project cd your-project npm init -y npm install -D @playwright/test npx playwright install # Generate initial configuration npx playwright init","title":"Project Integration"},{"location":"testing/playwright-setup/#writing-tests","text":"","title":"Writing Tests"},{"location":"testing/playwright-setup/#basic-test-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // tests/example.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Application Tests' , () => { test . beforeEach ( async ({ page }) => { // Setup before each test await page . goto ( '/' ); }); test ( 'should load homepage' , async ({ page }) => { await expect ( page ). toHaveTitle ( /My Application/ ); await expect ( page . locator ( 'h1' )). toContainText ( 'Welcome' ); }); test ( 'should navigate to about page' , async ({ page }) => { await page . click ( 'a[href=\"/about\"]' ); await expect ( page ). toHaveURL ( /.*about/ ); await expect ( page . locator ( 'h1' )). toContainText ( 'About' ); }); });","title":"Basic Test Structure"},{"location":"testing/playwright-setup/#api-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // tests/api.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'API Tests' , () => { test ( 'should fetch user data' , async ({ request }) => { const response = await request . get ( '/api/users' ); expect ( response . status ()). toBe ( 200 ); const users = await response . json (); expect ( users ). toHaveLength ( 3 ); expect ( users [ 0 ]). toHaveProperty ( 'name' ); expect ( users [ 0 ]). toHaveProperty ( 'email' ); }); test ( 'should create new user' , async ({ request }) => { const response = await request . post ( '/api/users' , { data : { name : 'Test User' , email : 'test@example.com' } }); expect ( response . status ()). toBe ( 201 ); const user = await response . json (); expect ( user . name ). toBe ( 'Test User' ); }); });","title":"API Testing"},{"location":"testing/playwright-setup/#visual-regression-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/visual.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Visual Regression' , () => { test ( 'should match homepage screenshot' , async ({ page }) => { await page . goto ( '/' ); // Wait for content to load await page . waitForLoadState ( 'networkidle' ); // Take screenshot and compare await expect ( page ). toHaveScreenshot ( 'homepage.png' ); }); test ( 'should match mobile view' , async ({ page }) => { await page . setViewportSize ({ width : 375 , height : 667 }); await page . goto ( '/' ); await expect ( page ). toHaveScreenshot ( 'homepage-mobile.png' ); }); });","title":"Visual Regression Testing"},{"location":"testing/playwright-setup/#php-application-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // tests/php-app.spec.ts import { test , expect } from '@playwright/test' ; import { execSync } from 'child_process' ; test . describe ( 'PHP Application' , () => { test . beforeEach ( async () => { // Reset database state execSync ( 'php artisan migrate:fresh --seed' , { stdio : 'inherit' }); }); test ( 'should register new user' , async ({ page }) => { await page . goto ( '/register' ); await page . fill ( '[name=\"name\"]' , 'John Doe' ); await page . fill ( '[name=\"email\"]' , 'john@example.com' ); await page . fill ( '[name=\"password\"]' , 'password123' ); await page . fill ( '[name=\"password_confirmation\"]' , 'password123' ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); await expect ( page . locator ( '.welcome' )). toContainText ( 'Welcome, John Doe' ); }); test ( 'should handle authentication' , async ({ page }) => { // Seed user first execSync ( 'php artisan tinker --execute=\"User::create([\\'name\\' => \\'Test\\', \\'email\\' => \\'test@test.com\\', \\'password\\' => bcrypt(\\'password\\')])\"' ); await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , 'test@test.com' ); await page . fill ( '[name=\"password\"]' , 'password' ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); }); });","title":"PHP Application Testing"},{"location":"testing/playwright-setup/#running-tests","text":"","title":"Running Tests"},{"location":"testing/playwright-setup/#basic-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Run all tests npx playwright test # Run specific test file npx playwright test tests/example.spec.ts # Run tests in specific browser npx playwright test --project = chromium # Run tests in headed mode (visible browser) npx playwright test --headed # Run tests with UI mode npx playwright test --ui","title":"Basic Execution"},{"location":"testing/playwright-setup/#docker-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Run tests in Playwright container docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test # Run with custom configuration docker run --rm \\ -v $( pwd ) :/app \\ -w /app \\ -e BASE_URL = http://staging.example.com \\ webgrip/playwright-runner:latest \\ npx playwright test --config = tests/playwright-runner/playwright.config.ts","title":"Docker Execution"},{"location":"testing/playwright-setup/#cicd-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # .github/workflows/e2e-tests.yml name : E2E Tests on : [ push , pull_request ] jobs : test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest services : database : image : postgres:15 env : POSTGRES_PASSWORD : postgres options : >- --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5 steps : - uses : actions/checkout@v4 - name : Setup application run : | composer install php artisan key:generate php artisan migrate --force - name : Start web server run : php artisan serve & - name : Wait for server run : npx wait-on http://localhost:8000 - name : Run Playwright tests run : | cd tests/playwright-runner npm install npx playwright test - name : Upload test reports uses : actions/upload-artifact@v3 if : always() with : name : playwright-report path : tests/playwright-runner/playwright-report/","title":"CI/CD Integration"},{"location":"testing/playwright-setup/#test-organization","text":"","title":"Test Organization"},{"location":"testing/playwright-setup/#recommended-directory-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 tests/playwright-runner/ \u251c\u2500\u2500 package.json \u251c\u2500\u2500 playwright.config.ts \u251c\u2500\u2500 fixtures/ # Test data and utilities \u2502 \u251c\u2500\u2500 auth.ts # Authentication helpers \u2502 \u251c\u2500\u2500 database.ts # Database utilities \u2502 \u2514\u2500\u2500 api.ts # API helpers \u251c\u2500\u2500 tests/ \u2502 \u251c\u2500\u2500 auth/ # Authentication tests \u2502 \u2502 \u251c\u2500\u2500 login.spec.ts \u2502 \u2502 \u2514\u2500\u2500 registration.spec.ts \u2502 \u251c\u2500\u2500 api/ # API tests \u2502 \u2502 \u251c\u2500\u2500 users.spec.ts \u2502 \u2502 \u2514\u2500\u2500 orders.spec.ts \u2502 \u251c\u2500\u2500 e2e/ # End-to-end workflows \u2502 \u2502 \u251c\u2500\u2500 checkout.spec.ts \u2502 \u2502 \u2514\u2500\u2500 user-journey.spec.ts \u2502 \u2514\u2500\u2500 visual/ # Visual regression tests \u2502 \u251c\u2500\u2500 homepage.spec.ts \u2502 \u2514\u2500\u2500 components.spec.ts \u251c\u2500\u2500 test-results/ # Generated test results \u251c\u2500\u2500 playwright-report/ # HTML reports \u2514\u2500\u2500 screenshots/ # Visual regression baselines","title":"Recommended Directory Structure"},{"location":"testing/playwright-setup/#test-categorization","text":"1 2 3 4 5 6 7 8 9 10 11 12 // Use test tags for organization test . describe ( 'User Management @smoke' , () => { // Smoke tests - critical functionality }); test . describe ( 'Advanced Features @integration' , () => { // Integration tests - complex workflows }); test . describe ( 'Visual Regression @visual' , () => { // Visual tests - UI consistency });","title":"Test Categorization"},{"location":"testing/playwright-setup/#running-categorized-tests","text":"1 2 3 4 5 6 7 8 # Run smoke tests only npx playwright test --grep \"@smoke\" # Run all except visual tests npx playwright test --grep-invert \"@visual\" # Run specific category npx playwright test tests/auth/","title":"Running Categorized Tests"},{"location":"testing/playwright-setup/#debugging-and-development","text":"","title":"Debugging and Development"},{"location":"testing/playwright-setup/#debug-mode","text":"1 2 3 4 5 6 7 8 # Debug specific test npx playwright test --debug tests/example.spec.ts # Debug with headed browser npx playwright test --headed --slowMo = 1000 # Debug in specific browser npx playwright test --project = chromium --debug","title":"Debug Mode"},{"location":"testing/playwright-setup/#test-inspector","text":"1 2 3 4 5 6 // Add breakpoint in test test ( 'debug example' , async ({ page }) => { await page . goto ( '/' ); await page . pause (); // Opens Playwright Inspector await page . click ( 'button' ); });","title":"Test Inspector"},{"location":"testing/playwright-setup/#trace-viewer","text":"1 2 3 4 5 # Generate traces npx playwright test --trace = on # View traces npx playwright show-trace test-results/trace.zip","title":"Trace Viewer"},{"location":"testing/playwright-setup/#console-and-network-monitoring","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 test ( 'monitor network' , async ({ page }) => { // Listen to console logs page . on ( 'console' , msg => console . log ( 'PAGE LOG:' , msg . text ())); // Monitor network requests page . on ( 'request' , request => { console . log ( 'REQUEST:' , request . url ()); }); page . on ( 'response' , response => { console . log ( 'RESPONSE:' , response . url (), response . status ()); }); await page . goto ( '/' ); });","title":"Console and Network Monitoring"},{"location":"testing/playwright-setup/#advanced-features","text":"","title":"Advanced Features"},{"location":"testing/playwright-setup/#custom-fixtures","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // fixtures/auth.ts import { test as base } from '@playwright/test' ; type AuthFixtures = { authenticatedPage : Page ; }; export const test = base . extend < AuthFixtures > ({ authenticatedPage : async ({ page }, use ) => { // Login before each test await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , 'test@example.com' ); await page . fill ( '[name=\"password\"]' , 'password' ); await page . click ( 'button[type=\"submit\"]' ); await page . waitForURL ( '/dashboard' ); await use ( page ); }, }); // Usage in tests test ( 'authenticated user can access profile' , async ({ authenticatedPage }) => { await authenticatedPage . goto ( '/profile' ); await expect ( authenticatedPage ). toHaveURL ( '/profile' ); });","title":"Custom Fixtures"},{"location":"testing/playwright-setup/#page-object-model","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // pages/LoginPage.ts export class LoginPage { constructor ( private page : Page ) {} async goto () { await this . page . goto ( '/login' ); } async login ( email : string , password : string ) { await this . page . fill ( '[name=\"email\"]' , email ); await this . page . fill ( '[name=\"password\"]' , password ); await this . page . click ( 'button[type=\"submit\"]' ); } async getErrorMessage () { return await this . page . locator ( '.error-message' ). textContent (); } } // Usage in tests test ( 'login flow' , async ({ page }) => { const loginPage = new LoginPage ( page ); await loginPage . goto (); await loginPage . login ( 'invalid@email.com' , 'wrongpassword' ); const error = await loginPage . getErrorMessage (); expect ( error ). toContain ( 'Invalid credentials' ); });","title":"Page Object Model"},{"location":"testing/playwright-setup/#performance-testing","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 test ( 'performance metrics' , async ({ page }) => { await page . goto ( '/' ); // Wait for page to load completely await page . waitForLoadState ( 'networkidle' ); // Get performance metrics const performanceEntries = await page . evaluate (() => { return JSON . stringify ( performance . getEntriesByType ( 'navigation' )); }); const navigation = JSON . parse ( performanceEntries )[ 0 ]; const loadTime = navigation . loadEventEnd - navigation . fetchStart ; expect ( loadTime ). toBeLessThan ( 3000 ); // 3 second load time });","title":"Performance Testing"},{"location":"testing/playwright-setup/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"testing/playwright-setup/#common-issues","text":"Browser launch failures 1 2 3 4 5 # Check browser installation npx playwright install --with-deps # Debug browser launch DEBUG = pw:browser npx playwright test Element not found errors 1 2 3 4 5 6 7 8 // Use proper waiting strategies await page . waitForSelector ( '[data-testid=\"submit-button\"]' ); await page . waitForLoadState ( 'networkidle' ); // Use more resilient selectors await page . click ( '[data-testid=\"submit\"]' ); // Better await page . click ( 'button:has-text(\"Submit\")' ); // Good await page . click ( 'button' ); // Fragile Flaky tests 1 2 3 4 5 6 7 // Add proper waits await page . waitForURL ( '/dashboard' ); await page . waitForSelector ( '.loading' , { state : 'detached' }); // Use assertions with auto-waiting await expect ( page . locator ( '.message' )). toBeVisible (); await expect ( page ). toHaveURL ( /dashboard/ ); Performance issues 1 2 3 4 5 # Run tests in parallel with limited workers npx playwright test --workers = 2 # Run specific browser only npx playwright test --project = chromium","title":"Common Issues"},{"location":"testing/playwright-setup/#related-documentation","text":"Playwright Runner Image - Container environment details Test Execution - Advanced execution strategies Architecture Overview - Testing in our infrastructure CI/CD Pipeline - Automated test execution Assumption : Tests primarily target web applications built with standard technologies (HTML, CSS, JavaScript, PHP). Complex SPA frameworks may require additional configuration and custom waiting strategies. Validation needed: Confirm application architecture and testing requirements with development teams. Maintainer : WebGrip Ops Team Configuration : tests/playwright-runner/playwright.config.ts Container : webgrip/playwright-runner","title":"Related Documentation"},{"location":"testing/test-execution/","text":"Test Execution \u00b6 Advanced strategies and patterns for executing Playwright tests across different environments and scenarios. Overview \u00b6 Test execution encompasses: \u2705 Environment-specific execution across development, staging, and production \u2705 Parallel and distributed testing for optimal performance \u2705 Cross-browser and cross-device testing for comprehensive coverage \u2705 CI/CD integration patterns for automated testing workflows \u2705 Test result management and reporting strategies Execution Strategies \u00b6 Local Development Execution \u00b6 flowchart TD DEV[Developer Machine] --> LOCAL_ENV[Local Environment] LOCAL_ENV --> QUICK[Quick Feedback Loop] QUICK --> INDIVIDUAL[Individual Test Files] QUICK --> BROWSER[Single Browser] QUICK --> DEBUG[Debug Mode] subgraph \"Development Workflow\" WRITE[Write Test] --> RUN[Run Test] RUN --> DEBUG_ISSUE[Debug Issues] DEBUG_ISSUE --> FIX[Fix Code] FIX --> WRITE end DEBUG --> WRITE CI/CD Execution Pipeline \u00b6 flowchart LR subgraph \"Commit Stage\" COMMIT[Code Commit] --> SMOKE[Smoke Tests] SMOKE --> FAST_FEEDBACK[< 5 minutes] end subgraph \"Integration Stage\" FAST_FEEDBACK --> FULL_SUITE[Full Test Suite] FULL_SUITE --> PARALLEL[Parallel Execution] PARALLEL --> MULTI_BROWSER[Multi-Browser] end subgraph \"Deployment Stage\" MULTI_BROWSER --> E2E[E2E Tests] E2E --> ACCEPTANCE[Acceptance Tests] ACCEPTANCE --> DEPLOY[Deploy] end Production Monitoring \u00b6 flowchart TD PROD[Production Environment] --> SYNTHETIC[Synthetic Tests] SYNTHETIC --> CRITICAL_PATHS[Critical User Paths] CRITICAL_PATHS --> ALERTS[Failure Alerts] ALERTS --> INCIDENT[Incident Response] subgraph \"Monitoring Schedule\" HOURLY[Hourly Checks] DAILY[Daily Full Suite] WEEKLY[Weekly Regression] end SYNTHETIC --> HOURLY SYNTHETIC --> DAILY SYNTHETIC --> WEEKLY Execution Environments \u00b6 Local Development \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Quick development cycle cd tests/playwright-runner # Run single test file npx playwright test tests/auth/login.spec.ts # Run with headed browser for debugging npx playwright test tests/auth/login.spec.ts --headed # Run with debug mode npx playwright test tests/auth/login.spec.ts --debug # Watch mode for continuous testing npx playwright test --watch Docker-based Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Standard container execution docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test # With environment variables docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ -e BASE_URL = http://staging.example.com \\ -e TEST_USER_EMAIL = test@example.com \\ -e TEST_USER_PASSWORD = password123 \\ webgrip/playwright-runner:latest \\ npx playwright test --project = chromium # With volume for reports docker run --rm \\ -v $( pwd ) :/app \\ -v playwright-reports:/app/tests/playwright-runner/playwright-report \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test --reporter = html GitHub Actions Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # .github/workflows/playwright-tests.yml name : Playwright Tests on : push : branches : [ main , develop ] pull_request : branches : [ main ] jobs : test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest strategy : fail-fast : false matrix : browser : [ chromium , firefox , webkit ] shard : [ 1 , 2 , 3 , 4 ] steps : - uses : actions/checkout@v4 - name : Setup application run : | composer install --no-dev --optimize-autoloader php artisan config:cache php artisan route:cache - name : Setup database env : DB_CONNECTION : sqlite DB_DATABASE : \":memory:\" run : | php artisan migrate --force php artisan db:seed --force - name : Start application server run : | php artisan serve --port=8000 & sleep 10 curl http://localhost:8000/health || exit 1 - name : Run Playwright tests env : BASE_URL : http://localhost:8000 run : | cd tests/playwright-runner npm ci npx playwright test \\ --project=${{ matrix.browser }} \\ --shard=${{ matrix.shard }}/4 \\ --reporter=blob - name : Upload test results uses : actions/upload-artifact@v3 if : always() with : name : playwright-results-${{ matrix.browser }}-${{ matrix.shard }} path : tests/playwright-runner/test-results/ merge-reports : if : always() needs : test runs-on : ubuntu-latest container : webgrip/playwright-runner:latest steps : - uses : actions/checkout@v4 - name : Download all test results uses : actions/download-artifact@v3 with : pattern : playwright-results-* merge-multiple : true path : test-results/ - name : Merge test reports run : | cd tests/playwright-runner npx playwright merge-reports --reporter=html test-results/ - name : Upload merged report uses : actions/upload-artifact@v3 with : name : playwright-report path : tests/playwright-runner/playwright-report/ Parallel Execution \u00b6 Browser Parallelization \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // playwright.config.ts - Browser parallelization export default defineConfig ({ projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, ], }); 1 2 3 4 5 6 7 8 # Run all browsers in parallel npx playwright test # Run specific browser npx playwright test --project = chromium # Run multiple specific browsers npx playwright test --project = chromium --project = firefox Test Sharding \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Split tests across multiple runners npx playwright test --shard = 1 /4 # Run 1st quarter npx playwright test --shard = 2 /4 # Run 2nd quarter npx playwright test --shard = 3 /4 # Run 3rd quarter npx playwright test --shard = 4 /4 # Run 4th quarter # In CI with matrix strategy: matrix: shard: [ 1 , 2 , 3 , 4 ] steps: - name: Run tests ( Shard ${ { matrix.shard } }) run: npx playwright test --shard = ${ { matrix.shard } } /4 Worker Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // playwright.config.ts - Worker optimization export default defineConfig ({ // Local development - use all cores workers : process.env.CI ? 2 : undefined , // Or specify exact number workers : 4 , // Full parallelization fullyParallel : true , // Global timeout globalTimeout : 60 * 60 * 1000 , // 1 hour // Per-test timeout timeout : 30 * 1000 , // 30 seconds }); Test Selection and Filtering \u00b6 Tag-based Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // tests/auth.spec.ts test . describe ( 'Authentication @smoke @auth' , () => { test ( 'should login successfully @critical' , async ({ page }) => { // Test implementation }); test ( 'should handle invalid credentials @error-handling' , async ({ page }) => { // Test implementation }); }); test . describe ( 'User Management @integration @users' , () => { test ( 'should create new user @crud' , async ({ page }) => { // Test implementation }); }); 1 2 3 4 5 6 7 8 9 # Run tests by tags npx playwright test --grep \"@smoke\" # Smoke tests only npx playwright test --grep \"@critical\" # Critical tests only npx playwright test --grep \"@smoke|@critical\" # Smoke OR critical npx playwright test --grep-invert \"@slow\" # Everything except slow tests # Run by test suite npx playwright test --grep \"@auth\" # All auth tests npx playwright test tests/auth/ # All files in auth directory Environment-specific Selection \u00b6 1 2 3 4 5 6 7 8 # Development environment - fast feedback npx playwright test --grep \"@smoke\" --project = chromium # Staging environment - comprehensive testing npx playwright test --grep \"@smoke|@integration\" # Production monitoring - critical paths only npx playwright test --grep \"@critical|@monitoring\" File-based Selection \u00b6 1 2 3 4 5 6 7 8 9 # Run specific test files npx playwright test tests/auth/login.spec.ts npx playwright test tests/auth/ # Run multiple specific files npx playwright test tests/auth/login.spec.ts tests/users/profile.spec.ts # Run tests matching pattern npx playwright test \"**/*auth*.spec.ts\" Cross-Environment Testing \u00b6 Environment Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // config/environments.ts export const environments = { development : { baseURL : 'http://localhost:8000' , timeout : 10000 , retries : 0 , }, staging : { baseURL : 'https://staging.webgrip.nl' , timeout : 30000 , retries : 2 , }, production : { baseURL : 'https://app.webgrip.nl' , timeout : 15000 , retries : 1 , }, }; // playwright.config.ts const env = process . env . TEST_ENV || 'development' ; const config = environments [ env ]; export default defineConfig ({ use : { baseURL : config.baseURL , actionTimeout : config.timeout , }, retries : config.retries , }); Environment-specific Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Test against different environments TEST_ENV = development npx playwright test TEST_ENV = staging npx playwright test --grep \"@smoke\" TEST_ENV = production npx playwright test --grep \"@monitoring\" # With Docker docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ -e TEST_ENV = staging \\ -e BASE_URL = https://staging.webgrip.nl \\ webgrip/playwright-runner:latest \\ npx playwright test --grep \"@smoke\" Cross-browser Testing Matrix \u00b6 1 2 3 4 5 6 7 8 9 10 11 # Complete cross-browser testing strategy : matrix : browser : [ chromium , firefox , webkit ] environment : [ staging , production ] steps : - name : Test ${{ matrix.browser }} on ${{ matrix.environment }} env : TEST_ENV : ${{ matrix.environment }} run : npx playwright test --project=${{ matrix.browser }} Performance Optimization \u00b6 Test Execution Performance \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // playwright.config.ts - Performance optimizations export default defineConfig ({ // Faster test execution fullyParallel : true , workers : process.env.CI ? 4 : undefined , // Reasonable timeouts timeout : 30000 , actionTimeout : 10000 , navigationTimeout : 15000 , // Optimize for CI use : { // Disable animations for faster execution reducedMotion : 'reduce' , // Optimize screenshots screenshot : 'only-on-failure' , // Minimal trace collection trace : 'retain-on-failure' , // Disable video in CI video : process.env.CI ? 'off' : 'retain-on-failure' , }, // Global setup for shared state globalSetup : require.resolve ( './global-setup' ), globalTeardown : require.resolve ( './global-teardown' ), }); Resource Management \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // global-setup.ts - Shared setup import { chromium , FullConfig } from '@playwright/test' ; async function globalSetup ( config : FullConfig ) { // Setup shared database state await setupTestDatabase (); // Warm up application const browser = await chromium . launch (); const page = await browser . newPage (); await page . goto ( config . projects [ 0 ]. use . baseURL ); await browser . close (); // Cache authentication state await setupAuthenticationState (); } export default globalSetup ; Caching Strategies \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // fixtures/auth-cache.ts import { test as base } from '@playwright/test' ; const STORAGE_STATE = 'auth-state.json' ; export const test = base . extend ({ // Reuse authentication state storageState : STORAGE_STATE , authenticatedPage : async ({ page }, use ) => { // Use cached authentication if available await use ( page ); }, }); Test Result Management \u00b6 Report Generation \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // playwright.config.ts - Multiple reporters export default defineConfig ({ reporter : [ // HTML report for local development [ 'html' , { outputFolder : 'playwright-report' , open : process.env.CI ? 'never' : 'on-failure' }], // JSON for CI integration [ 'json' , { outputFile : 'test-results.json' }], // JUnit for test management systems [ 'junit' , { outputFile : 'test-results.xml' }], // Line reporter for CI logs [ 'line' ], // Custom reporter for notifications [ './reporters/slack-reporter.js' ], ], }); Artifact Management \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # Generate and collect artifacts npx playwright test \\ --reporter = html \\ --output-dir = test-results \\ --screenshot = on \\ --video = on \\ --trace = on # Archive results tar -czf \"test-results- $( date +%Y%m%d-%H%M%S ) .tar.gz\" \\ test-results/ \\ playwright-report/ \\ test-results.json CI/CD Integration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Complete artifact handling - name : Run Playwright tests run : npx playwright test --reporter=blob - name : Generate HTML report if : always() run : npx playwright merge-reports --reporter=html blob-report/ - name : Upload test report uses : actions/upload-artifact@v3 if : always() with : name : playwright-report-${{ github.run_id }} path : | playwright-report/ test-results/ retention-days : 30 - name : Upload to test management if : always() run : | curl -X POST \\ -H \"Content-Type: application/json\" \\ -d @test-results.json \\ https://test-management.webgrip.nl/api/results Monitoring and Alerting \u00b6 Synthetic Monitoring \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // tests/monitoring/critical-paths.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Critical Path Monitoring @monitoring @critical' , () => { test ( 'user login flow' , async ({ page }) => { const startTime = Date . now (); await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , process . env . MONITOR_USER_EMAIL ! ); await page . fill ( '[name=\"password\"]' , process . env . MONITOR_USER_PASSWORD ! ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); const loadTime = Date . now () - startTime ; expect ( loadTime ). toBeLessThan ( 5000 ); // 5 second SLA }); test ( 'checkout process' , async ({ page }) => { // Simulate critical business process await page . goto ( '/products/1' ); await page . click ( 'button:has-text(\"Add to Cart\")' ); await page . goto ( '/checkout' ); // Verify checkout loads within SLA await expect ( page . locator ( 'h1' )). toContainText ( 'Checkout' ); }); }); Alert Configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # monitoring/run-synthetic-tests.sh # Run critical path tests npx playwright test --grep \"@monitoring\" --reporter = json > monitoring-results.json # Check for failures FAILURES = $( jq '.stats.failed' monitoring-results.json ) if [ \" $FAILURES \" -gt 0 ] ; then # Send alert to Slack curl -X POST -H 'Content-type: application/json' \\ --data '{\"text\":\"\ud83d\udea8 Synthetic monitoring tests failed: ' \" $FAILURES \" ' failures detected\"}' \\ $SLACK_WEBHOOK_URL # Page on-call team curl -X POST \\ -H \"Authorization: Token $PAGERDUTY_TOKEN \" \\ -H \"Content-Type: application/json\" \\ -d '{ \"incident\": { \"type\": \"incident\", \"title\": \"Synthetic Test Failures\", \"service\": {\"id\": \"' \" $PAGERDUTY_SERVICE_ID \" '\", \"type\": \"service_reference\"} } }' \\ https://api.pagerduty.com/incidents fi Performance Monitoring \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/performance/load-times.spec.ts test ( 'performance metrics' , async ({ page }) => { await page . goto ( '/' ); const metrics = await page . evaluate (() => { const perfData = performance . getEntriesByType ( 'navigation' )[ 0 ]; return { domContentLoaded : perfData.domContentLoadedEventEnd - perfData . fetchStart , loadComplete : perfData.loadEventEnd - perfData . fetchStart , firstPaint : performance.getEntriesByType ( 'paint' )[ 0 ] ? . startTime || 0 , }; }); // Assert performance SLAs expect ( metrics . domContentLoaded ). toBeLessThan ( 2000 ); expect ( metrics . loadComplete ). toBeLessThan ( 5000 ); expect ( metrics . firstPaint ). toBeLessThan ( 1500 ); // Log metrics for monitoring console . log ( 'Performance Metrics:' , JSON . stringify ( metrics )); }); Troubleshooting Test Execution \u00b6 Common Execution Issues \u00b6 Tests timing out 1 2 3 4 5 6 7 // Increase timeouts for specific tests test ( 'slow operation' , async ({ page }) => { test . setTimeout ( 60000 ); // 60 seconds for this test await page . goto ( '/slow-page' ); await page . waitForSelector ( '.slow-component' , { timeout : 30000 }); }); Flaky tests 1 2 3 4 5 6 7 8 9 10 11 12 13 // Add proper waits and retries test ( 'potentially flaky test' , async ({ page }) => { // Retry this test up to 3 times test . fixme (({ browserName }) => browserName === 'webkit' , 'Flaky on WebKit' ); await page . goto ( '/' ); // Wait for network to be idle await page . waitForLoadState ( 'networkidle' ); // Use auto-waiting assertions await expect ( page . locator ( '.dynamic-content' )). toBeVisible (); }); Resource exhaustion 1 2 3 4 5 6 7 8 9 10 11 12 13 # Reduce parallel workers npx playwright test --workers = 1 # Run tests sequentially npx playwright test --workers = 1 --fullyParallel = false # Increase system resources docker run --rm \\ --memory = 4g \\ --cpus = 2 \\ -v $( pwd ) :/app \\ webgrip/playwright-runner:latest \\ npx playwright test Debug Execution \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 # Debug with verbose output DEBUG = pw:* npx playwright test # Debug specific test npx playwright test --debug tests/auth/login.spec.ts # Debug in headed mode npx playwright test --headed --slowMo = 1000 # Generate trace for debugging npx playwright test --trace = on npx playwright show-trace test-results/example-test/trace.zip Related Documentation \u00b6 Playwright Setup - Initial configuration and test writing Playwright Runner Image - Container environment CI/CD Pipeline - Automated test execution Architecture Overview - Testing architecture Assumption : Test execution primarily occurs in containerized environments with reliable network connectivity. High-latency or unreliable network conditions may require additional timeout and retry configuration. Validation needed: Confirm network and infrastructure requirements for test execution environments. Maintainer : WebGrip Ops Team Configuration : tests/playwright-runner/playwright.config.ts Container : webgrip/playwright-runner","title":"Test Execution"},{"location":"testing/test-execution/#test-execution","text":"Advanced strategies and patterns for executing Playwright tests across different environments and scenarios.","title":"Test Execution"},{"location":"testing/test-execution/#overview","text":"Test execution encompasses: \u2705 Environment-specific execution across development, staging, and production \u2705 Parallel and distributed testing for optimal performance \u2705 Cross-browser and cross-device testing for comprehensive coverage \u2705 CI/CD integration patterns for automated testing workflows \u2705 Test result management and reporting strategies","title":"Overview"},{"location":"testing/test-execution/#execution-strategies","text":"","title":"Execution Strategies"},{"location":"testing/test-execution/#local-development-execution","text":"flowchart TD DEV[Developer Machine] --> LOCAL_ENV[Local Environment] LOCAL_ENV --> QUICK[Quick Feedback Loop] QUICK --> INDIVIDUAL[Individual Test Files] QUICK --> BROWSER[Single Browser] QUICK --> DEBUG[Debug Mode] subgraph \"Development Workflow\" WRITE[Write Test] --> RUN[Run Test] RUN --> DEBUG_ISSUE[Debug Issues] DEBUG_ISSUE --> FIX[Fix Code] FIX --> WRITE end DEBUG --> WRITE","title":"Local Development Execution"},{"location":"testing/test-execution/#cicd-execution-pipeline","text":"flowchart LR subgraph \"Commit Stage\" COMMIT[Code Commit] --> SMOKE[Smoke Tests] SMOKE --> FAST_FEEDBACK[< 5 minutes] end subgraph \"Integration Stage\" FAST_FEEDBACK --> FULL_SUITE[Full Test Suite] FULL_SUITE --> PARALLEL[Parallel Execution] PARALLEL --> MULTI_BROWSER[Multi-Browser] end subgraph \"Deployment Stage\" MULTI_BROWSER --> E2E[E2E Tests] E2E --> ACCEPTANCE[Acceptance Tests] ACCEPTANCE --> DEPLOY[Deploy] end","title":"CI/CD Execution Pipeline"},{"location":"testing/test-execution/#production-monitoring","text":"flowchart TD PROD[Production Environment] --> SYNTHETIC[Synthetic Tests] SYNTHETIC --> CRITICAL_PATHS[Critical User Paths] CRITICAL_PATHS --> ALERTS[Failure Alerts] ALERTS --> INCIDENT[Incident Response] subgraph \"Monitoring Schedule\" HOURLY[Hourly Checks] DAILY[Daily Full Suite] WEEKLY[Weekly Regression] end SYNTHETIC --> HOURLY SYNTHETIC --> DAILY SYNTHETIC --> WEEKLY","title":"Production Monitoring"},{"location":"testing/test-execution/#execution-environments","text":"","title":"Execution Environments"},{"location":"testing/test-execution/#local-development","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Quick development cycle cd tests/playwright-runner # Run single test file npx playwright test tests/auth/login.spec.ts # Run with headed browser for debugging npx playwright test tests/auth/login.spec.ts --headed # Run with debug mode npx playwright test tests/auth/login.spec.ts --debug # Watch mode for continuous testing npx playwright test --watch","title":"Local Development"},{"location":"testing/test-execution/#docker-based-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Standard container execution docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test # With environment variables docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ -e BASE_URL = http://staging.example.com \\ -e TEST_USER_EMAIL = test@example.com \\ -e TEST_USER_PASSWORD = password123 \\ webgrip/playwright-runner:latest \\ npx playwright test --project = chromium # With volume for reports docker run --rm \\ -v $( pwd ) :/app \\ -v playwright-reports:/app/tests/playwright-runner/playwright-report \\ -w /app/tests/playwright-runner \\ webgrip/playwright-runner:latest \\ npx playwright test --reporter = html","title":"Docker-based Execution"},{"location":"testing/test-execution/#github-actions-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # .github/workflows/playwright-tests.yml name : Playwright Tests on : push : branches : [ main , develop ] pull_request : branches : [ main ] jobs : test : runs-on : ubuntu-latest container : webgrip/playwright-runner:latest strategy : fail-fast : false matrix : browser : [ chromium , firefox , webkit ] shard : [ 1 , 2 , 3 , 4 ] steps : - uses : actions/checkout@v4 - name : Setup application run : | composer install --no-dev --optimize-autoloader php artisan config:cache php artisan route:cache - name : Setup database env : DB_CONNECTION : sqlite DB_DATABASE : \":memory:\" run : | php artisan migrate --force php artisan db:seed --force - name : Start application server run : | php artisan serve --port=8000 & sleep 10 curl http://localhost:8000/health || exit 1 - name : Run Playwright tests env : BASE_URL : http://localhost:8000 run : | cd tests/playwright-runner npm ci npx playwright test \\ --project=${{ matrix.browser }} \\ --shard=${{ matrix.shard }}/4 \\ --reporter=blob - name : Upload test results uses : actions/upload-artifact@v3 if : always() with : name : playwright-results-${{ matrix.browser }}-${{ matrix.shard }} path : tests/playwright-runner/test-results/ merge-reports : if : always() needs : test runs-on : ubuntu-latest container : webgrip/playwright-runner:latest steps : - uses : actions/checkout@v4 - name : Download all test results uses : actions/download-artifact@v3 with : pattern : playwright-results-* merge-multiple : true path : test-results/ - name : Merge test reports run : | cd tests/playwright-runner npx playwright merge-reports --reporter=html test-results/ - name : Upload merged report uses : actions/upload-artifact@v3 with : name : playwright-report path : tests/playwright-runner/playwright-report/","title":"GitHub Actions Integration"},{"location":"testing/test-execution/#parallel-execution","text":"","title":"Parallel Execution"},{"location":"testing/test-execution/#browser-parallelization","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // playwright.config.ts - Browser parallelization export default defineConfig ({ projects : [ { name : 'chromium' , use : { ... devices [ 'Desktop Chrome' ] }, }, { name : 'firefox' , use : { ... devices [ 'Desktop Firefox' ] }, }, { name : 'webkit' , use : { ... devices [ 'Desktop Safari' ] }, }, ], }); 1 2 3 4 5 6 7 8 # Run all browsers in parallel npx playwright test # Run specific browser npx playwright test --project = chromium # Run multiple specific browsers npx playwright test --project = chromium --project = firefox","title":"Browser Parallelization"},{"location":"testing/test-execution/#test-sharding","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Split tests across multiple runners npx playwright test --shard = 1 /4 # Run 1st quarter npx playwright test --shard = 2 /4 # Run 2nd quarter npx playwright test --shard = 3 /4 # Run 3rd quarter npx playwright test --shard = 4 /4 # Run 4th quarter # In CI with matrix strategy: matrix: shard: [ 1 , 2 , 3 , 4 ] steps: - name: Run tests ( Shard ${ { matrix.shard } }) run: npx playwright test --shard = ${ { matrix.shard } } /4","title":"Test Sharding"},{"location":"testing/test-execution/#worker-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // playwright.config.ts - Worker optimization export default defineConfig ({ // Local development - use all cores workers : process.env.CI ? 2 : undefined , // Or specify exact number workers : 4 , // Full parallelization fullyParallel : true , // Global timeout globalTimeout : 60 * 60 * 1000 , // 1 hour // Per-test timeout timeout : 30 * 1000 , // 30 seconds });","title":"Worker Configuration"},{"location":"testing/test-execution/#test-selection-and-filtering","text":"","title":"Test Selection and Filtering"},{"location":"testing/test-execution/#tag-based-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // tests/auth.spec.ts test . describe ( 'Authentication @smoke @auth' , () => { test ( 'should login successfully @critical' , async ({ page }) => { // Test implementation }); test ( 'should handle invalid credentials @error-handling' , async ({ page }) => { // Test implementation }); }); test . describe ( 'User Management @integration @users' , () => { test ( 'should create new user @crud' , async ({ page }) => { // Test implementation }); }); 1 2 3 4 5 6 7 8 9 # Run tests by tags npx playwright test --grep \"@smoke\" # Smoke tests only npx playwright test --grep \"@critical\" # Critical tests only npx playwright test --grep \"@smoke|@critical\" # Smoke OR critical npx playwright test --grep-invert \"@slow\" # Everything except slow tests # Run by test suite npx playwright test --grep \"@auth\" # All auth tests npx playwright test tests/auth/ # All files in auth directory","title":"Tag-based Execution"},{"location":"testing/test-execution/#environment-specific-selection","text":"1 2 3 4 5 6 7 8 # Development environment - fast feedback npx playwright test --grep \"@smoke\" --project = chromium # Staging environment - comprehensive testing npx playwright test --grep \"@smoke|@integration\" # Production monitoring - critical paths only npx playwright test --grep \"@critical|@monitoring\"","title":"Environment-specific Selection"},{"location":"testing/test-execution/#file-based-selection","text":"1 2 3 4 5 6 7 8 9 # Run specific test files npx playwright test tests/auth/login.spec.ts npx playwright test tests/auth/ # Run multiple specific files npx playwright test tests/auth/login.spec.ts tests/users/profile.spec.ts # Run tests matching pattern npx playwright test \"**/*auth*.spec.ts\"","title":"File-based Selection"},{"location":"testing/test-execution/#cross-environment-testing","text":"","title":"Cross-Environment Testing"},{"location":"testing/test-execution/#environment-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // config/environments.ts export const environments = { development : { baseURL : 'http://localhost:8000' , timeout : 10000 , retries : 0 , }, staging : { baseURL : 'https://staging.webgrip.nl' , timeout : 30000 , retries : 2 , }, production : { baseURL : 'https://app.webgrip.nl' , timeout : 15000 , retries : 1 , }, }; // playwright.config.ts const env = process . env . TEST_ENV || 'development' ; const config = environments [ env ]; export default defineConfig ({ use : { baseURL : config.baseURL , actionTimeout : config.timeout , }, retries : config.retries , });","title":"Environment Configuration"},{"location":"testing/test-execution/#environment-specific-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Test against different environments TEST_ENV = development npx playwright test TEST_ENV = staging npx playwright test --grep \"@smoke\" TEST_ENV = production npx playwright test --grep \"@monitoring\" # With Docker docker run --rm \\ -v $( pwd ) :/app \\ -w /app/tests/playwright-runner \\ -e TEST_ENV = staging \\ -e BASE_URL = https://staging.webgrip.nl \\ webgrip/playwright-runner:latest \\ npx playwright test --grep \"@smoke\"","title":"Environment-specific Execution"},{"location":"testing/test-execution/#cross-browser-testing-matrix","text":"1 2 3 4 5 6 7 8 9 10 11 # Complete cross-browser testing strategy : matrix : browser : [ chromium , firefox , webkit ] environment : [ staging , production ] steps : - name : Test ${{ matrix.browser }} on ${{ matrix.environment }} env : TEST_ENV : ${{ matrix.environment }} run : npx playwright test --project=${{ matrix.browser }}","title":"Cross-browser Testing Matrix"},{"location":"testing/test-execution/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"testing/test-execution/#test-execution-performance","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // playwright.config.ts - Performance optimizations export default defineConfig ({ // Faster test execution fullyParallel : true , workers : process.env.CI ? 4 : undefined , // Reasonable timeouts timeout : 30000 , actionTimeout : 10000 , navigationTimeout : 15000 , // Optimize for CI use : { // Disable animations for faster execution reducedMotion : 'reduce' , // Optimize screenshots screenshot : 'only-on-failure' , // Minimal trace collection trace : 'retain-on-failure' , // Disable video in CI video : process.env.CI ? 'off' : 'retain-on-failure' , }, // Global setup for shared state globalSetup : require.resolve ( './global-setup' ), globalTeardown : require.resolve ( './global-teardown' ), });","title":"Test Execution Performance"},{"location":"testing/test-execution/#resource-management","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // global-setup.ts - Shared setup import { chromium , FullConfig } from '@playwright/test' ; async function globalSetup ( config : FullConfig ) { // Setup shared database state await setupTestDatabase (); // Warm up application const browser = await chromium . launch (); const page = await browser . newPage (); await page . goto ( config . projects [ 0 ]. use . baseURL ); await browser . close (); // Cache authentication state await setupAuthenticationState (); } export default globalSetup ;","title":"Resource Management"},{"location":"testing/test-execution/#caching-strategies","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 // fixtures/auth-cache.ts import { test as base } from '@playwright/test' ; const STORAGE_STATE = 'auth-state.json' ; export const test = base . extend ({ // Reuse authentication state storageState : STORAGE_STATE , authenticatedPage : async ({ page }, use ) => { // Use cached authentication if available await use ( page ); }, });","title":"Caching Strategies"},{"location":"testing/test-execution/#test-result-management","text":"","title":"Test Result Management"},{"location":"testing/test-execution/#report-generation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // playwright.config.ts - Multiple reporters export default defineConfig ({ reporter : [ // HTML report for local development [ 'html' , { outputFolder : 'playwright-report' , open : process.env.CI ? 'never' : 'on-failure' }], // JSON for CI integration [ 'json' , { outputFile : 'test-results.json' }], // JUnit for test management systems [ 'junit' , { outputFile : 'test-results.xml' }], // Line reporter for CI logs [ 'line' ], // Custom reporter for notifications [ './reporters/slack-reporter.js' ], ], });","title":"Report Generation"},{"location":"testing/test-execution/#artifact-management","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # Generate and collect artifacts npx playwright test \\ --reporter = html \\ --output-dir = test-results \\ --screenshot = on \\ --video = on \\ --trace = on # Archive results tar -czf \"test-results- $( date +%Y%m%d-%H%M%S ) .tar.gz\" \\ test-results/ \\ playwright-report/ \\ test-results.json","title":"Artifact Management"},{"location":"testing/test-execution/#cicd-integration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Complete artifact handling - name : Run Playwright tests run : npx playwright test --reporter=blob - name : Generate HTML report if : always() run : npx playwright merge-reports --reporter=html blob-report/ - name : Upload test report uses : actions/upload-artifact@v3 if : always() with : name : playwright-report-${{ github.run_id }} path : | playwright-report/ test-results/ retention-days : 30 - name : Upload to test management if : always() run : | curl -X POST \\ -H \"Content-Type: application/json\" \\ -d @test-results.json \\ https://test-management.webgrip.nl/api/results","title":"CI/CD Integration"},{"location":"testing/test-execution/#monitoring-and-alerting","text":"","title":"Monitoring and Alerting"},{"location":"testing/test-execution/#synthetic-monitoring","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // tests/monitoring/critical-paths.spec.ts import { test , expect } from '@playwright/test' ; test . describe ( 'Critical Path Monitoring @monitoring @critical' , () => { test ( 'user login flow' , async ({ page }) => { const startTime = Date . now (); await page . goto ( '/login' ); await page . fill ( '[name=\"email\"]' , process . env . MONITOR_USER_EMAIL ! ); await page . fill ( '[name=\"password\"]' , process . env . MONITOR_USER_PASSWORD ! ); await page . click ( 'button[type=\"submit\"]' ); await expect ( page ). toHaveURL ( '/dashboard' ); const loadTime = Date . now () - startTime ; expect ( loadTime ). toBeLessThan ( 5000 ); // 5 second SLA }); test ( 'checkout process' , async ({ page }) => { // Simulate critical business process await page . goto ( '/products/1' ); await page . click ( 'button:has-text(\"Add to Cart\")' ); await page . goto ( '/checkout' ); // Verify checkout loads within SLA await expect ( page . locator ( 'h1' )). toContainText ( 'Checkout' ); }); });","title":"Synthetic Monitoring"},{"location":"testing/test-execution/#alert-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/bin/bash # monitoring/run-synthetic-tests.sh # Run critical path tests npx playwright test --grep \"@monitoring\" --reporter = json > monitoring-results.json # Check for failures FAILURES = $( jq '.stats.failed' monitoring-results.json ) if [ \" $FAILURES \" -gt 0 ] ; then # Send alert to Slack curl -X POST -H 'Content-type: application/json' \\ --data '{\"text\":\"\ud83d\udea8 Synthetic monitoring tests failed: ' \" $FAILURES \" ' failures detected\"}' \\ $SLACK_WEBHOOK_URL # Page on-call team curl -X POST \\ -H \"Authorization: Token $PAGERDUTY_TOKEN \" \\ -H \"Content-Type: application/json\" \\ -d '{ \"incident\": { \"type\": \"incident\", \"title\": \"Synthetic Test Failures\", \"service\": {\"id\": \"' \" $PAGERDUTY_SERVICE_ID \" '\", \"type\": \"service_reference\"} } }' \\ https://api.pagerduty.com/incidents fi","title":"Alert Configuration"},{"location":"testing/test-execution/#performance-monitoring","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tests/performance/load-times.spec.ts test ( 'performance metrics' , async ({ page }) => { await page . goto ( '/' ); const metrics = await page . evaluate (() => { const perfData = performance . getEntriesByType ( 'navigation' )[ 0 ]; return { domContentLoaded : perfData.domContentLoadedEventEnd - perfData . fetchStart , loadComplete : perfData.loadEventEnd - perfData . fetchStart , firstPaint : performance.getEntriesByType ( 'paint' )[ 0 ] ? . startTime || 0 , }; }); // Assert performance SLAs expect ( metrics . domContentLoaded ). toBeLessThan ( 2000 ); expect ( metrics . loadComplete ). toBeLessThan ( 5000 ); expect ( metrics . firstPaint ). toBeLessThan ( 1500 ); // Log metrics for monitoring console . log ( 'Performance Metrics:' , JSON . stringify ( metrics )); });","title":"Performance Monitoring"},{"location":"testing/test-execution/#troubleshooting-test-execution","text":"","title":"Troubleshooting Test Execution"},{"location":"testing/test-execution/#common-execution-issues","text":"Tests timing out 1 2 3 4 5 6 7 // Increase timeouts for specific tests test ( 'slow operation' , async ({ page }) => { test . setTimeout ( 60000 ); // 60 seconds for this test await page . goto ( '/slow-page' ); await page . waitForSelector ( '.slow-component' , { timeout : 30000 }); }); Flaky tests 1 2 3 4 5 6 7 8 9 10 11 12 13 // Add proper waits and retries test ( 'potentially flaky test' , async ({ page }) => { // Retry this test up to 3 times test . fixme (({ browserName }) => browserName === 'webkit' , 'Flaky on WebKit' ); await page . goto ( '/' ); // Wait for network to be idle await page . waitForLoadState ( 'networkidle' ); // Use auto-waiting assertions await expect ( page . locator ( '.dynamic-content' )). toBeVisible (); }); Resource exhaustion 1 2 3 4 5 6 7 8 9 10 11 12 13 # Reduce parallel workers npx playwright test --workers = 1 # Run tests sequentially npx playwright test --workers = 1 --fullyParallel = false # Increase system resources docker run --rm \\ --memory = 4g \\ --cpus = 2 \\ -v $( pwd ) :/app \\ webgrip/playwright-runner:latest \\ npx playwright test","title":"Common Execution Issues"},{"location":"testing/test-execution/#debug-execution","text":"1 2 3 4 5 6 7 8 9 10 11 12 # Debug with verbose output DEBUG = pw:* npx playwright test # Debug specific test npx playwright test --debug tests/auth/login.spec.ts # Debug in headed mode npx playwright test --headed --slowMo = 1000 # Generate trace for debugging npx playwright test --trace = on npx playwright show-trace test-results/example-test/trace.zip","title":"Debug Execution"},{"location":"testing/test-execution/#related-documentation","text":"Playwright Setup - Initial configuration and test writing Playwright Runner Image - Container environment CI/CD Pipeline - Automated test execution Architecture Overview - Testing architecture Assumption : Test execution primarily occurs in containerized environments with reliable network connectivity. High-latency or unreliable network conditions may require additional timeout and retry configuration. Validation needed: Confirm network and infrastructure requirements for test execution environments. Maintainer : WebGrip Ops Team Configuration : tests/playwright-runner/playwright.config.ts Container : webgrip/playwright-runner","title":"Related Documentation"}]}